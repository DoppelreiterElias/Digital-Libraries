<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T13:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visual Analytics for Complex Concepts Using a Human Cognition Model</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Tera</forename>
								<forename type="middle">Marie</forename>
								<surname>Green</surname>
							</persName>
							<affiliation>
								<orgName type="department">Charlotte Visualization Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">William</forename>
								<surname>Ribarsky</surname>
							</persName>
							<affiliation>
								<orgName type="department">Charlotte Visualization Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Brian</forename>
								<surname>Fisher</surname>
							</persName>
							<affiliation>
								<orgName type="department">School of Interactive Arts and Technology</orgName>
								<orgName type="institution">University of North Carolina Simon Fraser University at Charlotte</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Visual Analytics for Complex Concepts Using a Human Cognition Model</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>visual analytics, cognition and perception theory,</term>
					<term>embodied cognition, visualization taxonomies and models</term>
					<term>INDEX TERMS: visual analytics, cognition and perception theory,</term>
					<term>embodied cognition, visualization taxonomies and models</term>
				</keywords>
			</textClass>
			<abstract>
				<p>As the information being visualized and the process of understanding that information both become increasingly complex, it is necessary to develop new visualization approaches that facilitate the flow of human reasoning. In this paper, we endeavor to push visualization design a step beyond current user models by discussing a modeling framework of human &quot; higher cognition. &quot; Based on this cognition model, we present design guidelines for the development of visual interfaces designed to maximize the complementary cognitive strengths of both human and computer. Some of these principles are already being reflected in the better visual analytics designs, while others have not yet been applied or fully applied. But none of the guidelines have explained the deeper rationale that the model provides. Lastly, we discuss and assess these visual analytics guidelines through the evaluation of several visualization examples. 1 INTRODUCTION In a previous paper [1], we discussed the necessity of considering principles of human reasoning, problem-solving, and decision-making, in addition to the already familiar areas of sensation and perception, to develop information and knowledge visualizations capable of attacking today&apos;s complex, important problems which require both reasoning and analysis. In most visualization development up to this point, &quot; higher cognition &quot; processes have been considered as something of a human black box, into which information is inputted, and from which appropriate responsive behavior is somehow obtained. (We will discuss this metaphorical view of human-visualization interaction during our consideration of the van Wijk operational model of visualization in Section 4.) But as both interactive visualizations and their tasks become semantically complex, it becomes apparent that we must peek into the black box in an attempt to model a human-computer system and its interactions. In truth, the black box analogy is an imperfect one for human higher cognition. Psychology and other behavioral sciences have been researching reasoning and other thought processes for decades. One reason that much of this research has, as yet, been unused in the construction of interactive visualizations is the lack of a unifying theory of human reason. It is, as Newell once wrote, as if &quot; science advances by playing twenty questions with nature &quot; [2]. The study of higher cognition is not pursued holistically; it is usually broken down into bite-sized subprocesses, and competing theories of small, often binary, aspects of reasoning have dominated the research. In addition, holistic &quot; higher cognition, &quot; unlike human sensation and perception, employs combinatorial use of multiple heuristics, which is rarely binary, almost never perfectly sequential, and has, as yet, defied traditional model-based prediction. But while complex, higher cognition is still predictable to some degree. The number of available heuristics is finite, and is therefore theoretically knowable. And while extant research may disagree on the fine points, it does confirm one essential fact: humans use the simplest heuristic possible to accomplish the task at hand. This by itself is no small starting point. But humans are also predictable in other ways, which we will soon explore. This paper endeavours to lay the framework of a human cognition model, whose guidelines would guide the development of visual interfaces more able to attack the complex problems now at hand. Additionally, this paper shows how this model contributes new, cognition-based principles of visualization design. Some of these principles are already being used in the better visual analytics designs, but without the deeper rationale that the model provides. We will discuss and evaluate these visual analytics methods. Other principles from the model have not been applied or not fully applied, and we will discuss how their implementation and use will be of benefit. 2 COMPLEMENTARY STRENGTHS Both human and computer bring strengths to a mixed-initiative visualization, in which both the computer and the human initiate processes and with which both collaborate in the exploration and creation of knowledge. Several of the obvious strengths are complementary, which further strengthens the potential of the collaboration. 2.1 Human strengths Some of the earliest reasoning skills humans develop are those of adaptation and accommodation [3]. Adaptation is the ability to incorporate newly perceived information into extant knowledge schema and it relies heavily on an ability to categorize sensory stimuli at an &quot; instantaneous &quot; rate. Even when what is perceived is so novel it will not fit existing knowledge schema, accommodation allows a human to temporarily place a marker in a closely similar schema or create a new one [4].This fast and frugal reasoning ability [5] enables humans to more • Tera Marie Green: grepmon@gmail.com • William Ribarsky: ribarsky@uncc.edu • Brian Fisher: bfisher@sfu.ca 91</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In a previous paper <ref type="bibr" coords="1,144.46,433.21,9.45,8.21">[1]</ref>, we discussed the necessity of considering principles of human reasoning, problem-solving, and decision-making, in addition to the already familiar areas of sensation and perception, to develop information and knowledge visualizations capable of attacking today's complex, important problems which require both reasoning and analysis. In most visualization development up to this point, " higher cognition " processes have been considered as something of a human black box, into which information is inputted, and from which appropriate responsive behavior is somehow obtained. (We will discuss this metaphorical view of human-visualization interaction during our consideration of the van Wijk operational model of visualization in Section 4.) But as both interactive visualizations and their tasks become semantically complex, it becomes apparent that we must peek into the black box in an attempt to model a human-computer system and its interactions. In truth, the black box analogy is an imperfect one for human higher cognition. Psychology and other behavioral sciences have been researching reasoning and other thought processes for decades. One reason that much of this research has, as yet, been unused in the construction of interactive visualizations is the lack of a unifying theory of human reason. It is, as Newell once wrote, as if " science advances by playing twenty questions with nature " <ref type="bibr" coords="1,356.39,213.37,9.45,8.21">[2]</ref>. The study of higher cognition is not pursued holistically; it is usually broken down into bite-sized subprocesses, and competing theories of small, often binary, aspects of reasoning have dominated the research. In addition, holistic " higher cognition, " unlike human sensation and perception, employs combinatorial use of multiple heuristics, which is rarely binary, almost never perfectly sequential, and has, as yet, defied traditional model-based prediction. But while complex, higher cognition is still predictable to some degree. The number of available heuristics is finite, and is therefore theoretically knowable. And while extant research may disagree on the fine points, it does confirm one essential fact: humans use the simplest heuristic possible to accomplish the task at hand. This by itself is no small starting point. But humans are also predictable in other ways, which we will soon explore. This paper endeavours to lay the framework of a human cognition model, whose guidelines would guide the development of visual interfaces more able to attack the complex problems now at hand. Additionally, this paper shows how this model contributes new, cognition-based principles of visualization design. Some of these principles are already being used in the better visual analytics designs, but without the deeper rationale that the model provides. We will discuss and evaluate these visual analytics methods. Other principles from the model have not been applied or not fully applied, and we will discuss how their implementation and use will be of benefit. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">COMPLEMENTARY STRENGTHS</head><p>Both human and computer bring strengths to a mixed-initiative visualization, in which both the computer and the human initiate processes and with which both collaborate in the exploration and creation of knowledge. Several of the obvious strengths are complementary, which further strengthens the potential of the collaboration. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Human strengths</head><p>Some of the earliest reasoning skills humans develop are those of adaptation and accommodation <ref type="bibr" coords="1,452.36,629.29,9.45,8.21" target="#b1">[3]</ref>. Adaptation is the ability to incorporate newly perceived information into extant knowledge schema and it relies heavily on an ability to categorize sensory stimuli at an " instantaneous " rate. Even when what is perceived is so novel it will not fit existing knowledge schema, accommodation allows a human to temporarily place a marker in a closely similar schema or create a new one <ref type="bibr" coords="1,529.09,691.45,10.91,8.21">[4]</ref>.This fast and frugal reasoning ability <ref type="bibr" coords="1,450.20,701.77,10.48,8.21">[5] </ref>enables humans to more @BULLET Tera Marie Green: grepmon@gmail.com @BULLET William Ribarsky: ribarsky@uncc.edu @BULLET Brian Fisher: bfisher@sfu.ca effectively deal with rapidly-changing situations. Biederman's 1987 " recognition by components " model provides a mechanism by which basic level categorization of objects takes place rapidly and accurately regardless of viewpoint or changes in non-essential characteristics of those objects. <ref type="bibr" coords="2,222.48,97.21,10.78,8.21">[6]</ref>.This all seems effortless to a human, and allows the reasoning process to move forward, even when the information is incomplete. It is also vastly superior to rigid computer recognition; when presented with what it has not been programmed to recognize, the computer is stymied, often aborting the process. Human perceptual abilities are also well adapted to complex and rapidly changing scenes, defined here as complex sets of objects and events distributed in space that interact with each other in often novel ways. This takes place through a combination of a low-level " gist " mechanism that recognizes important scene characteristics and relationships <ref type="bibr" coords="2,252.72,211.21,9.45,8.21">[7]</ref>. This preattentive visual process guides the allocation of multiple attentional tokens i.e. FINSTS, see <ref type="bibr" coords="2,197.76,231.85,9.48,8.21">[8,</ref><ref type="bibr" coords="2,212.88,231.85,7.60,8.21"> 9] </ref>that support the automatic calculation of a set of operations <ref type="bibr" coords="2,236.16,242.17,15.04,8.21">[10] </ref>on their properties and relations to each other. All of this occurs prior to, and in support of, endogenous attention (attention to the task at hand). This resulting cascade of processes frees cognition for consideration of higher order characteristics of the information contained in the display rather than the display itself --object properties and spatial relations with other objects and causal relations to events taking place. Thus, cognitive operations can proceed using more parsimonious representations that are wellsuited for the task at hand. This can be thought of as a two-step process by which unconscious inference, the " logic of perception " , <ref type="bibr" coords="2,101.76,356.17,15.04,8.21">[11] </ref>works hand-in-hand with cognitive processes to support reasoning. In this view, expertise is not only a characteristic of higher-order cognitive logic, but also of perceptual logic, which can be trained to better support cognitive operations through " perceptual expertise " <ref type="bibr" coords="2,206.64,397.45,13.73,8.21">[12]</ref>. Partially due to a lifetime of experience in adaptation and accommodation, humans are also vastly superior reasoners to computers. Humans have a compendium of reasoning and problem-solving heuristics, which can be used singly or concomitantly to accomplish the task at hand. The simplest of these, elimination heuristics such as satisficing <ref type="bibr" coords="2,233.52,459.61,13.73,8.21">[13]</ref>, eliminate available choices that do not possess an identified important attribute. Elimination heuristics require little cognitive effort, and so are often what a human will use first in an attempt to narrow down available choices. Of course, if the problem becomes semantically complex, more effort is required. Our model assumes a mental model to inferred rules mechanization <ref type="bibr" coords="2,163.44,531.85,13.73,8.21">[14]</ref>, wherein the human uses all available information to create a mental model of the concept being considered. From this model, the human infers generalizable rules – sometimes in a matter of seconds – that are used in later instantiations of a similar concept or problem. Because these models are based entirely on available (including previously held) information, it is imperative that all pertinent information is available to avoid the creation of incomplete mental models, which are, in turn, likely to be the basis of invalid rules. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Computer strengths</head><p>A computer is capable of two distinct processes that complement human reasoning strengths well: superior working memory and information processing without cognitive biases. Humans depend on their working memory as they reason, but are, at best, able to remember 7 ± 2 chunks of information <ref type="bibr" coords="2,270.72,707.77,13.73,8.21">[15]</ref>. The computer, on the other hand, has a " working memory " limited only by hardware. The computer's ability to keep all pertinent information visually available to the human aids in complete mental modeling, among other things. The other computer strength is the lack of inherent biases. This bias-free environment is, to be sure, influenced by what the interface is designed to see as relationally relevant. But unlike humans, computers do not situationally filter out pertinent information in accordance with a perceived belief or due to the way a problem is presented <ref type="bibr" coords="2,428.64,149.05,14.22,8.21">[16,</ref><ref type="bibr" coords="2,442.86,149.05,10.66,8.21">17]</ref>. By presenting all relevant information, the computer can aid not only in mental modeling, but also in the analysis of competing hypotheses. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">USE OF A HUMAN COGNITION MODEL</head><p>This section will discuss the ways in which a knowledge of higher cognition focuses a mixed-initiative human cognition model (HCM), as well as provides several guidelines which can be derived from the model's use. (See <ref type="figure" coords="2,465.84,242.17,29.33,8.21">Figure 1</ref>.) On each of the HCM's submodels, please see <ref type="bibr" coords="2,434.88,252.49,10.48,8.21">[1] </ref>for more discussion. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Information Discovery &amp; Knowledge Building</head><p>The central process of the HCM is discovery, during which the computer presents information in an ontological-like structure within a relevant, possibly human-defined, context. Presenting information with a relevant context is one method of mitigating human cognitive overload in the midst of an overwhelming number of semantic data points. The human directly interacts with the visualized information, focusing the attention of discovery. We will explore this idea further in Section 5.4. An intuitive multi-model visualization also encourages knowledge building through new knowledge creation. Throughout the process of discovery, the human may uncover a relationship between two currently unrelated concepts or ideas. By creating a new relationship between the two concepts and perhaps annotating the relationship, the human collaborator can extend the knowledge base of the visualization, not only for what is to be accomplished in that particular session, but for every session by every human who uses the visualization thereafter. The computer can augment the discovery of relevant information through computer-aided discovery. Through observation of what interests the human collaborator, the computer can suggest information that is semantically related, but up to this point, has not been considered. This also would include relational data which has been added by other human collaborators, which allows one person to learn from another. The human is free to explore or to reject the suggestion. But by making the effort in ensuring that nothing important is overlooked, the computer works to counteract human cognitive biases which can interfere with complete mental modelling. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Guidelines for Discovery and Knowledge Building</head><p>We will now briefly discuss several guidelines based upon the HCM discovery and knowledge submodels. but we would argue that a visualization that utilizes multiple organizational views of the same information can be a powerful aid. As the human interacts with information in any view, the relational changes are visualized in all views. While the concept of multiple views is not a new one <ref type="bibr" coords="3,270.96,97.21,13.73,8.21">[18]</ref>, what we would highlight is how multiple views are informed by human cognition. First, as humans perceive information in a variety of ways including through the filter of their own assumptions, patterns are more likely to be discovered if represented multiple ways, each tuned to particular, important aspects of the data. Secondly, as we have discussed previously, humans prefer to narrow down the field of choices by eliminating those that do not posses desired attributes. This is usually done before utilizing more complicated heuristics. Multiple views make the process easier; multiple layers of relational attributes are readily knowable without additional search. Thirdly, multiple views enable more intuitive manipulation. Humans themselves do not interact with information in one dimension; humans are capable of multi-layered processing: perceptual, emotional, and higher-cognitive. Indeed, of all the guidelines we will discuss, use of multiple views is the one most likely to lead to spontaneous insight. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Direct interaction</head><p>By definition, a well-designed information visualization allows the user to directly interact with information. But we would take direct interaction one step further. In computer-aided discovery, for example, the guideline of direct interaction would propose that whatever tactic the computer uses to suggest relational information to the human be done without interfering with a human's train of thought or flow of reasoning. Additionally, direct interaction supports the goals of other HCM guidelines by facilitating rich, fast, and effective interaction. The human thinks in terms of the analysis task, which is closely aligned with the interaction, and then looks at the visualized results. As a result, the user is more able to stay in the cognitive zone (as we will discuss shortly), even with multiple windows. With this in mind, visualization design should avoid, as much as possible, menus or other actions that take the user outside of the frame of the task. Interactions should be through direct manipulation and translucent wherever possible, avoiding the traditional pull-down menus, which require the human to sort through and think about menu items. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Central Role of Interaction</head><p>Human-computer interaction is not a series of disjointed behaviors. And while the visual process is an important part of visualization, it is not the central role. Interaction has a rhythm, a cycle of give and take. Interaction is the process by which the computer and the human give, take, and create knowledge. We will see an example of this when we will consider the van Wijk operational model in the next section. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5">Intimate interaction</head><p>It is important that the interaction is so translucent to the human collaborator that the give and take which occurs in a successful collaboration is seamless. Entering the interaction should seem natural and obvious. The use of on-screen tools should not require additional cognitive focus – i.e. be usable without the human having to " think about it. " Intimate interaction deters attentional interference during the cognitive flow, and enables the reasoning process to move forward unabated. When interaction is intimate, what the human should see and cognitively manipulate is not the tool being used or the method of interaction, but only the interaction itself. Intimate interaction is an important asset to flow insulation, and is supportive of the central role of interaction. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Search by Example &amp; Search by Pattern</head><p>Searching for information has traditionally been done by stipulating a search term in a text box. But text boxes require humans to know exactly what to look for (such as in Booleantype queries), as well as to stop where they are in the reasoning process to look for information in concrete terms. When text box queries are not ideal, such as work within an information-scent model <ref type="bibr" coords="3,353.28,511.21,13.73,8.21">[34]</ref>, we would propose that search be done by graphically indicating an example to search by, or by drawing a bounding box around a pattern or other organization of relational information. In either case, search is done more intuitively, and reasoning moves forward. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Creation and Analysis of Hypotheses</head><p>One extension of the knowledge building process that holds great potential for multi-modal visualization is in the creation of hypotheses. Hypothesis generation can be fraught with human cognitive bias, as humans are wont to seek out evidence that proves what they already believe or want to believe. Getting past these biases can be time-expensive and destructive to the process. As Heuer described it <ref type="bibr" coords="3,409.68,666.49,13.54,8.21">[19]</ref>, hypothesis analysis starts with a list of hypotheses and a list of evidence that proves or disproves each one. As the human creates of list of hypotheses, the computer can aid in finding relevant evidence. From there, the computer, with its superior working memory, creates a weighted matrix or another relational structure which the human edits with superior reasoning. Using the edited relational structure, the human draws conclusions about which hypotheses are correct, and if desired, sets up a data watch in the visualization which will notify the user of data changes. Hypotheses generation is initiated by the human, but the computer plays a significant role in shortening the process and neutralizing biases, as contributing to more solid conclusion through use of its strengths. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONSIDERING THE VAN WIJK MODEL</head><p>We will now discuss what the implications of our model would look like if integrated into the van Wijk operational model of the visualization process <ref type="bibr" coords="4,132.96,200.89,13.73,8.21">[20]</ref>. We do this primarily as another way to envision how a human cognition model interrelates with other aspects of visualization theory, or as another way to broadly sketch out the basic assumptions of the HCM within the context of an extant model. Van Wijk models the " user " as P (perception and cognition), K (knowledge), and E (interactive exploration), as is demonstrated in <ref type="figure" coords="4,115.68,273.37,29.94,8.21" target="#fig_0">Figure 2</ref>. The user perceives the image (I) and utilizes the specifications (S) in exploration. It is difficult, however, to separate " knowledge " from the reasoning process that created it. A person's knowledge is not simply a compendium of declarative facts; it is also the relational or inferential semantic meaning a person gives the facts, patterns of facts and their relationships, the perceived worth of those facts, and the ways in which facts are used to reason about the encounter with future novel information. Indeed, facts are useless without the reasoning power to manipulate them, and so we believe that the 'K' submodel, must include the cognition processes that created it. Knowledge determines the methods used when new knowledge is integrated with the old. Van Wijk also seems to imply this in how he models his " user; " his model pictures Knowledge feeding Exploration. But K cannot inform E without the guiding focus of a reasoning process. Indeed, exploration itself is cognition in action. With these thoughts in mind, it might truly be more representative if Perception, Knowledge, and Exploration were all modelled as cognitive processes informing each other. We would see P as the early cognitive processes of selective attention, categorization, accommodation, including perceptual logic. (See Section 2.1.) K is viewed as meaningful knowledge with the use of reasoning, problem-solving and other thought processes which allow the human to create knowledge, and E as a focused, interactive cognitive process utilizing both P and K. When viewing the model this way, it's easy to see that two additional directional arrows need to be added to the model: from P to E, and from E to K. The first arrow indicates the important role that perception and perceptual logic plays in active exploration. The second arrow signifies how a rhythm of interaction feeds knowledge reasoning. As the human explores and learns, that learning directs and focuses the attention of further exploration. Additionally, van Wijk expressed Knowledge in this way: <ref type="bibr" coords="4,519.84,157.93,15.04,8.21">[20] </ref>While this expression does encapsulate the idea that Perception is a vital part of the process, our integration would express the creation of knowledge over time more like the following: </p><formula>= ) (t K ∫ + t K 0 0 dt t) K, P(I, </formula><formula>0 ) ( K t K = + ∫ t 0 dt t) K, E(P, </formula><p>where Knowledge is the extension of currently held knowledge through the integrated perceptual and reasoning cognitive processes of Exploration. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXAMPLES</head><p>In this section, we will demonstrate the model guidelines by using them to evaluate and/or illustrate several visual analytics designs. The model, which was not used as a basis for these designs, provides a deeper understanding of the choices made and how the designs might be improved. Because we can discuss the rationale behind them more fully, we present predominantly designs in which we were developmentally involved. However, the arguments we make here would also apply to many other designs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">WireVis</head><p>Discovering financial fraud in the great stream of transactions at a large bank is a difficult, time-consuming, and expensive process since it must employ expert analysts and uncover everchanging modes of operation by criminals. The WireVis system was designed to combine the art of analysis with the science of visual analytics <ref type="bibr" coords="4,385.20,493.69,13.73,8.21">[21]</ref>. WireVis is an expert system, enhancing insight with what, in the terms of our Knowledge expression in the last section, is presumed to be the human's already sizeable K 0 ; it provides intuitive visual representations of wire transactions, enhancing P; different views within the system allow the analysts to gain an overview of all transactions in one glance, while the ability to drill down into specific details of individual transactions enables finer examination and scrutiny. The main interface is shown in <ref type="figure" coords="4,462.72,576.49,33.18,8.21" target="#fig_0">Figure 2</ref>. A time-based visualization allows the analysts to detect abnormal temporal patterns. Search by example permits selection of a particular keyword or time distribution pattern; the system then finds patterns that are similar to (or quite different from) the selected pattern. Finally, a keyword network shows keyword links for the selected group of transactions (where linked keywords appear in the same transaction), uncovering relationships that significantly aid the analyst in picking out suspicious transactions. This process highlights the importance of E in extending K. Results of a user evaluation found WireVis to be an efficient, effective tool, which can discover suspicious patterns in a great mass of transaction data <ref type="bibr" coords="4,387.36,700.57,13.93,8.21">[21]</ref>; the tool is also generally applicable to other types of transactional analysis. WireVis has a number of capabilities that conform to the above cognitive model and highlights some of the design choices that must be made. Four windows are tailored to specific, important views and tasks. Though having a single window to focus the user's attention may be ideal in some conceptual sense, and there is presumably a cognitive and perceptual load during task switching, multiple windows seem necessary for many complex analytical problems <ref type="bibr" coords="5,239.04,128.41,14.28,8.21">[22,</ref><ref type="bibr" coords="5,256.56,128.41,10.71,8.21"> 23]</ref>. The key is to minimize the load in order to mitigate the interference to the human's reasoning flow. In WireVis, the views were carefully chosen so that overviews of main aspects of financial analysis were maintained. Linking and brushing between all views was enacted and immediate update to any interaction was enforced. (There are not only perceptual but cognitive aspects to maintaining high interactivity.) In addition, WireVis is designed to promote " balanced interaction " , during which the multiple interlinked windows act and look like a single interface, rather than separate entities; changes in one window are reflected across the interface, allowing the human to focus on the interaction; and similar types of interaction are supported in all windows. Thus, various selecting, filtering, and drill-down (through the transaction hierarchy of transactions) interactions appear simultaneously in the multiple windows. Further, very lightweight cursor passover interaction is enabled in several places (for example, passing over specific keywords). Finally, direct manipulation is used wherever possible to maintain user focus. We believe that balanced interaction is an essential design principle to keep investigators " in the cognitive zone " when using a multi-window interface on complex problems. With balanced interaction, the different components of the interface merge into one cognitive whole where, as one of the papers coauthors remarked, " The interaction is the analysis " <ref type="bibr" coords="5,239.28,387.13,13.54,8.21">[24]</ref>. WireVis also has search by example, which has been singled out in our cognitive model because it is very general and it keeps the user in the context of her reasoning process without interrupting it to construct the appropriate search query, which can quite difficult to accomplish. In this case, the user selects the keyword or transaction pattern she is thinking about to gather similar or dissimilar patterns. Search by example has been considered generally useful in other types of visualization, such as image analysis <ref type="bibr" coords="5,121.44,480.25,13.73,8.21">[25]</ref>, broadcast news event analysis <ref type="bibr" coords="5,254.88,480.25,13.73,8.21">[26]</ref>, and terrorism event investigation <ref type="bibr" coords="5,160.32,490.57,13.73,8.21">[27]</ref>. In fact, we believe that search by example should be part of any visual analytics interface involving analysis or reasoning tasks for large amounts of information. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Jigsaw</head><p>Jigsaw is a visual analytics system used to support investigative analysis <ref type="bibr" coords="5,85.92,573.37,13.73,8.21">[22]</ref>. It works with large collections of reports or other text documents and with the entities extracted from them. Its two main goals are to permit investigators to handle efficiently and move quickly through large document collections and to support hypothesis formation and evidence gathering. Jigsaw won the university portion of the VAST 2007 Contest, which centered on a simulated investigation similar to those carried out by intelligence analysts. As with WireVis, Jigsaw makes strong use of multiple windows with carefully tailored representations for complex investigative problems. The user is thought be in an " information cockpit " with multiple monitors, in front of and above the user <ref type="bibr" coords="5,110.16,697.45,13.73,8.21">[22]</ref>. Jigsaw seeks to maximize pixel use to take advantage of both the user's high acuity central focus and wide peripheral field. This is also a valid design point for WireVis (which requires at least two desktop monitors or a high resolution cinema display) or any other multi-window system. However, although Jigsaw has some linking and brushing to integrate the windows, it does not have the balanced interaction WireVis employs. Based on the HCM guidelines, we would expect that users of Jigsaw would be less in the flow and require more cognitive effort than in WireVis during window management and connection. This is certainly a point worthy of further analysis and evaluation. As a point of contrast, Jigsaw uses a bottom-up approach, employing an incremental, query-based method to bring in subsets of data for exploration and possible connection, as compared with WireVis's top-down visualization of the whole dataset and its context. Undoubtedly both approaches are valid and could be available in a general tool for complex problemsolving , and will be the subject of future study. Finally, Jigsaw is usable and simple. The interface permits direction interaction with representations of entities and reports, changing focus and detail. As with WireVis and other tools described here, simplicity and intuitiveness are not just goals based on perception principles but also based on the need for cognitive support. The HCM provides a point of view for investigating these goals in that light. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">UrbanVis</head><p>UrbanVis is a system created to combine views of detailed geographical information with relational views of associated abstract information <ref type="bibr" coords="5,402.72,355.93,13.73,8.21">[28]</ref>. The geographical view is based on urban legibility theories in architecture, and the overall system permits the user to interactively explore an urban environment to understand the detailed characteristics of a city. As with WireVis and Jigsaw and for the same general reasons, UrbanVis is highly dependent upon multiple views, with a 3D multiresolution map driving the updates of a straight category view and a parallel coordinates view, giving the user a rich overview of many categories and relations at once (<ref type="figure" coords="5,535.20,438.49,23.01,8.21;5,324.00,449.05,3.32,8.21">Figure  3</ref>). These views were carefully chosen after consultation with architects, urban planners, and GIS experts. UrbanVis provides a general approach to reasoning with the combination of geographic and abstract data. In addition to the data shown in <ref type="figure" coords="5,324.00,490.33,29.82,8.21">Figure 3</ref>, we are applying UrbanVis to bridge management data over city and state regions and are planning to use it for situation awareness in emergency response. This and the other examples in Section 5 show the generality of a multi-window approach that is designed with principles of human cognition in mind. Users of UrbanVis interact directly with the information, moving a geographic pointer and highlighting areas of interest or conversely choosing categories or individual coordinates in the parallel coordinates view to highlight specific geographic areas. This makes it easer to discover hidden geographical patterns for combinations of demographic or other abstract data. In the same sense as with WireVis, UrbanVis provides balanced interaction. This combined with direct manipulation, makes interaction the central focus. In addition, UrbanVis also provides a top-down, exploratory view with drill down controlled by simple movement of the ball up and down. The interface has only one menu, as it strives to keep the user cognitively focused during problem solving. Finally, since UrbanVis utilizes the central role of interaction, the visualization makes E, as defined in Section 4, the seminal focus. In this interface, designed for a broad cross-section of users, K 0 can be small or great, and an attempt is made through use of color and spatial organization to facilitate P. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">GVis</head><p>Although the human is uniquely qualified for " higher order " reasoning, our human cognition model permits the computer to support this process in numerous ways. GVis in this section and SRS in the next provide some of this support. As several of the visualization approaches utilize similar methods, in these final sections we will highlight areas that are different from WireVis. Using information available in public biological databases such as NCBI, GVis pictures the relationships and publications known about genomic data (<ref type="figure" coords="6,164.12,190.57,30.36,8.21">Figure 5</ref>) <ref type="bibr" coords="6,202.08,190.57,13.73,8.21">[29]</ref>. Due to the detail inherent in genomic data, the amount of information presently viewable during drill down in direct interaction becomes quickly overwhelming; the use of multiple views to visualize multiple levels of information hierarchies prevents humans from " losing their place " in the taxonomy. Also, similarly to WireVis, GVis is an expert visualization, requiring a rather sizeable K 0 to focus effective Exploration. This may mitigate the cognitive overload effects of information on P and K in <ref type="figure" coords="6,186.72,273.37,28.98,8.21" target="#fig_0">Figure 2</ref>. A popup menu allows the user to view and explore publications on the spheres in the main view. This is perhaps not an optimum solution, as use of the menu is not intimate and can obstruct the field of view, which could threaten reasoning flow insularity and reduce the value of direct interaction. The visualization uses color and simple circles to highlight groups, insulating reasoning flow and focusing P. In addition, it employs the notion of a stretchable canvas, similar to Pad++ <ref type="bibr" coords="6,54.00,366.49,13.73,8.21">[30]</ref>, to handle detail at all scales. The latest version of GVis applies the precepts of knowledge visualization, relying on taxonomic and ontological representations of genomic knowledge to determine what to visualize for the task at hand. When combined with the stretchable canvas, important knowledge at any scale can be made visible to support the current reasoning task. Thus, for example, glyphs showing how many genes are annotated (and what types) are made visible at the genome or even the cluster level, even though the individual genes are sub-pixel at these levels. This provides important support for the human reasoning process. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Scalable Reasoning System (SRS)</head><p>In SRS, Pike et al. demonstrate nicely the capacity of visual analytics to aid in hypothesis generation and analysis <ref type="bibr" coords="6,255.12,521.77,13.73,8.21">[31]</ref>. For example, while searching by example in SRS is limited to text searches, queried information can become " reasoning artifacts " to be used as the basis of hypotheses, or as evidence for hypotheses represented in " thought chains. " The human is free to manipulate these artifacts directly in a sandbox-like information space, which encourages reasoning flow insularity and focuses P as described in Section 4. Additionally, by allowing the human to arrange artifacts, interaction becomes the principle objective. While SRS does not use multiple views to display information, by allowing rearrangement of artifacts, SRS encourages the human to organize them in a way that is meaningful to the individual. Additionally, SRS is more than a display. New knowledge can be created by creating relationships between reasoning artifacts. Thus, as the human generates hypotheses and their evidence, new knowledge that is created during the process is not lost, either to the current analysis, or to all other humans who use SRS after its creation. These new relationships are given editable confidence ratings, which aids in the weighing of evidence in hypothesis analysis. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>If we in the visual analytics community are to attain our aspiration of more effective, more human-perceptive visualizations, we must begin to understand how humans manipulate semantically-complex information. It is not enough to understand what is being seen and given attention. Nor is it appropriate to infer combinatorial, individually-variable reasoning heuristics from the more binary cognitive behaviors. Just as an understanding of perceptual cognition based on evaluative research have been employed in creation of information-valuable displays, a competent comprehension of reasoning, problem-solving, and decision-making must be employed in the development of mixed-initiative analytical interfaces. What we have proposed is not a derived working model, but is, as yet, a framework of human cognition. Our goal is to sketch out a system of " thinking about thinking " as a first step to interface interaction which is no longer just between user and data, but between human and computer partners, collaborating in the discovery of information and the creation and extension of knowledge. What we have proposed is a model still in its rudimentary stages, whose future will undoubtedly be marked by additions, corrections, and multiple series of empirical evaluation. In some ways, this work still has the emergent expectation and general outline of an excavation; we cannot pretend to have all of the answers, but we know we're digging at the right spot. And yet, it doesn't take a bulldozer to uncover that humans, like any other thinking system, behave in foreseeable ways. Thanks to decades of psychological research and some research in human-computer interaction, we aren't starting from scratch or relying on anecdotal evidence; we have, at the very least, a thorough understanding of how the model is shaped and where to go from here. We have been able to show extant examples of several of the HCM's submodels, but there is still work to be done. There are, as yet, no spontaneous methods of searching by analogical structure. Computer-aided discovery will require both a better understanding of learning interfaces as well as a comprehensive understanding of human iterative thought chaining. There is also the pesky problem of a unified theory of reasoning. Understanding the available fragmented research is a good foundation, but we must approach a more complete discernment of how all of the pieces work together in an information space to be better able to define and evaluate the best ways to insulate reasoning flow, mitigate cognitive load, facilitate appropriate task switching, and minimize attentional interference during the reasoning process. Finally, there is the issue of better understanding of the temporal coordination of human reasoning and computation and presentation of information. The temporal dynamics of control actions and cognitive processing were addressed early in the history of HCI with GOMS and keystroke analysis. However the dynamic coupling of scene gist perception, eye movements, attentional allocation, cognitive processing and microstrategic perception/action patterns <ref type="bibr" coords="6,422.40,666.49,15.04,8.21">[32] </ref>remains to be explored. Recent advances in the application of nonlinear dynamical modeling <ref type="bibr" coords="6,324.00,687.13,15.04,8.21">[33] </ref>may provide sufficient predictive validity for incorporation into models of sensemaking in visual analytics </p><p>These tasks are broad items on a bold agenda. But our evaluation has also uncovered multiple practical problems, and directed the search for how best to tackle them: what number of multiple views maximizes the cognitive return on investment, the best way for the computer to suggest unconsidered information without interrupting – or annoying – the human at work, and methods of maintaining the interactive process so as to keep cognition in the flow, whatever the task. Finally, it is also clear that there must be strong support for permitting and managing human annotations. But again, it all starts with daring to peek into reasoning's black box. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,75.36,693.91,190.88,7.33"><head>Figure 2. </head><figDesc>Figure 2. Van Wijk's model with our integrations in red </figDesc></figure>

			<note place="foot" n="3">.2.1 Multiple views When the information being explored is semantically rich, and could be visualized through a variety of categorization levels, it is often left to the discretion of the visualization developer as to which level merits the primary view. It is important to categorize information to aid the human in directing attention,</note>

			<note place="foot" n="3">.2.4 Insulation of Reasoning Flow One goal of intuitive visualization should be the facilitation of the flow of human reasoning. Once the human has focused cognitive resources in an area of interest, the visualization should not hamper the rhythm of reasoning until the human chooses to refocus resources elsewhere. This insulation can be achieved partially through direct interaction within context and intuitive computer-aided information discovery, as is discussed elsewhere in this section. Insularity is also aided, where possible, by an understanding of the temporal constraints of human perception and patterns of cognitive activity, adapting the timing of interface events and/or reducing the time required to retrieve necessary information from interface interaction [33]. Additionally, the process of insuring cognitive insulation would also encompass any interface process or rendering feature that has the potential to interfere with rather than inform the reasoning flow. In the terminology of the HCM, being in the zone allows the human collaborator to reason without attentional or cognitive impediment. And further, when the task becomes crushingly complex or when the human exhibits functional fixedness in thought, the computer provides a scaffolding of support, presenting the information within relevant context, suggesting what may have been overlooked, and keeping relevant information present.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS </head><p>This work was performed with support from the National Visualization and Analytics Center (NVAC TM ), a U.S. Department of Homeland Security Program, under the auspices of the SouthEast Regional Visualization and Analytics Center. Special thanks to Benjamin F. Green for helpful insights. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="8,54.00,293.87,9.36,7.13;8,90.00,293.87,176.76,7.13;8,90.00,302.99,191.44,7.13;8,90.00,312.11,179.10,7.13;8,90.00,321.47,109.74,7.13;8,54.00,330.59,9.36,7.13;8,90.00,330.59,164.80,7.13;8,90.00,339.71,163.88,7.13;8,90.00,349.07,192.54,7.13;8,90.00,358.19,134.70,7.13"  xml:id="b0">
	<analytic>
		<title level="a" type="main">Using a human cognition model in the creation of collaborative knowledge visualizations [2] A. Newell, You can&apos;t play 20 questions with nature and win: Projective comments on the papers of this symposium</title>
		<author>
			<persName>
				<forename type="first">]</forename>
				<forename type="middle">T M</forename>
				<surname>Green</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Ribarsky</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SPIE Defense + Security Visual Information Processing</title>
		<editor>Chase, W.G.</editor>
		<meeting>. of SPIE Defense + Security Visual Information essing<address><addrLine>Orlando, FL ; New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,90.00,367.31,170.04,7.13;8,90.00,376.67,164.64,7.13;8,90.00,385.79,127.26,7.13;8,54.00,394.91,9.36,7.13;8,90.00,394.91,174.00,7.13;8,90.00,404.27,144.78,7.13;8,54.00,413.39,9.36,7.13;8,90.00,413.39,162.88,7.13;8,90.00,422.51,164.70,7.13;8,90.00,431.87,123.18,7.13;8,54.00,440.99,9.36,7.13;8,90.00,440.99,149.00,7.13;8,90.00,450.11,176.68,7.13;8,90.00,459.47,114.54,7.13;8,54.00,468.59,9.36,7.13;8,90.00,468.59,163.26,7.13;8,90.00,477.71,89.82,7.13;8,54.00,487.07,9.36,7.13;8,90.00,487.07,160.84,7.13;8,90.00,496.19,179.08,7.13;8,90.00,505.31,23.58,7.13;8,54.00,514.67,9.36,7.13;8,90.00,514.67,189.90,7.13;8,90.00,523.79,79.74,7.13"  xml:id="b1">
	<analytic>
		<title level="a" type="main">Recent views of conceptual structure Reasoning the fast and frugal way: Models of bounded rationality [6] I. Biederman Recognition by components: A theory of human image understanding [7] R.A. Rensink, A dynamic representation of scenes</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Piaget Development To Adolescence</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Richardson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">L</forename>
				<surname>Sheldon ] K</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Komatsu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">G</forename>
				<surname>Gigerenzer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Goldstein</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pylyshyn, Seeing and Visualizing: It&apos;s not what you think</title>
		<editor>Hillsdale, NJ</editor>
		<meeting><address><addrLine>Bradford Books, Cambridge, MA ; Bradford Books ; Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press IT Press</publisher>
			<date type="published" when="1987" />
			<biblScope unit="page" from="3" to="18" />
		</imprint>
	</monogr>
	<note>[. 9] Z. Pylyshyn, Things and Places</note>
</biblStruct>

<biblStruct coords="8,54.00,532.91,13.44,7.13;8,90.00,532.91,197.10,7.13;8,54.00,542.27,13.44,7.13;8,90.00,542.27,120.28,7.13;8,90.00,551.39,154.14,7.13"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Visual routines [11] I. Rock. The logic of perception</title>
		<author>
			<persName>
				<forename type="first">]</forename>
				<forename type="middle">S</forename>
				<surname>Ullman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="97" to="159" />
			<date type="published" when="1984" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,54.00,560.51,13.44,7.13;8,90.00,560.51,174.12,7.13;8,90.00,569.87,105.42,7.13"  xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning to see faces and objects</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Tarr</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,55.92,578.99,13.44,7.13;8,90.00,578.99,193.41,7.13;8,90.00,588.11,142.62,7.13"  xml:id="b4">
	<analytic>
		<title level="a" type="main">Elements of a psychological decision theory</title>
		<author>
			<persName>
				<forename type="first">]</forename>
				<forename type="middle">J</forename>
				<surname>Kozielecki</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studia Psychologica</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="60" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,54.00,597.47,13.44,7.13;8,90.00,597.47,178.36,7.13;8,90.00,606.59,192.16,7.13;8,90.00,615.71,193.98,7.13;8,90.00,625.07,83.58,7.13"  xml:id="b5">
	<analytic>
		<title level="a" type="main">From models to rules: Mechanization of reasoning as a way to cope with cognitive overloading in combinatorial problems</title>
		<author>
			<persName>
				<forename type="first">]</forename>
				<forename type="middle">P</forename>
				<surname>Cherubini</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Mazzocco</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="223" to="243" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,54.00,634.19,13.44,7.13;8,90.00,634.19,189.40,7.13;8,90.00,643.31,179.44,7.13;8,90.00,652.67,115.02,7.13;8,54.00,661.79,13.44,7.13;8,90.00,661.79,180.88,7.13;8,90.00,670.91,170.92,7.13;8,90.00,680.27,115.02,7.13"  xml:id="b6">
	<analytic>
		<title level="a" type="main">The magic number seven, plus or minus two: Some limits on our capacity for processing information On the failure to eliminate hypotheses in a conceptual task</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">A</forename>
				<surname>Miller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="81" to="97" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,90.00,689.39,194.44,7.13;8,90.00,698.51,188.56,7.13;8,90.00,707.87,122.22,7.13"  xml:id="b7">
	<analytic>
		<title level="a" type="main">On the conflict between logic and belief in syllogistic reasoning</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">B T</forename>
				<surname>St</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Evans</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Varston</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Pollard</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memory and Cognition</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="295" to="306" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,360.00,55.79,176.22,7.13;8,362.93,64.91,163.03,7.13;8,360.00,74.27,187.80,7.13;8,360.00,83.39,167.10,7.13;8,324.00,92.51,13.44,7.13;8,360.00,92.51,191.04,7.13;8,360.00,101.87,135.42,7.13"  xml:id="b8">
	<analytic>
		<title level="a" type="main">Guidelines for using multiple views in information visualization The Psychology of Intelligence Analysis Center for the Study of Intelligence</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">Q W</forename>
				<surname>Baldonado</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Woodruff</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">J</forename>
				<surname>Kuchinsky ] R</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Heuer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Working Conference on Advanced Visual Interfaces</title>
		<meeting>Working Conference on Advanced Visual Interfaces<address><addrLine>Palermo, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,324.00,110.99,13.44,7.13;8,360.00,110.99,163.24,7.13;8,360.00,120.11,181.98,7.13;8,324.00,129.47,13.44,7.13;8,360.00,129.47,194.70,7.13;8,360.00,138.59,184.12,7.13;8,360.00,147.71,196.36,7.13;8,360.00,157.07,190.28,7.13;8,360.00,166.19,183.42,7.13;8,360.00,175.31,180.54,7.13;8,360.00,184.67,18.30,7.13;8,324.00,193.79,13.44,7.13;8,360.00,193.79,163.00,7.13;8,360.00,202.91,171.76,7.13;8,360.00,212.27,183.96,7.13;8,360.00,221.39,190.62,7.13;8,360.00,230.51,86.28,7.13;8,324.00,239.87,13.44,7.13;8,360.00,239.87,166.86,7.13;8,360.00,248.99,171.60,7.13;8,360.00,258.11,177.48,7.13;8,360.00,267.47,183.16,7.13;8,360.00,276.59,187.50,7.13;8,360.00,285.71,128.46,7.13;8,324.00,295.07,13.44,7.13;8,360.00,295.07,125.82,7.13;8,324.00,304.19,13.44,7.13;8,360.00,304.19,187.02,7.13;8,360.00,313.31,165.48,7.13;8,360.00,322.67,193.36,7.13;8,360.00,331.79,183.90,7.13;8,360.00,340.91,23.58,7.13"  xml:id="b9">
	<analytic>
		<title level="a" type="main">WireVis: Visualization of categorical, time-varying data from financial transactionsJigsaw: Supporting Investigative Analysis through Interactive Visualization Visualizing the nonvisual: spatial analysis and interaction with information from text documents</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">J</forename>
				<surname>Van Wijk</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Chang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ghoniem</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Kosara</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Ribarsky</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Yang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Suma</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Ziemkiewicz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Kern</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Sudjianto</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Stasko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Gorg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Liu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Singhal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Vis 05 Proceedings of the 2007 IEEE Symposium on Visual Analytics Science and Technology Sacramento, CA Proceedings of 2007 IEEE Symposium on Visual Analytics Science and Technology INFOVIS &apos;95: Proceedings of the 1995 IEEE Symposium on Information V visualization Semantic Image Browser: Bridging Information Visualization with Automated Intelligent Image Analysis Proceedings of IEEE VAST 2006</title>
		<editor>23] J. A.Wise, J. J. Thomas, K. Pennock, D. Lantrip, M. Pottier, A. Schur, and V. Crow J. Yang, J. Fan, D. Hubball, Y. Gao, H. Luo, W. Ribarsky, and M. Ward</editor>
		<meeting>Vis 05 the 2007 IEEE Symposium on Visual Analytics Science and Technology Sacramento, CA 2007 IEEE Symposium on Visual Analytics Science and Technology INFOVIS &apos;95: the 1995 IEEE Symposium on Information V visualization Semantic Image Browser: Bridging Information Visualization with Automated Intelligent Image Analysis IEEE VAST 2006<address><addrLine>Sacramento, CA ; Remco Chang</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society IEEE Computer Society</publisher>
			<date type="published" when="1995-10" />
			<biblScope unit="page" from="79" to="86155" />
		</imprint>
	</monogr>
	<note>[. 24] Private communication</note>
</biblStruct>

<biblStruct coords="8,324.00,350.27,13.44,7.13;8,360.00,350.27,157.74,7.13;8,363.39,359.39,184.35,7.13;8,360.00,368.51,121.50,7.13"  xml:id="b10">
	<monogr>
		<title level="m" type="main">NewsLab:Exploratory Broadcast News Video Analysis</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ghoniem</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Luo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Yang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Ribarsky</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="123" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,324.00,377.87,13.44,7.13;8,360.00,377.87,185.82,7.13;8,360.00,386.99,176.44,7.13;8,360.00,396.11,188.60,7.13;8,360.00,405.47,41.52,7.13;8,324.00,414.59,13.44,7.13;8,360.00,414.59,104.94,7.13;8,360.00,423.71,138.76,7.13;8,360.00,433.07,166.80,7.13;8,360.00,442.19,143.88,7.13;8,360.00,451.31,174.68,7.13;8,360.00,460.67,120.60,7.13;8,324.00,469.79,13.44,7.13;8,360.00,469.79,165.42,7.13;8,360.00,478.91,186.84,7.13;8,360.00,488.27,189.08,7.13;8,360.00,497.39,78.06,7.13"  xml:id="b11">
	<analytic>
		<title level="a" type="main">Investigative Visual Analysis of Global TerrorismLegible Cities: Focus-Dependent Multi-Resolution Visualization of Urban Relationships GVis: A Scalable Visualization Framework for Genomic Data</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Wang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Chang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Kosara</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Ribarsky</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Smarick</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">]</forename>
				<forename type="middle">R</forename>
				<surname>Miller28</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Chang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Wessel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Kosara</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Sauda</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Ribarsky</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EuroVis 2005 p</title>
		<editor>29] J. Hong, D. H. Jeong, C. D. Shaw, W. Ribarsky, M. Borodovsky, and C. Song</editor>
		<meeting>EuroVis 2005 p<address><addrLine>Sacramento, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="191" to="198" />
		</imprint>
	</monogr>
	<note>Accepted. for publication</note>
</biblStruct>

<biblStruct coords="8,324.00,506.51,13.44,7.13;8,360.00,506.51,187.72,7.13;8,361.92,515.63,190.64,7.13;8,360.00,524.99,67.68,7.13;8,324.00,534.11,13.44,7.13;8,360.00,534.11,192.36,7.13;8,360.00,543.23,162.84,7.13;8,360.00,552.59,179.72,7.13;8,360.00,561.71,192.68,7.13;8,360.00,570.83,91.26,7.13"  xml:id="b12">
	<analytic>
		<title level="a" type="main">Pad++: A zooming graphical interface for exploring alternate interface physics Scalable visual reasoning: supporting collaboration through distributed analysis</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">B</forename>
				<surname>Bederson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D P</forename>
				<surname>Hollan31 ] A</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Pike</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>May</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Baddeley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Riensche</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Bruce</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Younkin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">:UIST &apos;94 Proceedings of .International Symposium on Collaborative Technologies and Systems (IEEE)</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="17" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,325.92,580.19,13.44,7.13;8,360.00,580.19,167.72,7.13;8,360.00,589.31,194.76,7.13;8,360.00,598.43,187.72,7.13;8,360.00,607.79,186.72,7.13;8,324.00,616.91,13.44,7.13;8,360.00,616.91,166.86,7.13;8,360.00,626.03,72.54,7.13"  xml:id="b13">
	<analytic>
		<title level="a" type="main">Milliseconds Matter: An introduction to microstrategies and to their use in describing and predicting interactive behavior The Continuity of Mind</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">D</forename>
				<surname>Gray</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Boehm-Davis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experiment Psychology: Applied</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="322" to="335" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,324.00,635.39,13.44,7.13;8,360.00,635.39,178.08,7.13;8,360.00,644.51,164.08,7.13;8,360.00,653.63,169.32,7.13;8,360.00,662.99,161.82,7.13"  xml:id="b14">
	<analytic>
		<title level="a" type="main">Computational models of information scentfollowing in a very large browsable text collection</title>
		<author>
			<persName>
				<forename type="first">]</forename>
				<forename type="middle">P</forename>
				<surname>Pirolli</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Human Factors in Computing Systems, CHI &apos;97</title>
		<meeting>the Conference on Human Factors in Computing Systems, CHI &apos;97<address><addrLine>Atlanta, GA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
