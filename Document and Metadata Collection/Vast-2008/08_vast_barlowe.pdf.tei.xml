<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T13:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multivariate Visual Explanation for High Dimensional Datasets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Scott</forename>
								<surname>Barlowe</surname>
							</persName>
							<affiliation>
								<orgName type="department" key="dep1">Dept of Computer Science</orgName>
								<orgName type="department" key="dep2">Dept of Physics and Optical Science University of North Carolina at Charlotte</orgName>
								<orgName type="institution">University of North Carolina at Charlotte</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Tianyi</forename>
								<surname>Zhang</surname>
							</persName>
							<affiliation>
								<orgName type="department" key="dep1">Dept of Computer Science</orgName>
								<orgName type="department" key="dep2">Dept of Physics and Optical Science University of North Carolina at Charlotte</orgName>
								<orgName type="institution">University of North Carolina at Charlotte</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Yujie</forename>
								<surname>Liu</surname>
							</persName>
							<affiliation>
								<orgName type="department" key="dep1">Dept of Computer Science</orgName>
								<orgName type="department" key="dep2">Dept of Physics and Optical Science University of North Carolina at Charlotte</orgName>
								<orgName type="institution">University of North Carolina at Charlotte</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Jing</forename>
								<surname>Yang</surname>
							</persName>
							<affiliation>
								<orgName type="department" key="dep1">Dept of Computer Science</orgName>
								<orgName type="department" key="dep2">Dept of Physics and Optical Science University of North Carolina at Charlotte</orgName>
								<orgName type="institution">University of North Carolina at Charlotte</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName>
								<forename type="first">Donald</forename>
								<surname>Jacobs</surname>
							</persName>
							<email>djacobs1@uncc.edu</email>
							<affiliation>
								<orgName type="department" key="dep1">Dept of Computer Science</orgName>
								<orgName type="department" key="dep2">Dept of Physics and Optical Science University of North Carolina at Charlotte</orgName>
								<orgName type="institution">University of North Carolina at Charlotte</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Multivariate Visual Explanation for High Dimensional Datasets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>visual analysis, multivariate analysis, dimension re-</term>
					<term>duction, multivariate model construction, multivariate visualiza-</term>
					<term>tion</term>
					<term>Index Terms:</term>
					<term>H52 [Information Interfaces and Presenta-</term>
					<term>tion]: User Interfaces—User Centered Design; G3 [Mathematics</term>
					<term>of Computing]: Probability and Statistics—Multivariate Statistics</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Understanding multivariate relationships is an important task in multivariate data analysis. Unfortunately, existing multivariate vi-sualization systems lose effectiveness when analyzing relationships among variables that span more than a few dimensions. We present a novel multivariate visual explanation approach that helps users interactively discover multivariate relationships among a large number of dimensions by integrating automatic numerical differentiation techniques and multidimensional visualization techniques. The result is an efficient workflow for multivariate analysis model construction , interactive dimension reduction, and multivariate knowledge discovery leveraging both automatic multivariate analysis and interactive multivariate data visual exploration. Case studies and a formal user study with a real dataset illustrate the effectiveness of this approach.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The analysis of multivariable behavior and model construction for quantitative relationships among a large number of variables is important in a myriad of applications. For example, economic forecasting is dependent on the relationships among unemployment, interest rates, consumer confidence, and inflation. Predicting solvent formulation for protein storage, an example important to pharmaceutical technology, depends on the nature of the protein, and the temperature, pH, ionic strength, and co-solute concentrations of the solvent. Often, it is desirable to identify significant affecting factors from empirically accumulated data, and discover hidden relationships that transcend a neural network approach. To deduce an explanation of the behavior of monitored characteristics, multivariate data must be examined in context with all attributes simultaneously. Multivariate analysis is a mature topic in the field of statistics. Numerous statistical methods are available, such as linear regres- sion <ref type="bibr" coords="1,72.53,562.48,9.52,8.20" target="#b4">[6]</ref>, generalized additive models <ref type="bibr" coords="1,195.66,562.48,13.74,8.20" target="#b9">[11]</ref>, and response surface analysis <ref type="bibr" coords="1,85.52,572.44,9.52,8.20" target="#b1">[3]</ref> . Despite ample computational power of modern computers , application of automatic statistical methods for constructing correlation models scales poorly to increasingly massive, high dimensional multivariate datasets. Two important reasons are that analysts find it difficult to apply domain knowledge critical for understanding complex data, and their perceptual ability to discern relationships is lost when using an automatic analysis approach. Information visualization approaches allow users to gain insights from complex abstract data using their perceptual abilities and domain knowledge, but are they helpful for multivariate analysis? In <ref type="figure" coords="1,317.95,310.95,29.56,8.20">Figure 1</ref>: A 4-d dataset in (a) a pixel-oriented display, (b) parallel coordinates, and (c) a scatterplot matrix. (a) and (b) were generated using XmdvTool <ref type="bibr" coords="1,380.51,330.88,13.74,8.20" target="#b26">[28]</ref>. the field of information visualization, a major category of techniques named multivariate visualization does exist. It aims to help users analyze multivariate datasets. However, existing multivariate visualization techniques are quite limited in helping multivariate analysis when there are more than three variables involved. For example , in <ref type="figure" coords="1,354.64,414.10,29.48,8.20">Figure 1</ref>, a four variable dataset with one thousand data items is shown in a pixel-oriented display <ref type="bibr" coords="1,468.33,424.06,13.74,8.20" target="#b14">[16]</ref>, parallel coordinates <ref type="bibr" coords="1,317.95,434.02,13.74,8.20" target="#b11">[13]</ref>, and scattorplot matrices <ref type="bibr" coords="1,426.81,434.02,9.52,8.20" target="#b3">[5]</ref> . These are among the most popular , most widely used multivariate visualization techniques. However , can you tell from any of the displays the simple relationship among the four dimensions: y 0 = x 0 x 1 + x 2 ? Just as Amar and Stasko pointed out in their Infovis 2004 paper <ref type="bibr" coords="1,490.53,473.88,9.52,8.20" target="#b0">[1]</ref> , there is an urgent need for multivariate visualization systems to support determination of correlation among multiple variables. A Worldview Gap, namely the gap between what is being shown and what actually needs to be shown to draw a straightforward representational conclusion for decision making <ref type="bibr" coords="1,420.06,523.69,9.52,8.20" target="#b0">[1]</ref>, is to be filled. In this paper, we present our preliminary research toward supporting determination of correlation among multiple dimensions in multivariate visualization systems to fill the Worldview Gap. We call this type of research Multivariate Visual Explanation (MVE), following the multivariate explanation notion proposed by Amar and Stasko <ref type="bibr" coords="1,358.31,583.75,9.52,8.20" target="#b0">[1]</ref> . An MVE system explicitly reveals the hidden multivariate relationships to users in a straightforward way. In particular, the MVE techniques presented in this paper are targeted at answering the following questions important to multivariate analysis: Given a multivariate relationship, how does an independent variable affect the dependent variable in the context of the remaining independent variables? Is the effect positive or negative? Is the effect strong or weak? Are there any independent variables closely entangled in their effects and thus need to be considered together in the analysis? Can we identify ignorable variables and infer interdependence between variables to achieve rational dimension reduction? From strategic analysis, can we construct a model to quantify the relationships between dependent and independent variables? A system that can answer the above questions will not only <ref type="figure" coords="2,220.45,107.57,28.91,8.20">Figure 1</ref>, it is almost impossible to do this job using pure visualization techniques. A natural approach is to integrate numerical methods with visualization techniques. In our preliminary work, we chose to use partial derivatives calculated by a numerical differentiation method to reveal the local effects of the independent variables on the dependent variables, and allow users to gain a global view of the effects through multivariate visualization techniques. We selected this approach for three reasons. First, partial derivatives convey intuitive meanings and are familiar to analysts in domains such as physics and engineering . Second, partial derivatives can be easily displayed together with the original data in existing multivariate visualization techniques . Third, compared with other analysis methods that generate summary results, partial derivatives reveal multivariate relationship details across the whole multidimensional space and the users can still gain summarized information through visual aggregation. Our approach consists of the following components: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="147"></head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Partial derivative calculation and inspection</head><p> : A numerical differentiation method is used to calculate the partial derivatives of the dependent variables on their independent variables. The error bounds of the partial derivatives are visually examined (see <ref type="figure" coords="2,270.62,323.21,23.41,8.20;2,54.00,333.18,4.48,8.20">Figure  3</ref>for an example) to ensure the quality of the partial derivatives to be used in the following partial derivative visual exploration. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visual exploration of partial derivatives: </head><p>The partial derivatives are visually presented with the variables to help detect correlation among the variables. To reduce clutter, a step by step visual exploration pipeline is used to guide users in analyzing different types of correlations in different steps. Different views, such as the First Order Partial Derivative Histograms (see <ref type="figure" coords="2,241.41,408.93,29.84,8.20" target="#fig_2">Figure 4</ref>for an example) and the Independent Variable-First Order Partial Derivative Scatterplot Matrices (see <ref type="figure" coords="2,163.72,428.86,34.87,8.20" target="#fig_5">Figure 7c</ref> for an example), are provided in these steps for determining different types of correlations. This visual exploration process is tightly integrated into a multivariate visualization system (see <ref type="figure" coords="2,181.25,459.14,31.18,8.20" target="#fig_4">Figure 6</ref>for an example). All partial derivative views are coordinated with other multivariate visualizations available in the system such as parallel coordinates and glyphs. Thus users can perform interactions such as interactive dimension selection and data selection from the partial derivative views and propagate the selection results to other views in the system in support of meaningful dimension reduction and data filtering . The coordinated views and the interactions available in them such as N-D brushing <ref type="bibr" coords="2,133.09,538.84,14.94,8.20" target="#b21">[23] </ref>also enable flexible visual exploration of the partial derivative views. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interactive multivariate model construction</head><p> : An interactive model construction interface is provided to allow users to interactively construct correlation models for high dimensional datasets (see <ref type="figure" coords="2,102.69,594.67,30.82,8.20" target="#fig_5">Figure 7</ref>for an example). Coupled with the step by step partial derivative visual exploration pipeline, the interface allows users to generate models that can be used in automatic multivariate analysis which are useful for more than acquiring a qualitative impression about the correlations. The major contributions of this paper are: @BULLET A novel MVE approach that is tightly integrated into a multivariate visualization system is proposed. It supports determination of correlation among variables in high dimensional datasets. It leverages the visual exploration in other views provided by the system by allowing users to perform dimension reduction and data filtering using the MVE insights. It also allows users to interactively construct multivariate models for automatic analysis; @BULLET A novel visualization approach is proposed to examine the quality of the partial derivatives. A novel visualization pipeline and informative displays for examining multivariate correlations and constructing multivariate models are pro- posed; @BULLET A formal user study and case studies have been conducted. The case studies reveal how the proposed approach supports users to effectively detect multivariate relationships. The user study compared the proposed approach with scatterplot matrices in revealing multivariate relationships in a real dataset and its result was strongly in favor of the proposed approach. The rest of the paper is organized as follows: Section 2 summarizes the related work; Section 3 briefly introduces the partial derivative calculation method we use and presents our visual differentiation error examination approach; Section 4 describes the visual exploration of the partial derivatives; Section 5 demonstrates the interactive model construction process; Section 6 presents the user study we conducted; and Section 7 gives our conclusions and future work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>There exist many automatic techniques for multivariate analysis. For example, regression analysis <ref type="bibr" coords="2,441.25,324.93,10.45,8.20" target="#b4">[6] </ref> establishes a linear relationship between an independent variable and a dependent variable in its simplest case. It has been extended to include multiple independent variables and describe more complex relationships, such as generalized additive models <ref type="bibr" coords="2,435.30,364.78,14.93,8.20" target="#b9">[11] </ref> for detecting nonlinear relationships . Response surface analysis <ref type="bibr" coords="2,453.06,374.75,10.45,8.20" target="#b1">[3] </ref>is a method of discerning multivariate relationships through model fitting and 3d graphs <ref type="bibr" coords="2,540.80,384.71,13.74,8.20" target="#b15">[17]</ref>. Our approach is different from the automatic techniques in that it enables users to intuitively examine multivariate relationships in detail by tightly integrating numerical approaches with interactive visual explorations. The multivariate analysis tool we use is differentiation, which can establish detailed quantifiable relationships among multiple variables. Differentiation can be conducted numerically for discrete data items. Numerical differentiation methods include finite, polynomial interpolation, operator, lozenge diagrams, and undetermined coefficients <ref type="bibr" coords="2,387.90,484.50,13.74,8.20" target="#b18">[20]</ref>. Other approaches span spline numerical differentiation, regularization, and automatic differentiation. Recently , the contribution that nonuniform fast Fourier transforms <ref type="bibr" coords="2,317.95,514.39,14.94,8.20" target="#b20">[22] </ref>and wavelet transforms <ref type="bibr" coords="2,424.27,514.39,14.94,8.20" target="#b24">[26] </ref> can have in numerical differentiation has been examined. Numerical differentiation is intuitive, flexible, powerful, and is widely used in applications such as engineering and the physical sciences. For example, it was used in cell cycle network research to prove the usefulness of mathematical models in molecular networks <ref type="bibr" coords="2,427.27,564.20,13.74,8.20" target="#b23">[25]</ref> . Image processing has also benefited from partial derivatives. Partial derivatives have been used as image descriptors through higher-order histograms <ref type="bibr" coords="2,503.27,584.13,13.74,8.20" target="#b19">[21]</ref>. However, these and other similar approaches are typically relegated to specific application domains and do not provide a general framework in which partial derivatives and their visualizations are used in dynamic dimension reduction and model building. To the best of our knowledge, the MVE approach we proposed is among the first efforts toward using numerical differentiation techniques to enhance high dimensional data visualization. There exist a few efforts toward understanding the relationships between pairs of dimensions in existing multivariate visualization systems. Among them, rank-by-feature <ref type="bibr" coords="2,468.07,683.92,14.94,8.20" target="#b22">[24] </ref> calculates measurements such as correlation and uniformity between pairs of dimensions and allows users to select two dimensional projections of a high dimensional dataset according to these measurements. Value and Relation display <ref type="bibr" coords="3,132.87,57.76,14.94,8.20" target="#b27">[29] </ref> calculates the pair wise correlation between each pair of dimensions and visually presents the correlations to users through dimension positions in a two dimensional display using multi-dimensional scaling. Some traditional multivariate visualization methods, such as scatterplot matrices <ref type="bibr" coords="3,267.85,97.61,10.45,8.20" target="#b3">[5] </ref>and parallel coordinates <ref type="bibr" coords="3,128.19,107.57,13.74,8.20" target="#b11">[13]</ref> , can also visually reveal correlations between pairs of dimensions. However, few approaches effectively convey the correlation between two dimensions in the context of other dimensions. Among the few exceptions, the conditional scatterplot matrix <ref type="bibr" coords="3,106.30,147.43,10.46,8.20" target="#b6">[8] </ref>depicts partial correlations among variables, but it is hard to scale to high dimensional datasets. Model construction and selection, namely the construction and selection of appropriate predictive or explanatory models for automatic multivariate analysis, is an important research topic in multivariate analysis since the effectiveness and efficiency of a large portion of multivariate analysis algorithms heavily depend on the underlying model used. Numerous algorithms have been proposed for model construction and model selection. Examples of model selection methods include bootstrap and backward elimination <ref type="bibr" coords="3,281.35,237.46,9.52,8.20" target="#b5">[7]</ref>, nonlinear bounded-error estimation <ref type="bibr" coords="3,183.34,247.42,9.52,8.20" target="#b2">[4]</ref>, and visualization <ref type="bibr" coords="3,261.64,247.42,13.74,8.20" target="#b10">[12]</ref>. For high dimensional datasets, most automatic algorithms lose their effectiveness and efficiency due to the large number of candidate models and the number of dimensions per model. Our approach provides users a transparent model construction process with the help of both automatic numerical differentiation calculation and human perceptional abilities and domain knowledge. Our approach is different from previous visual model selection approaches, such as D2MS <ref type="bibr" coords="3,91.17,327.13,13.74,8.20" target="#b10">[12]</ref>, by integrating visualization into the preprocessing steps through which users can interactively filter unimportant di- mensions. Dimension reduction is an important topic for a wide range of research fields such as data compression, pattern recognition, cluster and outlier detection, multivariate analysis, as well as visualization . For example, dimension reduction can reduce the number of candidate models or the number of dimensions per model and thus leverage the model construction and selection process in multivariate analysis. In visualization, projecting a high dimensional dataset to a lower dimensional space can also effectively reduce the clutter of visualizations. Commonly used dimension reduction techniques include principle component analysis <ref type="bibr" coords="3,191.71,447.04,13.74,8.20" target="#b13">[15]</ref> , multidimensional scal- ing <ref type="bibr" coords="3,67.46,457.00,13.74,8.20" target="#b17">[19]</ref>, and Self Organizing Maps <ref type="bibr" coords="3,182.14,457.00,13.74,8.20" target="#b16">[18]</ref>. Major drawbacks of these automatic techniques are that they yield results that have little intuitive meaning to users and that they may yield huge information loss for high dimensional datasets. A few visualization approaches, such as VHDR <ref type="bibr" coords="3,91.88,496.84,13.74,8.20" target="#b28">[30]</ref>, have been proposed allowing users to interactively select dimensions for constructing lower dimensional spaces. Unfortunately , only pairwise dimensional relationships are considered in VHDR and thus its capability of manual dimension reduction is largely limited. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PARTIAL DERIVATIVE CALCULATION AND INSPECTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Partial derivative calculation</head><p>Our multivariate visual explanation approach is based upon partial derivatives calculated using numerical differentiation. The derivative of a dependent variable, y, as the independent variable, x, changes is approximated as Δy/Δx. The relationship is geometrically interpreted as a local slope of the function y(x). This idea is extended to partial derivatives where multiple independent variables are analyzed. In partial differentiation, the derivative of the variable of interest is taken while all other independent variables are held constant. This can be repeated until a quantitative relationship to the dependent variable can be found for each independent variable. For example, partial differentiation of the </p><formula>lationship y = x 1 x 2 + x 3 yields y x 1 = x 2 , y x 2 = x 1 , and y x 3 = 1. Here y x i ≡ ∂ y/∂ x i . </formula><p> Furthermore, the non-zero second order partial derivatives yield y x 1 ,There exist many methods to obtain partial derivatives <ref type="bibr" coords="3,531.04,208.98,9.71,8.20" target="#b7">[9,</ref><ref type="bibr" coords="3,543.80,208.98,10.64,8.20" target="#b12"> 14]</ref>, and thus it is not the focus of this paper. We only briefly introduce the partial derivative calculation for completeness. We extract a local tangent on every point in a high-dimensional space. For point P specified by n variables, x 0 , x 2 ...x n−1 , the set of neighboring points within a threshold t is defined as: </p><formula>x 2 = y x 2 ,x 1 = 1 where y x i ,x j ≡ ∂ y x i /∂ x j . </formula><formula>Set(P) = {p||P − p 2 &lt; t} (1) </formula><p>The data items are segmented into small groups of neighboring points determined by a threshold based on dimension value ranges and adjusted according to the amount of acceptable error. A tangent line for each central point is calculated based on its neighbors using linear regression for every data entry and independent variable . To find higher order derivatives, the set of values consisting of the slopes of tangent lines are repeatedly substituted in place of the original set of points. Although the assumption of continuity may fail for discrete data, numerical differentiation often continues to provide useful characteristics in exploring relationships. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Partial Derivative Inspection</head><p>Errors can be introduced in the partial derivative calculation, as shown in <ref type="figure" coords="3,352.33,427.92,30.98,8.20" target="#fig_0">Figure 2</ref>. In Equation 1, we have to trade off between the significance of errors and the speed of the algorithm by setting the boundary searching threshold t. In addition, care must be taken to ensure that the function under consideration is well behaved being differentiable at the points of analysis. Since errors can overwhelm users with distracting and inaccurate information in the following visual explorations, we propose a novel visualization approach for partial derivative quality inspection. This approach not only allows users to visually examine the quality of partial derivatives calculated , but also enables users to filter out low quality partial derivatives from the following visual explorations. Furthermore, users can adjust the partial derivative calculation parameters to improve the overall quality based on the visual feedbacks provided by the visualization. First, we calculate the partial derivative error for each point. Among choices such as the sum of squared errors, the sum of absolute errors, and the maximum value of errors, we find that the sum of squared errors achieves the best performance for many real datasets in practice. The sum of squared errors for P is calculated using Set (P) and is expressed as: </p><formula>E = ∑ (y i − y i ) 2 (2) </formula><p> Then errors are visually shown using an extension of parallel coordinates to allow users to interactively examine the errors. In <ref type="figure" coords="4,74.20,228.33,29.55,8.20">Figure 3</ref>, the data items are colored by the average errors of their derivatives. Each horizontal blue bar attached to a projection of a data item on an axis indicates the first order partial derivative error at that data item. The longer the bar, the larger the error is. It can be seen from the figure that there are large errors around the segmentation boundary. The error display reminds users to drop derivatives with large errors in the MVE. Since errors can often be reduced by adjusting the threshold t used in Equation 1, this visualization is useful in helping improve the quality of the derivatives calculated by adjusting t. Besides this method, the errors can be treated as extra dimensions and visualized together with the variables. <ref type="figure" coords="4,234.24,338.60,34.73,8.20" target="#fig_4">Figure 6a</ref>shows such an approach where x0 Error and x1 Error give the errors of y x 0 and y x 1 respectively. The data items with low quality derivatives were unselected from the display so that users can focus on high quality derivatives in the visual exploration. They can also be filtered out to avoid distracting the users. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">VISUAL EXPLORATION OF PARTIAL DERIVATIVES</head><p>After the partial derivatives are calculated and inspected, they need to be visually presented to users in the context of the original data to facilitate users in detecting correlation among multiple variables. This is a challenging task: the partial derivatives are a data body that can be larger than the original data; and the data volume is even larger when the partial derivatives are considered together with the original data. The following example shows how large the data volume will be: Assume that there is a 4 dimensional dataset that contains one dependent variable, namely y, and 3 independent variables, namely x 0 , x 1 , and x 2 , and the calculated partial derivatives up to the second order. Then 9 extra dimensions will be added into the dataset that include: </p><formula>y x 0 , y x 1 , y x 2 , y x 0 ,x 0 , y x 1 ,x 1 , y x 2 ,x 2 , y x 0 ,x 1 , y x 0 ,x 2 , and y x 1 ,x 2 . </formula><p>Thus, rather than exploring a 4 dimensional dataset, we now need to explore a 13 dimensional dataset! This number increases significantly when more variables are considered. Before we reached our final solution, we had a few failed trials on visualizing the extended datasets that augmented the partial derivatives. Our first attempt was a modified scatterplot matrix . We tried to dedicatedly arrange the scatterplots of all pairs of dimensions in the extended dataset in the same display to reveal correlations. Since there were too many scatterplots that cluttered the display, we employed the graph-theoretic scagnostics technique <ref type="bibr" coords="4,54.00,644.05,14.94,8.20" target="#b25">[27] </ref>to capture the outliers, shape, trend, density, and coherence of the scatterplots and colored them according to a measurement of user interest. However, our informal user studies showed that it was a failed trial since users were completely overwhelmed by so many scatterplots and so many possible correlations among the variables. An important lesson from this attempt is that the various relationships among the partial derivatives and variables reveal different types of correlations among the variables. We should not mix once the correlation between an independent variable and the dependent variable is decided, that independent variable will be excluded from further steps so that the users can focus on the variables with unknown correlations. For each step in the visual exploration pipeline, one or more views are provided. The view for the first step is a highly condensed first order partial derivative histogram display. <ref type="figure" coords="4,422.66,434.27,29.68,8.20" target="#fig_2">Figure 4</ref>shows the histogram view for a synthesized dataset named ThreeSix. It has 3 dependent variables (y 0 -y 2 ), 6 independent variables (x 0 -x 5 ), and 1000 data points. In this figure, all independent variables are examined together for all the dependent variables. In the top row are the histograms of the dependent variables. In the left most column are the histograms of the independent variables. The rest of the views are histograms of the first order partial derivatives ∂ (y i )/∂ (x j ), where y i is the dependent variable whose histogram is shown in the top row for the same column and x j is the independent variable whose histogram is shown in the left most column for the same row. The histograms of the first order partial derivatives reveal important information about the data: a first order partial derivative dimension with mostly positive/negative values reveals a positive/negative effect of the independent variable on the dependent variable. If the scales are properly selected, the significance of the independent variables on the same dependent variable can be compared by the shapes of their partial derivative histograms. In our approach, we set the scales in this way: we assume that all values of the independent variables from which the analyzed datasets are sampled are randomly distributed in known value ranges, and the variables are normalized into <ref type="bibr" coords="4,437.49,644.06,9.71,8.20">[0,</ref><ref type="bibr" coords="4,449.43,644.06,7.47,8.20" target="#b0"> 1] </ref>ranges from their real value ranges. Since for a given data point, the value of a first order partial derivative reflects the change of the dependent variable per unit change of the independent variable when all the other independent variables are held constant, the higher the absolute values of the partial derivatives from the derivative calculation, the stronger the independent variable impacts the dependent variable. To enable users to directly compare the absolute derivative values for <ref type="figure" coords="5,54.00,332.02,29.39,8.20">Figure 5</ref>: The Boston Neighborhood Housing Price dataset <ref type="bibr" coords="5,270.02,332.02,10.46,8.20">[2] </ref>in (a) a scatterplot matrix and (b) first order partial derivative histogram. (a) was generated using XmdvTool <ref type="bibr" coords="5,169.74,341.99,13.74,8.20" target="#b26">[28]</ref>. paring the variable impacts, the value ranges of all the derivative histograms are set to be the same. Although in many real applications the random distribution assumption does not hold and we simply normalize the independent variables by their actual value range in our system, the histogram view still allows users to estimate and compare the impacts of the independent variables. The histograms of the dependent variables and independent variable provided in the histogram view not only serve as an index of the derivatives, but also allow users to examine the distribution of the independent variables for judging their impacts on the dependent variables observed from the partial derivative histograms. <ref type="figure" coords="5,63.96,484.95,32.66,8.20">Figure 5</ref>shows an interesting example with a real dataset, namely the Boston Neighborhood Housing Price (BNHP) dataset <ref type="bibr" coords="5,54.00,504.87,9.52,8.20">[2]</ref>, which is a corrected version of the Boston house-price data <ref type="bibr" coords="5,54.00,514.83,13.74,8.20" target="#b8">[10]</ref>. It contains 506 data items and 14 variables. A dummy variable with huge derivative errors is dropped from the display although it is considered when calculating the derivatives of other variables. The variables displayed are listed as follows: We view Med-Price as the dependent variable and the others as the independent variables. The correlation among them is explored. Figures 5a and 5b show the BNHP dataset displayed in a scatterplot matrix and the proposed histogram view respectively. In the histograms, values increase from the left side to the right side, and the red lines indicate the zero value. Many correlations hidden in the scatterplot matrix are explicitly revealed in the histogram view. For example, we found that PTRATIO had a negative correlation with housing prices, i.e., the higher the pupil-teacher ratio by town, the lower the housing prices. Also, the accessibility to radial highways (RAD) had a positive correlation with the housing prices, and the weighted distance to the five employment centers (DIS) had a negative correlation with the housing prices. Such correlations can hardly be detected from the scatterplot matrix. Assuming that users want to reduce the number of dimensions displayed in a coordinated display to reduce clutter, it is convenient to accomplish this from the histogram view: since INDUS and AGE show pretty small effects on the housing prices, they are not interesting to the users and thus can be removed. The users can perform the dimension reduction easily from the histogram view by clicking these dimensions. In addition, the partial derivatives can be recalculated without the ignorable variables to eliminate the noise caused by them.  The histogram view not only reveals the significance of the independent variables, but also allows users to discover correlations: if y x 0 is a constant, then </p><formula>y = A 0 x 0 + f 0 (x 1 , .., x n )</formula><p>, where A 0 is a constant. In other words, if we find a first order partial derivative dimension with most values concentrated in a small value range (a histogram with a slim, tall bar), namely its value is a constant, the correlation between the independent variable and the dependent variable is discovered. For example, it can be seen from <ref type="figure" coords="6,263.34,368.30,30.70,8.20" target="#fig_2">Figure 4</ref>that all the correlations in the ThreeSix dataset belong to this type except y 0x 3 , y 0x 4 , and y 0x 5 . Users can pick up the exceptions to examine them further in the following steps. Variables with known correlations will be removed from the following steps to reduce clutter and confusion. A drawback of the histogram view is that it only conveys aggregated information. To overcome this drawback, we coordinate the histogram view with other multivariate views such as parallel coordinates and scatterplot matrices. In these displays the extended datasets or their subsets are displayed. Users can interactively select subsets of data items of their interest from these displays. The aggregated information of the selected subsets is then visually displayed in the histogram view (see <ref type="figure" coords="6,176.78,498.37,30.13,8.20" target="#fig_4">Figure 6</ref>for an example). The view for the second step consists of scatterplots between the first order partial derivatives and the independent variables. A single dependent variable is examined in such a view. <ref type="figure" coords="6,236.01,528.81,33.86,8.20" target="#fig_5">Figure 7c</ref>shows an example of the second step scatterplots. In this figure, each scatterplot is composed of a first order partial derivative dimension and an independent variable dimension. This view allows users to discover correlations. If y x 0 is linearly related to x i (0 ≤ i &lt; n), then there will be a straight line in the scatterplot of </p><formula>y x 0 versus x i . Thus, y = Bx 0 x i + A 0 x 0 + f 0 (x 1 , .., x n )</formula><p> , where B is another constant. Interestingly , periodic correlations, such as y x 0 = sin(x 0 ) can also be detected from this view. After the second step, scatterplots between the second order partial derivatives and the independent variable, and scatterplots between the second order partial derivatives and the first order partial derivatives are provided in different views to allow users to detect more complex correlations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">INTERACTIVE MODEL CONSTRUCTION</head><p> We support users in interactive model construction for further multivariate analysis through an interface tightly integrated with the step by step visual exploration pipeline. In particular, a dialog (see <ref type="figure" coords="6,317.95,298.56,33.91,8.20" target="#fig_5">Figure 7a</ref>) is used to record the exploration results from the steps and summarize the final result. At the top of the dialog, there are multiple tagged pages. One page is the control page and the others are step pages. The control page allows users to select the dependent variable whose model is to be constructed and to set the dimension reduction propagation mode within and outside the pipeline. Each step page is associated with a visual exploration step and contains one or more lists recording the outcome from the visual exploration of that step. At the bottom of the dialog, there is a summary list summarizing outcomes from all steps so far and a button for model construction when the exploration is done. The switch of views in the main display triggers the switch of the step pages in the dialog, and vise verse. Users can go through the pipeline starting from the first step and go back to a previous step at any moment during the visual exploration. In each step, users inspect the display to find histograms or scatterplots containing desired correlations. They then use simple keyboard input and mouse clicks to import the correlations into the dialog. In the first step, a derivative histogram with a small value range around zero indicates that this independent variable is ignorable compared to other independent variables. A left click on a histogram sends the independent variable name into the ignorable variable list in the step one page in the dialog. A left click with the control key pressed removes a variable from the list. A derivative histogram with a small and concentrated positive/negative value range indicates that the independent variable is linearly related to the dependent variable while holding other variables constant. A right click on a histogram sends the independent variable name into to the y = ax + f(other xs) list. In the second step, variable pairs are sent to the y = ax1x2 + bx1 + f(other xs) list if data are distributed in a straight line in their derivative/variable scatterplot. We allow users to create their own lists for more complex correlations in the second step and the later steps. In the default dimension reduction propagation setting, once a variable is imported into a list, it won't be shown in the views of the following steps. For example, after a linear correlation is detected in the first step, the independent variable and its derivatives will not be considered in the second step to avoid visual clutter and a model more complex than necessary. Users can also examine all variables in all steps by changing the settings from the control page. For views outside the pipeline, users can select to view all dimensions, dimensions with detected correlations only, or all <ref type="figure" coords="7,63.96,346.07,30.32,8.20" target="#fig_5">Figure 7</ref>shows a model construction example with the example dataset shown in <ref type="figure" coords="7,117.26,356.03,29.51,8.20">Figure 1</ref>. In the first step (<ref type="figure" coords="7,215.89,356.03,32.45,8.20" target="#fig_5">Figure 7b</ref> ), it was detected that ∂ (y 0 )/∂ (x 2 ) was a constant (the histogram with a yellow frame). The user right clicked on the histogram and sent x 2 to the y = ax + f(other xs) list, i.e., the information y </p><formula>0 = A 2 x 2 + f 0 (x 0 , x 1 ) </formula><p>was recorded. <ref type="figure" coords="7,108.97,395.89,34.73,8.20" target="#fig_5">Figure 7a</ref>shows the dialog after this operation. In the second step (<ref type="figure" coords="7,115.64,405.85,31.98,8.20" target="#fig_5">Figure 7c</ref>), only x 0 , x 1 , and their derivatives were examined. Straight lines were detected from the x 0 -∂ (y 0 )/∂ (x 1 ) and the x 1 -∂ (y 0 )/∂ (x 0 ) scatterplots (highlighted by yellow frames). These scatterplots were clicked and the information y </p><formula>0 = B 0 x 0 x 1 + A 0 x 0 + f 1 (x 1 , x 2 ) and y 0 = B 0 x 0 x 1 +A 1 x 1 + f 2 (x 0 , x 2 ) </formula><p>was recorded. Since the correlations between all independent variables and the dependent variable had been decided upon, the user clicked the Create Model button and the model: </p><formula>y 0 = B 0 x 0 x 1 +A 0 x 0 +A 1 x 1 +A 2 x 2 +C </formula><p>will be created and shown to the user. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">USER STUDY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Setup</head><p> A formal user study has been conducted to evaluate how our approach helps users understand the impact of independent variables on a dependent variable. We compared our first order partial derivative histogram view (derivative view to be short) with traditional scatterplot matrices without derivatives (scatterplot view to be short) since the latter is known for being good at revealing dimension relationships. Our assumption was that the derivative view could explicitly reveal correlations among multiple variables that were invisible from the scatterplot view. The dataset we used was the Boston Neighborhood Housing Price (BNHP) dataset <ref type="bibr" coords="7,134.75,634.09,9.52,8.20">[2]</ref>. This dataset was selected since housing prices and their affecting parameters were so familiar to us that the correlations detected from this dataset could be justified. In order to eliminate the influence of users' prior knowledge of the housing price in the user study, we used x 0 to x 11 to replace the true meaningful variable names, as shown in the BNHP variable name list. A screen capture of the BNHP dataset in the scatterplot view and a screen capture of the dataset in the derivative view, similar to the ones shown in <ref type="figure" coords="7,107.33,713.79,29.01,8.20">Figure 5</ref>, were each printed out on A4 paper. The user study was a within subjects, balanced user study. Eight graduate students participated in the user study, all of which majored in computer science. The subjects completed the study one by one with the same instructor. All work was done on paper with the screen captures since no interactions were evaluated in this study. The tasks the subjects conducted were to classify the correlation of each independent variable to the dependent variable into one of three types, namely positive, negative, or ignorable/uncertain correlation . The subjects were also required to record their confidence in each decision they made using a 0 -5 scale (0 -low confidence, 5 -high confidence). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Procedure</head><p>The user study was conducted as follows. Each subject worked two sections. Half of them worked with the scatterplot view first and the derivative view second. Half of them worked in a reversed order. Each section was conducted as follows. First, the instructor suggested to the subject how to find correlations from the view to be tested. A short question/answer time followed the instruction. Then the subject was given the screen capture of the view and conducted the tasks. At the end of the test, the participants were asked to complete a post-test questionnaire to rate their satisfaction on the two views based on the performed tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Result</head><p>The correctness of the result was strongly in favor of the derivative view. The average correct answer rate for all variables was 99% for the derivative view and only 66% for the scatterplot view. The variable by variable correct answer rates are shown in <ref type="figure" coords="7,534.58,563.85,23.41,8.20;7,317.95,573.81,7.14,8.20">Figure  8a</ref>. This detailed view shows the difficulty the subjects encountered in identifying the influence of x 1 , x 2 , x 3 , x 7 , x 8 , x 9 , x 10 , especially x 6 , with the scatterplot view. No one got the correct answer for x 6 that weighted distances to five Boston employment centers had a negative effect on housing price in Boston. We observed that for these variables, their correlations to the dependent variable can only be observed if the effects of other variables were eliminated. Our approach showed its strength in revealing such hidden correlations. The variable by variable average confidence rating is shown in <ref type="figure" coords="7,317.95,663.98,33.36,8.20">Figure 8b</ref> . It is surprising to see that the subjects were fairly confident about their answers with the scatterplot view, even when the correctness of their answers was pretty low. This phenomenon reveals a crisis in existing multivariate visualization systems: users often perceive wrong correlations among multiple dimensions from the display, and they are fairly confident with the wrong insights. It <ref type="figure" coords="8,118.84,168.58,29.15,8.20">Figure 8</ref>: The user study result seems that it is critical to introduce multivariate visual explanation techniques, such as the techniques presented in this paper, into existing multivariate visualization systems. The answers to the posttest questionnaire also showed a higher preference to the derivative view than the scatterplot view. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this paper, we present a novel Multivariate Visual Explanation approach to support determination of correlations among multiple variables. This approach tightly integrates partial derivative calculation , inspection, and visualization into a multivariate visualization system. Our case studies and user study show how this approach was effectively used to facilitate interactive dimension reduction, multivariate model construction, and user understanding of multivariate relationships for high dimensional datasets. Multivariate visual explanation is a challenging topic and there is much more work to be completed. In the future, we will provide visual aid and automatic techniques to facilitate users in detecting more complex correlations in interactive model construction. We would like to integrate more analysis techniques, such as generalized additive models <ref type="bibr" coords="8,129.09,404.98,14.94,8.20" target="#b9">[11] </ref>and surface response analysis <ref type="bibr" coords="8,252.55,404.98,9.52,8.20" target="#b1">[3]</ref>, into the MVE approaches and increase the scalability of our system in the number of dimensions and the types of data it supports. Integrating techniques to help users determine independent and dependent variables when no semantic information is provided is also an interesting extension to the system. More user studies will be conducted to evaluate the overall effectiveness of the MVE approaches. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,317.95,146.01,240.03,8.20;3,317.95,155.97,240.02,8.20;3,317.95,165.93,240.05,8.20;3,317.95,175.90,15.69,8.20"><head>Figure 2: </head><figDesc>Figure 2: Typical Errors [9, 14]. (a) Data with two different trends is oversimplified into a straight line. (b) One outlier dramatically skews the result. (c) A piece-wised defined function is treated as a line. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,54.00,174.20,240.04,8.20;4,54.00,184.16,240.04,8.20;4,54.00,194.12,136.63,8.20"><head>FigureFigure 3: </head><figDesc>Figure 3: The error display of a segmented dataset. The lengths of the horizontal blue bars and the colors of the data items indicate the error bounds of the partial derivatives. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,317.95,259.63,240.06,8.20;4,317.95,269.59,60.01,8.20"><head>Figure 4: </head><figDesc>Figure 4: The first order partial derivative histogram view of the ThreeSix dataset </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,64.33,561.88,229.72,11.66;5,73.93,574.13,28.39,8.20;5,64.33,591.79,156.31,11.66;5,64.33,611.75,229.70,11.66;5,73.93,624.01,44.84,8.20;5,64.33,641.67,227.60,11.66;5,64.33,661.63,222.18,11.66;5,64.33,681.58,181.64,11.66;5,64.33,701.53,229.71,11.74;5,73.93,713.79,17.93,8.20;5,328.29,372.57,229.70,11.74;5,337.88,384.82,12.95,8.20;5,328.29,399.35,192.17,11.66;5,328.29,416.17,188.35,11.66;5,328.29,432.99,162.79,11.66;5,328.29,449.82,229.70,11.66;5,337.88,462.08,54.06,8.20;5,328.29,476.61,179.65,11.66"><head>@BULLET </head><figDesc>Med-Price(y): Median value of owner-occupied homes in $1000's @BULLET CRIM(x 0 ): per capita crime rate by town @BULLET ZN(x 1 ): proportion of residential land zoned for lots over 25,000 sq.ft. @BULLET INDUS(x 2 ): proportion of non-retail business acres per town @BULLET NOX(x 3 ): nitric oxides concentration (parts per 10 million) @BULLET RM(x 4 ): average number of rooms per dwelling @BULLET AGE(x 5 ): proportion of owner-occupied units built prior to 1940 @BULLET DIS(x 6 ): weighted distances to five Boston employment cen- ters @BULLET RAD(x 7 ): index of accessibility to radial highways @BULLET TAX(x 8 ): full-value property-tax rate per $10,000 @BULLET PTRATIO(x 9 ): pupil-teacher ratio by town @BULLET B(x 10 ): 1000(Bk − 0.63) 2 where Bk is the proportion of blacks by town @BULLET LSTAT(x 11 ): -% lower status of the population </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,54.00,225.83,504.00,8.20;6,54.00,235.79,503.98,8.20;6,54.00,245.76,503.98,8.20;6,54.00,255.72,503.97,9.35;6,54.00,265.68,253.63,9.35"><head>Figure 6: </head><figDesc>Figure 6: Coordinated Views of the SegData Dataset. (a) The parallel coordinates view of a dataset where the variables and their derivative errors are shown. Data items with good derivative qualities are selected and highlighted. (b) The selection is propagated to the histogram view. It shows that the noise in the histograms is the unselected low quality derivatives. (c) The selection in the parallel coordinates is modified so that only data items whose y 0 values fall into the lower value group are selected. (d) The corresponding histogram view shows that the selected data items have constant derivatives in both x 0 and x 1 . </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="7,54.00,233.03,181.41,9.35;7,237.99,230.74,24.47,11.66;7,264.26,230.74,293.73,11.66;7,54.00,242.99,25.90,8.20"><head>Figure 7: </head><figDesc>Figure 7: Interactive model construction for the y 0 = x 0 x 1 + x 2 dataset. (a) model construction dialog in Step 1 (b) Step 1 display (c) Step 2 display </figDesc></figure>

			<note place="foot" n="3"> shows an example of such a display. It shows the original dimensions , partial derivatives, and differentiation errors of a synthesized segmented dataset named SegData, defined as: y = 8x 0 + x 1 if x 0 ≥ 0.6 and x 1 ≤ 0.3 and y = x 0 −7x 1 otherwise for x 0 and x 1 randomly distributed on [0,1].</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS </head><p>This work is partially supported by UNCC internal faculty research grant 1-11436 and NIH grant 1R01GM 073082-0181. It is also partially supported by the National Visualization and Analytics Center (NVAC(TM)), a U.S. Department of Homeland Security Program, under the auspices of the Southeastern Regional Visualization and Analytics Center. NVAC is operated by the Pacific Northwest National Laboratory (PNNL), a U.S. Department of Energy Office of Science laboratory . </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="8,81.66,600.91,212.37,7.29;8,72.26,610.37,221.78,7.29;8,72.26,619.84,165.46,7.29;8,57.99,629.30,36.86,7.29;8,117.25,629.30,44.28,7.29;8,183.92,629.30,25.24,7.29;8,231.57,629.30,15.93,7.29;8,269.91,629.30,24.13,7.29;8,72.26,638.77,199.12,7.29"  xml:id="b0">
	<analytic>
		<title level="a" type="main">Knowledge task-based framework for design and evaluation of information visualizations</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Amar</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Stasko</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symposium on Information Visualization</title>
		<meeting>. IEEE Symposium on Information Visualization</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="143" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.26,648.23,221.79,7.29;8,72.26,657.69,104.94,7.29"  xml:id="b1">
	<monogr>
		<title level="m" type="main">Empirical Model-Building and Response Surfaces</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Box</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Draper</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.26,667.16,221.76,7.29;8,72.26,676.63,221.80,7.29;8,72.26,686.09,221.77,7.29;8,72.26,695.56,69.29,7.29"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Model selection via worst-case criterion for nonlinear bounded-error estimation</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Brahim-Belhouari</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Kieffer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Fleury</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Jaulin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Walter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Instrumentation and Measurement</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="653" to="658" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.26,705.01,221.78,7.29;8,72.26,714.48,74.10,7.29"  xml:id="b3">
	<monogr>
		<title level="m" type="main">Dynamic Graphics for Statistics</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Cleveland</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Mcgill</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>Wadsworth, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,58.45,221.79,7.29;8,336.21,67.91,50.93,7.29"  xml:id="b4">
	<monogr>
		<title level="m" type="main">Applied Regression Analysis</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Draper</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Smith</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>John Wiley and Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,77.37,221.80,7.29;8,336.21,86.84,221.79,7.29;8,336.21,96.30,221.79,7.29;8,336.21,105.77,33.88,7.29"  xml:id="b5">
	<analytic>
		<title level="a" type="main">Bootstrap and backward elimination based approaches for model selection</title>
		<author>
			<persName>
				<forename type="first">A</forename>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Kayhan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Zoubir</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd International Symposium on Image and Signal Processing and Analysis</title>
		<meeting>. 3rd International Symposium on Image and Signal essing and Analysis</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="238" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,115.23,221.77,7.29;8,336.21,124.69,221.79,7.29;8,336.21,134.16,122.87,7.29"  xml:id="b6">
	<analytic>
		<title level="a" type="main">Extending mosaic displays: Marginal, partial, and conditional views of categorical data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Friendly</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="373" to="395" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,143.62,214.01,7.29"  xml:id="b7">
	<analytic>
		<title level="a" type="main">Multivariable Calculus</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Cain</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Herod</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Georgia Tech</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,153.09,221.79,7.29;8,336.21,162.56,210.58,7.29"  xml:id="b8">
	<analytic>
		<title level="a" type="main">Hedonic prices and the demand for clean air</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Harrison</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Rubinfeld</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Environ. Economics &amp; Management</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="81" to="102" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,172.01,221.80,7.29;8,336.21,181.48,49.15,7.29"  xml:id="b9">
	<monogr>
		<title level="m" type="main">Generalized Additive Models</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hastie</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>Chapman and Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,190.95,221.79,7.29;8,336.21,200.41,221.79,7.29;8,336.21,209.88,221.79,7.29;8,336.21,219.34,33.88,7.29"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Visualization support for user-centered model selection in knowledge discovery in databases</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ho</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Nguyen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th International Conference on Tools with Artificial Intelligence</title>
		<meeting>. 13th International Conference on Tools with Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="228" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,228.80,221.80,7.29;8,336.21,238.27,204.43,7.29"  xml:id="b11">
	<monogr>
		<title level="m" type="main">The plane with parallel coordinates. Special Issue on Computational Geometry, The Visual Computer</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Inselberg</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
			<biblScope unit="page" from="69" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,247.73,221.80,7.29;8,336.21,257.20,17.94,7.29"  xml:id="b12">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Mcclave</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Sincich</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics</title>
		<imprint>
			<publisher>Prentice Hall. Inc</publisher>
			<date type="published" when="2003" />
			<publisher>Prentice Hall. Inc</publisher>
		</imprint>
	</monogr>
	<note>10th. Edition</note>
</biblStruct>

<biblStruct coords="8,336.21,266.66,209.23,7.29"  xml:id="b13">
	<monogr>
		<title level="m" type="main">Principal Component Analysis</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Jolliffe</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,276.12,221.79,7.29;8,336.21,285.59,221.77,7.29;8,336.21,295.05,95.64,7.29"  xml:id="b14">
	<analytic>
		<title level="a" type="main">Recursive pattern: a technique for visualizing very large amounts of data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Keim</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H.-P</forename>
				<surname>Kriegel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ankerst</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>. IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="279" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,304.52,221.79,7.29;8,336.21,313.98,221.81,7.29;8,336.21,323.44,221.78,7.29;8,336.21,332.91,113.11,7.29"  xml:id="b15">
	<analytic>
		<title level="a" type="main">Responsesurface analysis of exposure-duration relationships: The effects of hyperthermia on embryonic development of the rat in vitro</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Kimmel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Williams</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Claggett</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Kimmel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Toxicological Sciences</title>
		<imprint>
			<biblScope unit="page" from="391" to="399" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,342.37,188.76,7.29"  xml:id="b16">
	<monogr>
		<title level="m" type="main">Self Organizing Maps</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Kohonen</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,351.84,221.78,7.29;8,336.21,361.31,17.94,7.29"  xml:id="b17">
	<monogr>
		<title level="m" type="main">Multidimensional Scaling</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kruskal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Wish</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1978" />
			<publisher>Sage Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,370.77,221.76,7.29;8,336.21,380.23,221.79,7.29;8,336.21,389.69,29.90,7.29"  xml:id="b18">
	<analytic>
		<title level="a" type="main">General explicit difference formulas for numerical differentiation</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Applied Mathematics</title>
		<imprint>
			<biblScope unit="page" from="29" to="52" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,399.16,221.80,7.29;8,336.21,408.63,221.79,7.29;8,336.21,418.09,156.17,7.29"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Object recognition using composed receptive field histograms of higher dimensionality</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Linde</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Lindeberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Pattern Recognition</title>
		<meeting>. International Conference on Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,427.55,221.79,7.29;8,336.21,437.01,221.79,7.29;8,336.21,446.48,221.78,7.29;8,336.21,455.95,77.27,7.29"  xml:id="b20">
	<analytic>
		<title level="a" type="main">Applications of nonuniform fast transform algorithms in numerical solutions of differential and integral equations</title>
		<author>
			<persName>
				<forename type="first">Q</forename>
				<surname>Liu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Xu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on geoscience and remote sensing</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1551" to="1560" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,465.41,221.80,7.29;8,336.21,474.87,221.79,7.30;8,336.21,484.35,33.88,7.29"  xml:id="b21">
	<analytic>
		<title level="a" type="main">High dimensional brushing for interactive exploration of multivariate data</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Martin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ward</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>. IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,493.81,221.78,7.29;8,336.21,503.28,221.78,7.29;8,336.21,512.74,221.79,7.29;8,336.21,522.21,41.85,7.29"  xml:id="b22">
	<analytic>
		<title level="a" type="main">A rank-by-feature framework for unsupervised multidimensional data exploration using low dimensional projections</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Seo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Shneiderman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symposium on Information Visualization</title>
		<meeting>. IEEE Symposium on Information Visualization</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.20,531.67,221.79,7.29;8,336.21,541.13,200.58,7.29"  xml:id="b23">
	<analytic>
		<title level="a" type="main">Mathematical modeling as a tool for investigating cell cycle control networks</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Sible</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Tyson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Method</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="238" to="247" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,550.60,221.77,7.29;8,336.21,560.06,221.81,7.29;8,336.21,569.53,17.94,7.29"  xml:id="b24">
	<analytic>
		<title level="a" type="main">Wavelet approach to numerical differentiation of noisy functions</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communication on Pure and Applied Analysis</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="873" to="897" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,579.00,221.79,7.29;8,336.21,588.45,221.80,7.29;8,336.22,597.92,33.88,7.29"  xml:id="b25">
	<analytic>
		<title level="a" type="main">Graph-theoretic scagnostics</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Wilkinson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Anand</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Grossman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symposium on Information Visualization</title>
		<meeting>. IEEE Symposium on Information Visualization</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="157" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,607.38,161.59,7.29"  xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">Page</forename>
				<surname>Xmdvtool Home</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,616.85,221.80,7.29;8,336.22,626.32,221.77,7.29;8,336.22,635.78,221.77,7.29;8,336.22,645.24,87.67,7.29"  xml:id="b27">
	<analytic>
		<title level="a" type="main">Value and relation display for interactive exploration of high dimensional datasets</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Yang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Patro</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Huang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Mehta</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ward</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Rundensteiner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symposium on Information Visualization</title>
		<meeting>. IEEE Symposium on Information Visualization</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,654.71,221.80,7.29;8,336.22,664.17,221.76,7.29;8,336.22,673.64,221.80,7.29;8,336.22,683.10,17.94,7.29"  xml:id="b28">
	<analytic>
		<title level="a" type="main">Visual hierarchical dimension reduction for exploration of high dimensional datasets</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Yang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ward</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Rundensteiner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Huang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics/IEEE TCVG Symposium on Visualization</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
