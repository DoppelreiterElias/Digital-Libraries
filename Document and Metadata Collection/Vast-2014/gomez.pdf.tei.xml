<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T13:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Insight-and Task-based Methodology for Evaluating Spatiotemporal Visual Analytics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Steven</forename>
								<forename type="middle">R</forename>
								<surname>Gomez</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Hua</forename>
								<surname>Guo</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Caroline</forename>
								<surname>Ziemkiewicz</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">David</forename>
								<forename type="middle">H</forename>
								<surname>Laidlaw</surname>
							</persName>
						</author>
						<title level="a" type="main">An Insight-and Task-based Methodology for Evaluating Spatiotemporal Visual Analytics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms—Evaluation methodology</term>
					<term>insight-based evaluation</term>
					<term>visual analytics</term>
					<term>network visualization</term>
					<term>information visualization</term>
				</keywords>
			</textClass>
			<abstract>
				<p>—We present a method for evaluating visualizations using both tasks and exploration, and demonstrate this method in a study of spatiotemporal network designs for a visual analytics system. The method is well suited for studying visual analytics applications in which users perform both targeted data searches and analyses of broader patterns. In such applications, an effective visualization design is one that helps users complete tasks accurately and efficiently, and supports hypothesis generation during open-ended exploration. To evaluate both of these aims in a single study, we developed an approach called layered insight-and task-based evaluation (LITE) that interposes several prompts for observations about the data model between sequences of predefined search tasks. We demonstrate the evaluation method in a user study of four network visualizations for spatiotemporal data in a visual analytics application. Results include findings that might have been difficult to obtain in a single experiment using a different methodology. For example, with one dataset we studied, we found that on average participants were faster on search tasks using a force-directed layout than using our other designs; at the same time, participants found this design least helpful in understanding the data. Our contributions include a novel evaluation method that combines well-defined tasks with exploration and observation, an evaluation of network visualization designs for spatiotemporal visual analytics, and guidelines for using this evaluation method.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Evaluating visual analytics systems is challenging because users need to know that the system supports both basic information retrieval tasks as well as complex reasoning and exploration. A system that is good for looking up specific data is not always good for building insights and testing hypotheses, and vice versa. At the same time, practical applications frequently demand that the same tool be used for both purposes . Despite visual analytics' focus on reasoning, many studies evaluate tools using task-based protocols that measure only user performance on low-level tasks. By contrast, insight-based methodologies aim to measure how well visualizations promote insight generation, using characteristics like the domain value of observations users make about the data model. However, these methodologies can be difficult to follow, and it is not clear how best to capture insight characteristics alongside users' task performance, as is relevant in visual analytics applications that support both targeted data searches and analysis of broader patterns. Here we present a method for evaluating visualizations using both tasks and exploration, and demonstrate this method in a study of four spatiotemporal network designs for a visual analytics system. We call the approach layered insight-and task-based evaluation (LITE) because it interposes several prompts for observations about the data model between sequences of predefined search tasks. Our evaluation demonstrates the feasibility of a lightweight, within-subjects insightbased evaluation. We reflect on the relationship between users' task performance with a visualization and how well it promotes insights in assessing the best choice among four visualization designs for a spatiotemporal visual analytics system. Our contributions here include: 1) a novel method of evaluating both task performance and insight characteristics of visualizations in a single study using a mixed design; 2) a demonstration of the method in a case study of four network-layout designs for spatiotemporal visual analytics, and 3) guidelines for using the evaluation method in @BULLET Steven R. Gomez is with Brown University. E-mail: steveg@cs.brown.edu. @BULLET Hua Guo is with Brown University. E-mail: huag@cs.brown.edu. @BULLET Caroline Ziemkiewicz is with Aptima, Inc. E-mail: cziemkiewicz@aptima.com. @BULLET David H. Laidlaw is with Brown University. E-mail: dhl@cs.brown.edu. future studies. While our case study focuses on a spatiotemporal visual analytics application where both exploration and routine search tasks might be performed, the evaluation method can be applied to other visualization types. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p> Many evaluation methods have been demonstrated in empirical visualization research. Carpendale reviews evaluation approaches for information visualization <ref type="bibr" coords="1,412.42,381.15,14.94,8.02" target="#b9">[10] </ref>and describes challenges outlined in earlier works by Plaisant <ref type="bibr" coords="1,411.71,391.11,14.94,8.02" target="#b21">[22] </ref> and others. Another overview of approaches aimed at visual analytics appears in the VisMaster consortium book <ref type="bibr" coords="1,357.53,411.03,13.74,8.02" target="#b14">[15]</ref>. The biennial BELIV workshop (Beyond Time and Errors: Novel Evaluation Methods for Visualization) has significantly added to the discussion of challenges in visualization evaluation. The research contributions in its proceedings have focused on developing more effective evaluation methods that avoid the pitfalls of traditional methodologies. Taxonomies of past studies have also been helpful in constructing guidelines for evaluating new visualizations <ref type="bibr" coords="1,522.64,470.81,14.19,8.02" target="#b15">[16,</ref><ref type="bibr" coords="1,539.08,470.81,11.21,8.02" target="#b12"> 13,</ref><ref type="bibr" coords="1,552.52,470.81,10.64,8.02" target="#b19"> 20]</ref>. In the remainder of this section, we describe methods relevant to a combined insight-and task-based evaluation, as well as to evaluations of information layouts for visual analytics. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Task-based Evaluations</head><p>Controlled laboratory studies with predefined tasks are commonplace in visualization research. In general, these studies aim to produce measurable outputs that are comparable among participants, design conditions , or other independent variables. Accuracy and response time for tasks are typical measures, with accuracy sometimes being used to filter task executions from the response-time analysis (e.g., <ref type="bibr" coords="1,546.82,580.67,13.45,8.02" target="#b11">[12]</ref>). In such studies the objective is to demonstrate differences in task efficiency . The evaluation approach described here collects user efficiency and accuracy measures for tasks selected using a typology covering the basic analysis questions one might ask of a spatiotemporal data model. These tasks represent analysis pieces that could be composed into a larger-scale, exploratory analysis. We acknowledge that there are tradeoffs in the realism of tasks performed in order to gain precise, quantitative results <ref type="bibr" coords="1,387.36,660.37,13.74,8.02" target="#b15">[16]</ref> . Our study uses non-experts rather than professional data analysts, and tasks have been abstracted to remove any dependence on domain knowledge. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Insight-based Evaluations</head><p>Unlike task-based evaluation methods, insight-based methodologies are motivated by the realization that the goal of a visualization tool is  usually to enhance understanding of the underlying data, not to improve task accuracy and efficiency <ref type="bibr" coords="2,170.16,63.35,9.71,8.02" target="#b8">[9,</ref><ref type="bibr" coords="2,182.06,63.35,11.21,8.02" target="#b16"> 17,</ref><ref type="bibr" coords="2,195.45,63.35,10.65,8.02" target="#b22"> 23]</ref>. Saraiya et al. presented an insight-based approach for evaluating bioinformatics tools <ref type="bibr" coords="2,265.47,73.31,14.94,8.02">[26] </ref>and later used it in a longitudinal study where insights were developed over months <ref type="bibr" coords="2,93.29,93.23,13.74,8.02" target="#b26">[27]</ref>. Characteristics of insights include the number of distinct data observations, the time needed to reach each insight, the domain value of each insight, breadth-versus-depth labeling, and other characteristics. Quantifying some of these attributes requires domain experts to participate as response coders in the evaluation. Even with this scheme, eliminating all subjectivity from the evaluation is difficult ; for instance, the cutoff between a depth insight and a breadth insight might vary depending on the expert coder. Other studies have applied similar methods to measure insight characteristics between visualization conditions. It is worth noting that insight characteristics have been adapted from those proposed by Saraiya et al. in order to fit the hypotheses of other studies. For instance , O'Brien et al. made an insight-based evaluation of two tools for visualizing genomic rearrangements using a reduced set of insight characteristics <ref type="bibr" coords="2,119.95,233.22,13.94,8.02" target="#b18">[19]</ref>: researchers counted the instances of three categories of insights as well as the total number of insights, total " hypothesis-driving " insights, and the insights per minute of analysis . Our method also uses a simplified set of insight characteristics and collects these with a single study protocol alongside task perfor- mance. North et al. found that the results of an insight-based evaluation can both support and contradict findings of studies using benchmark tasks with the same visualizations <ref type="bibr" coords="2,151.76,313.44,13.74,8.02" target="#b17">[18]</ref>. It is possible that evaluators who use only one of these methods will miss details visible using the other. We aim to combine the two in a single, practical protocol while minimizing interactions or biases in the results. Our method differs in time scale from longitudinal studies in visualization, such as multidimensional in-depth long-term case studies (MILCS) <ref type="bibr" coords="2,218.32,363.25,13.74,8.02" target="#b29">[30]</ref>. Unlike previous insight-based evaluations, the evaluation we present uses non-expert participants. Using non-experts lets us achieve a larger sample size than would otherwise be possible, enabling us to test hypotheses about task performance and quantified insight characteristics more precisely. There are drawbacks in using non-experts; e.g., asking participants for initial analysis questions might be unreliable; however, even if domain experts were used, they would not necessarily have experience with the analysis tools in the study, as in <ref type="bibr" coords="2,198.40,442.95,13.74,8.02">[26]</ref> . Furthermore, we expect that combining tasks with exploration provides extra training and motivation for participants. Previous studies <ref type="bibr" coords="2,206.22,462.88,14.94,8.02" target="#b10">[11] </ref>and models <ref type="bibr" coords="2,266.93,462.88,14.19,8.02" target="#b24">[25,</ref><ref type="bibr" coords="2,283.43,462.88,11.95,8.02" target="#b23"> 24] </ref>have demonstrated how predefined tasks enhance exploratory learning of computer interfaces. While the insights themselves are likely to be less deep for non-experts than for domain experts, it is possible to compare insight-promoting characteristics between visualizations using non-experts. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="63"></head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Spatiotemporal Tasks and Visual Designs</head><p> An indispensable part of designing a visual analytics tool is considering the set of analytical tasks to be supported. The visualizations evaluated here are grounded in previous work on visual analysis of spatiotemporal data. In <ref type="bibr" coords="2,130.77,576.51,13.74,8.02" target="#b20">[21]</ref>, Peuquet distinguished three components in spatiotemporal data and queries about those components: space (where), time (when), and objects (what). Users can complete queries when two of the three components are known and the other is the search target. Andrienko et al., drawing on Peuquet's work as well as other task typologies, proposed a typology for visual analytical tasks with the dimensions of search target, search level, and cognitive oper- ation <ref type="bibr" coords="2,64.81,646.25,9.52,8.02" target="#b3">[4]</ref>. Others <ref type="bibr" coords="2,105.93,646.25,9.71,8.02" target="#b5">[6,</ref><ref type="bibr" coords="2,117.51,646.25,6.72,8.02" target="#b1"> 2,</ref><ref type="bibr" coords="2,126.10,646.25,11.95,8.02" target="#b27"> 28] </ref>have proposed more general task typologies that also apply to spatiotemporal data. Many visual analytics designs for spatiotemporal data exist, as reviewed comprehensively in <ref type="bibr" coords="2,144.32,676.65,9.52,8.02" target="#b3">[4]</ref>. Notably, maps and timelines, the most common representations for spatial and temporal data, have been combined in previous design studies. <ref type="bibr" coords="2,163.61,696.57,50.48,8.02">Slingsby et al. </ref> showed that these representations can be configured as levels of a tree map in order to support different queries <ref type="bibr" coords="2,123.98,716.50,13.74,8.02" target="#b30">[31]</ref>. More recently, Andrienko and Andrienko proposed the cartographic map display and time-series display as the two visualization components in their visual analytics framework for <ref type="figure" coords="2,307.62,100.30,21.51,8.02">Fig. 1</ref>: Example ordering of k visualization conditions and n task types in LITE. After each block of tasks with a visualization (labeled T 1 . . . T n ), the participant is prompted for exploration and observation about the data (labeled O 1 . . . O k ). Task ordering within a visualization condition is randomized using a balanced Latin square, and visualization orders are randomized between participants using a balanced Latin square. In our case study, k = 4 and n = 4. spatiotemporal analysis <ref type="bibr" coords="2,394.29,193.51,9.52,8.02" target="#b2">[3]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">LAYERED INSIGHT-AND TASK-BASED EVALUATION</head><p>We propose combining a lightweight insight-based evaluation adapted from Saraiya et al. <ref type="bibr" coords="2,378.59,236.60,14.94,8.02">[26] </ref>with a traditional task-based evaluation. We call this approach layered insight-and task-based evaluation, or LITE, because it interposes several prompts for observations about the data model between sequences of predefined search tasks or queries. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Motivation</head><p>Two main goals for this method are: 1) to measure the accuracy and efficiency of common tasks alongside insight characteristics without compromising task measurements; and 2) to measure insight characteristics while sidestepping some of the difficulties of performing the insight-based method, such as: D1 Users must be intrinsically motivated to look for insights during a session that might be open-ended. D2 Training new users on visualization interfaces can be challenging . Training can fatigue users and make them try less hard in the actual study <ref type="bibr" coords="2,386.07,397.29,13.74,8.02">[26]</ref>. D3 After the user study, coding observations for measurable insight characteristics like domain value is difficult and requires domain experts. </p><p> Even when these difficulties are managed in an insight-based evaluation , challenges arise when performing such an evaluation separately from a task-based evaluation so as to collect measures of both task performance and insight generation. If these studies use different participants it can be difficult to draw conclusions about relationships between tasks and exploration. Individual differences or differing sample sizes must be considered. Performing separate task-and insight-based evaluations back to back creates other challenges. If a full insight-based evaluation is performed before a task-based evaluation, open-ended exploration may fatigue users to the point that they perform poorly on the follow-up study. If a full task-based evaluation is performed before an insightbased evaluation, users may have less motivation to explore the data model: they might satisfice and report only shallow insights in order to finish the study. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Steps</head><p> The initial stages in a LITE evaluation are similar to those in previous insight-based methodologies. As a study session proceeds, sets of predefined tasks are interleaved with exploration periods letting participants find and record insights. The steps are: 1. Background about the dataset is provided, then participants are prompted for initial analysis questions. Alternatively, initial analysis questions can be provided by the evaluators. 2. Participants are then trained on each task type for different visualization conditions. Participants are not trained on exploration, as in <ref type="bibr" coords="2,346.47,716.50,13.74,8.02">[26]</ref>. 3. When the study begins, participants complete blocks of tasks with each visualization condition. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time Range </head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Apr 30 May 01 May 02 May 03 May 04 May 05 May 06 May 07 May 08 May 09 May 10 May 11 May 12 May 13 May 14 May 15 May 16 May 17 May 18 May 19 May 20 May 21 Apr 30 May 01 May 02 May 03 May 04 May 05 May 06 May 07 May 08 May 09 May 10 May 11 May 12 May 13 May 14 May 15 May 16 May 17 May 18 May 19 May 20 May 21 </head><p>Time-situated (TS) Fig. 2: Four visualization designs were evaluated using a layered insight-and task-based evaluation: force-directed (F), time-situated (TS), space-situated (SS), and time-and space-situated (TSS). These visualizations depict microblog messages and their authors, and the designs differ in how attributes of the nodes, like timestamp and location, are used to lay out the diagram. 4. After each block, participants explore the data freely using the visualization and record insights. Each exploration period is open-ended. In order to keep participants from skipping these periods, a minimum time requirement may be enforced before they can move to the next visualization and block of tasks. <ref type="figure" coords="3,289.43,544.04,14.95,8.02;3,73.93,554.00,18.25,8.02">Fig- ure 1</ref> shows an example ordering of tasks and visualization conditions in which each participant completes each task type once using each visualization. 5. Finally, a post-test questionnaire or interview may be used after all tasks and exploration periods are finished. Subjective feedback about the insightfulness of visualizations may be used to explore findings from insight characteristics measured during exploration periods. </p><p>The proposed method addresses some difficulties of the traditional insight-based evaluation listed earlier. Study participants in LITE may feel more motivated because the session makes concrete progress through task completions rather than asking for open-ended exploration alone (D1). Tasks may improve participants' confidence with the visualizations and provide extra experience that promotes exploration and insight generation (D2). In our case study, we developed and used a scoring system without domain experts to code the value of insights (D3), but this system is not specific to LITE and could be applied to other insight-based methods. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CASE STUDY</head><p>We evaluated four node-link diagram layout designs for an interactive visual analytics system that uses a graph-based model of real-world entities, like documents and people. We chose node-link diagrams here because of their flexibility in representing arbitrary node and edge types in the model. That said, we expect most nodes to have spatiotemporal attributes that describe when and where events happen. Based on this, we developed designs that differ in how location and time attributes are used to lay out nodes with these attributes in the diagram. Specifically, we looked at ways to project location and time attributes onto the drawing-plane axes. This is conceptually similar to previous work in which generic quantitative attributes are mapped onto axes to guide node placement <ref type="bibr" coords="3,408.36,627.31,9.52,8.02" target="#b6">[7]</ref>. In this study, we restricted ourselves to designing a layout for a single display. We considered four distinct node-link diagram layouts for the network model: F Force-directed: A force-directed layout plots marks based on a physical simulation and has the effect of reducing visual density in the node-link diagram. Force-directed layouts are widely used and well understood. We consider this a control condition in an evaluation of visualization designs that position nodes using spatial or temporal attributes. </p><p>SS Space-situated: The space-situated layout overlays document marks on a map of the city based on documents' geotags. Nodes without geotags are placed at the top of the visualization and distributed evenly. </p><p>TS Time-situated: The time-situated layout aligns document marks with a horizontal timeline. The vertical positions of document marks are determined using a force-directed layout to reduce visual density in the diagram. Nodes without timestamps are placed at the top of the visualization and distributed evenly. </p><p>TSS Time-and space-situated: The time-and space-situated layout plots document marks according to both geotags and timestamps. Nodes without geotags and timestamps are placed at the top of the visualization and distributed evenly. In TSS the horizontal axis is a timeline, as in TS. In our prototype, the vertical axis is divided into categories corresponding to neighborhoods in the data model. Categories on the vertical axis can be ordered in different ways, for instance from top to bottom based on an ordering of neighborhood locations from northernmost to southernmost. In this case, boundaries between categories could reflect some information about the geographic boundaries between neighbor- hoods. <ref type="figure" coords="4,54.96,276.95,29.63,8.02">Figure 2</ref>shows each of these layout designs. All visualizations were prototyped using D3 <ref type="bibr" coords="4,120.82,286.91,10.45,8.02" target="#b4">[5] </ref> and JavaScript, and share some visual encodings . The entity type of each node is double-encoded by shape and color. Marks representing documents are blue squares and marks representing people are gold diamonds; these two sorts of marks have roughly the same size in the browser. A detailed description of each node appears in a scrollable tooltip when the user hovers over the node. For documents, this description includes the author, timestamp, location , and content. In general, document content is limited to 140 characters , since documents in our data model are microblog formats like Twitter messages that enforce a content-length limit. A simple aggregation scheme is built into each prototype so that node marks that would otherwise overlap cannot become inaccessible to the user. When marks of the same entity type overlap, both are removed from the diagram and a single aggregated mark is added. Only marks representing entities of the same type can be aggregated: thus, documents can be aggregated only with other documents. Aggregated marks retain the same entity-type encoding (shape and color) but are distinguished by a red border and increased size. Because multiple marks might overlap, the size of aggregated marks is used to encode the number of individual entities it represents. We considered several approaches to aggregating nodes in nodelink diagrams. A common approach is to aggregate a primary entity node and nodes representing its attributes into a compound node <ref type="bibr" coords="4,281.18,506.09,14.19,8.02" target="#b28">[29,</ref><ref type="bibr" coords="4,45.00,516.05,6.47,8.02" target="#b7"> 8]</ref>. This approach does not work for our case, however, as the mapping between two types of entities in our data model might be many-tomany . In our prototypes, when a node is aggregated into a different mark, each edge mark connected to that node is replaced by another that is connected to the aggregated node. The underlying data model is not changed by this process. Two nodes connected by an edge cannot be aggregated together. Hovering over a node mark highlights all edges connected to that entity. For example, hovering over a person node highlights edges to all document nodes connected to that person by an " authored-by " relationship . Hovering over a document highlights the edge to its author node. Highlighting is implemented by restyling edges from transparent gray to opaque red. A selection interaction is also included to allow persistent highlighting during user exploration. Users can toggle selection on node marks by clicking them with the cursor. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENT DESIGN</head><p>After a small pilot study, we performed an experiment to evaluate a set of hypotheses about task performance and insight characteristics for participants using four visualization designs. A 2 × (4 × 4) mixed design was used to examine the independent variables of dataset size between subjects, and visualization design and task type within sub- jects. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Hypotheses</head><p>In general, we expect that layouts that position nodes by projecting their attributes onto the axes will improve task performance and promote insight generation. Below are specific hypotheses about the effect of independent variables on task performance (H1, H2), subjective ratings from participants (H3, H4, H5), and insight characteristics (H6–H10): H1 For all tasks, participants will be fastest using TSS, which uses both spatial and temporal attributes to lay out nodes. For all tasks, participants will be the slowest using F. H2 Visualization type will have a significant effect on task accuracy. H3 Participants will report feeling most confident in their task responses when using TSS and least confident when using F. H4 Participants will report that TSS is the most helpful visualization type for understanding the data and that F is the least insightful in this way. H5 Participants will report that TSS is the easiest visualization type to use and that F is the hardest. H6 Total domain value for observation prompts will be highest for the TSS condition and least for the F condition. H7 Visualization type will have an effect on the total domain value during observation prompts. H8 Dataset size will have an effect on both total time and total domain value during observation prompts. Both characteristics will be higher in the large dataset than in the small one. H9 The order of observation prompts will have an effect on the total domain value during those prompts. H10 The order of observation prompts will have an effect on the total response time during those prompts. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Visualization Types</head><p>The four visualization types in our study are described in Section 4 and shown in <ref type="figure" coords="4,341.91,384.02,28.84,8.02">Figure 2</ref> . In addition to the visualization layouts, the user interface included controls to filter document nodes by publication time and location. Data-filter controls are common in visual analytics applications , and it is important that the test interface match realistic usage scenarios. The time filter is a slider that can be moved on both ends in increments of one day. Node and edge marks related to documents published outside the chosen range are invisible. The location filter contains checkboxes that correspond to all neighborhood locations in the data model and can be toggled to filter marks related to documents published outside selected neighborhoods. This filter also provides " Select all " and " Deselect all " interactions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Datasets</head><p> Dataset size is an important consideration in designing network visualizations . In general, larger data models add complexity and visual density that can expose scalability problems in different designs. For our experiment, two graph-based datasets of different sizes were compiled using data from the 2011 VAST Challenge Mini-Challenge #1 (MC1) <ref type="bibr" coords="4,334.85,563.82,9.52,8.02" target="#b0">[1]</ref> . Both are subsets of a synthetic dataset containing timestamped , geotagged microblog messages from residents in a city experiencing a health epidemic. </p><p>@BULLET Small – includes 10 person nodes and 139 document nodes. There are 139 " authored by " edges that connect documents to their authors. Documents were published from 13 different neighborhoods over a span of 22 days. </p><p>@BULLET Large – includes 74 person nodes and 999 document nodes. There are 999 " authored by " edges that connect documents to their authors. Documents were published from 13 different neighborhoods, and some lacked a neighborhood-specific location (i.e., location is " Vastopolis " , the city name). They were published over a span of 22 days. </p><p>Both datasets were created by sampling the Challenges full-size dataset, and both contain evidence of the health epidemic in the microblogs . These 'evidence' microblogs appear in similar proportions in both datasets. We note that, while larger data models are common in real analysis scenarios, we limited the size in order to keep tasks and exploration manageable for non-expert participants during single study sessions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Tasks</head><p>Based on the spatiotemporal network data model, tasks were selected using a simple typology based on when, where, what, and who queries. This task typology is similar to ones used in previous studies <ref type="bibr" coords="5,277.90,351.89,9.71,8.02" target="#b3">[4,</ref><ref type="bibr" coords="5,290.18,351.89,10.65,8.02" target="#b27"> 28]</ref>. We note that in the training and task instructions, the word " tweet " was used as a colloquialism for a microblog message. No data or services from Twitter were used in the study. The four task types are: </p><p>@BULLET who + when + where → what: Given a microblog's author, date, and location, summarize the content in a few words. For example , " Cara Guthrie published a tweet in Plainville on May 20. Summarize the content of that tweet in a few words. " @BULLET what + who + when → where: Given a brief summary of the microblog's content, author, and date, find where it was published. For example, " Angela Barnett published a tweet about stylish watches on May 5. Where was that tweet published? " @BULLET where + what + who → when: Given a microblog's location, a summary of its content, and its author, find when it was published . For example, " Bradley Church published a tweet about loss of appetite in Plainville. When was that tweet published? " @BULLET when + where + what → who: Given a microblog's date, location , and a summary of its content, find its author. For example, " Someone published a tweet about Sham Wow in Uptown on May 11. Who is the author of that tweet? " </p><p>An answer key for all task instances was created in order to score responses as accurate or inaccurate. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Prompts for Exploration and Observation</head><p>After each block of tasks, participants were prompted to explore the data using the visualization and record observations relevant to the epidemic in the data model. The instructions are: </p><p>Explore the data using the visualization, then write down your observations about the data below. You should record observations about the data that are relevant to the following questions: " Do you find evidence in the data of an outbreak? " ; " If so, when and where do you think it started? And how might the infection be transmitted, and is it contained? " Please number each observation. </p><p>These specific questions were taken from the instructions for MC1 <ref type="bibr" coords="5,554.05,269.84,9.71,8.02" target="#b0">[1]</ref>; they are the questions MC1 participants were asked to answer by exploring and observing a superset of the data we used. We provided these as replacements for the initial analysis questions asked as part of the insight-based methodology <ref type="bibr" coords="5,429.44,309.69,13.74,8.02">[26]</ref>. In response to findings from our pilot study, we added a minimum time for the observation prompt before each participant could move ahead to the next block of visualization tasks. During this time, participants could not access the " Next " button. When an onscreen timer showing the amount of time remaining (sec) reached 0, the " Next " button became available. At that point, participants could either continue exploring and making observations about the data or move onto the next block of tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Participants</head><p> We recruited 24 participants for the study, 10 men and 14 women. Participants were primarily graduate and undergraduate students whose ages ranged from 19 to 30 years (M=24.4, SD=2.6). We assigned participants randomly to the small and large dataset groups so that each had 12 people. Participant prior experience with node-link diagrams was similar in both groups. In follow-up questions after the experiment , about half the participants in each group (5 out of 12 in the small dataset and 7 out of 12 in the large dataset) responded that they 'somewhat agree' to 'strongly agree' with the statement " I have experience using visualizations of nodes and edges, " using a 7-point Likert scale. The remaining participants responded that they 'somewhat disagree' to 'strongly disagree' with that statement. No participants gave a neutral response. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Protocol</head><p>Participants were given background information about the data model and were trained for approximately 20 minutes on the four visualization designs, including the time and location filter controls in the user interface. During this training, participants performed practice trials for each task type. With the informed consent of participants, all tasks and exploration following the training were video-recorded for later analysis. Each participant in the study performed four blocks of tasks, one per visualization. Each block contained one instance of each of the four task types. Participants performed different task instances between blocks. For each task, responses were recorded and timed for later analysis. At the end of each task block, participants explored the data using the visualization for at least three minutes and recorded insights by typing into an on-screen text field. In total, each participant performed 16 tasks and four observation prompts. This part of the study session lasted 40–60 minutes on average. <ref type="figure" coords="5,501.77,726.46,30.13,8.02">Figure 1</ref>shows an example workflow for this part of the study. Ordering effects for both visualization types and task types are mitigated by counterbalancing. The order of visualization types is chosen between participants using a balanced Latin square, as is the order of task types within each visualization block for each person. Participants were asked in a post-test questionnaire to report their preferred visualization type for each of the four task types. They were also asked to rate each visualization type for ease of use, confidence in task responses, and how well the visualization helped them understand what is happening in the data model. Ratings were on a 7-point Likert scale from " strongly disagree " to " strongly agree " for statements corresponding to these properties. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.1">Insight Characteristics</head><p>Two insight characteristics were measured during each observation prompt in the study: total time spent and total domain value of observations . Total time spent had a lower bound because of the threeminute minimum time before participants could move to the next task block, as described in Section 5.4.1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scoring Domain Value </head><p>We developed a simple scoring system to assess the domain value of individual observations. From a four-user pilot study, we identified two main parts of each observation about the data model: a general claim about the data (e.g., " It looks like the outbreak started in Downtown " ), and 0 or more specific data points that are evidence for the observation (e.g., " John Doe tweeted about feeling sick – from Downtown on April 19 " ). In the scoring system, each recorded observation has a starting score based on whether or not it makes a new claim that was not previously reported by the user during an earlier observation prompt. Because participants explore the same data model repeatedly, it is important not to double-count observations that were arrived at earlier. For our purposes, a claim is a general hypothesis, question, or remark about the data model that is potentially synthesized from multiple observations. On top of the starting score, points are added to observations that include specific references to data points in the model as evidence for the claim. The total points awarded during an observation prompt is equal to the sum of scores of individual observations i in the set of observations I: base(i) = 0 if i makes no new claim 2 if i makes new claim </p><formula>(1) bonus(i) =      </formula><p>+0 if i includes no new, supporting data points +1 if 1 new, supporting data point in i +n if n new, supporting data points in i </p><formula>(2) </formula><p>score(i) = base(i) + bonus(i) </p><formula>(3) total(I) = ∑ i∈I score(i) (4) </formula><p>In this system, we expect individual observations to range from 2 (e.g., a new claim provided without details) to 5 points (e.g., a new claim with a few supporting data points). Previous insight-based evaluations scored domain values for individual insights in a similar range and also awarded points to insights based on depth <ref type="bibr" coords="6,196.95,617.19,14.19,8.02" target="#b18">[19,</ref><ref type="bibr" coords="6,213.38,617.19,10.65,8.02"> 26]</ref>. Two authors of this paper independently coded all insights from the experiment using this system. Both coders were doctoral candidates studying visualization and had experience with the datasets and visualization designs. Scores for the total domain value of each observation prompt from both coders were averaged for later analyses. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS</head><p>All statistical tests described in this section were performed using SPSS. The results include support for some hypotheses from Section 5.1 but not others: we accept H4, H9, and H10; we find partial support for H3, H5, and H8; and we reject H1, H2, H6, and H7. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1"></head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Task Performance</head><p>Overall, participants were very accurate during the study: accuracy across all participants and tasks is 96% and did not differ significantly between visualization types. Therefore, we reject hypothesis H2. We used a mixed ANOVA to analyze how the response time varied across visualization types and tasks. Average response times for all task and visualization types are shown in <ref type="figure" coords="6,465.29,337.45,30.26,8.02" target="#fig_3">Figure 3</ref>. We performed the ANOVA analysis on the log-transformed time data, as is typical in response-time analysis. Times corresponding to incorrect task answers were replaced with the mean response time for all correct responses under the same condition. Otherwise, the repeated measures analysis would exclude data from correct tasks by participants who gave one or more incorrect answer. The results showed that task type had a main effect on response time (p &lt; .001, F 3,50.743 = 13.109, with Greenhouse-Geisser correction ). Pairwise comparisons were made using Bonferroni-corrected p-values by SPSS. These comparisons showed that participants were significantly faster on the who task than on the when (p &lt; .001) and where (p &lt; .001) tasks. Participants were also significantly faster on the what than on the where task (p = .025). We did not find support for hypothesis H1 and reject it. In fact, as shown in <ref type="figure" coords="6,343.21,486.89,29.49,8.02" target="#fig_3">Figure 3</ref>, we found that the mean response time using TSS is greater than the mean response time using F for most task types in both the small and large dataset size conditions. We did not observe a main effect of visualization type on response time (p = .147, F 3,66 = 1.848) or an effect of dataset size on response time (p = .179, F 1,22 = 1.931). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Insight Characteristics</head><p>Insight characteristics measured during the study are shown in <ref type="figure" coords="6,543.05,567.06,14.95,8.02;6,307.62,577.02,36.66,8.02" target="#fig_9">Fig- ure 6 and</ref><ref type="figure" coords="6,348.18,577.02,30.67,8.02" target="#fig_10">Figure 7</ref>. We first analyzed the insight scores together with time spent on each insight task (using a log-transformation on times) with a multivariate mixed ANOVA with visualization type as the within-subject independent variable. The results showed that visualization type did not have a main effect on either the insight value score or the exploration time. We did not find evidence for H6 or H7 and reject both. We found partial support for H8: dataset size had a main effect on time (p = .041, F 1,22 = 4.702), but not on the total domain values of insights (F 1,22 = 0.092, n.s.). There was also an interaction effect between visualization type and dataset size on the total domain values (p = .035, F 3,66 = 3.031) but not on time (F 3,66 = 0.347, n.s.). We then performed a similar analysis with presentation order of the visualizations as the independent variable. This time we observed a strong main effect of presentation order on both the total domain value scores of insights (p &lt; .001, F 3,66 = 7.488) and the exploration time (p &lt; .001, F 3,38.256 = 11.621, with Greenhouse-Geisser correction). We . 5: Preferences for visualization type based on task type. From left to right, the tasks shown are who, what, where, and when queries. Columns show the number of participants (n=12 in both groups) who preferred each visualization for the task. thus found support for H9 and H10. Participants spent significantly more time on the visualization that was presented first than on the following three (p = .033, p = .011, and p = .002 respectively), and also spent more time on the second visualization than on the last one (p = .02). Participants also had higher insight scores on the first visualization than on the third (p &lt; .001) or the last (p = .005) visualization. <ref type="figure" coords="7,54.00,294.92,29.89,8.02">Figure 5</ref> shows the numbers of participants who preferred each visualization type for each task type. No participants who interacted with the large dataset preferred the force visualization for any task. TSS was preferred by more participants than any other visualization for both datasets, except on the where task. In that task, participants using the small dataset preferred SS more than TSS, and participants using the large dataset preferred TS, SS, and TSS in equal numbers. We analyzed the subjective Likert-scale ratings of the four visualizations using a multivariate mixed ANOVA. Visualization type had strong main effects on all three measures (understanding: p &lt; .001, F 3,51 = 18.374; ease of use: p &lt; .001, F 3,51 = 9.117; confidence: p &lt; .001, F 3,38.955 = 10.386, with Greenhouse-Geisser correction). Dataset size had a main effect on understanding (p = .049, F 1,17 = 4.512) and ease of use (p = .014, F 1,17 = 7.557), but not on confidence (F 1,17 = 0.705, n.s.). Pairwise comparisons of the visualization types showed that participants found the force visualization the least useful in helping them understand the dataset; on average F was rated significantly lower than TS, SS, and TSS (p &lt; .001 in all cases). TSS was rated as the most helpful for understanding the data, although it was only significantly higher than F. Thus, we find support for H4. F was rated as the most difficult to use (lower than TS, p = .003; lower than SS, p = .004; lower than TSS, p = .013). Participants rated SS easiest (not significantly higher than TS or TSS). Therefore, we found partial support for H5. Participants also felt the least confident with the F (lower than TS, p = .006; lower than SS, p = .001; lower than TSS, p = .007). They were most confident with TS (not significantly higher than SS or TSS). Therefore, we found partial support for H3. Pairwise comparisons for the two dataset sizes showed that participants generally felt that they had a better understanding of the small dataset and also found the visualizations easier to use with the smaller dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Subjective Ratings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">What Is the Best Design?</head><p>We expected that visualization designs using spatiotemporal attributes of nodes in the layout (SS, TS, and TSS) would have better task performance than F, but this was not the case. A possible explanation is that the process of using node positions along with guide marks on axes (e.g., in TS and TSS) to solve search tasks is less efficient than using the data filters for time and location. In fact, the features of these spatiotemporal layouts might have distracted participants from using filters as much as they did in the F layout. Task-execution videos showed that most participants used filtering often, even with the spatiotemporal layouts, so other factors may be involved. For instance, participants might have taken extra time to verify their answers using guide marks, and tasks in our typology might have been easy enough that this verification step added time without significantly improving accuracy. The efficiency of filtering might also account for the significant differences in average response time between task types. Overall, participants were faster on who and what tasks, which gave both location and time components in the task description. In these tasks, participants can use both location and time filters before inspecting any nodes in the visualization. In the other tasks, participants had only enough information to use one filter – location or time – based on the task description. Looking at task performance alongside user feedback, it is difficult to choose a best layout for the data model studied. The same layout with the fastest overall task performance (F) was also the one that participants felt least confident with overall and found the hardest to use overall. F was rated significantly less helpful in understanding the data than the other types. In such cases, a visual analytics designer must choose a layout by weighing competing objectives for the tool, including efficient task performance and subjective user preferences that might impact adoption rates and indicate insightfulness. When task efficiency is prioritized, F is a good layout choice in a visual analytics system with interactive, spatiotemporal data filtering. If we prioritize user preferences and subjective feedback about usability and insightfulness, SS or TSS might be a better layout. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head><p>Here we discuss what we learned about LITE through our case study and present open challenges and guidelines for using the methodology. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Limitations</head><p>We set out to develop a practical visualization evaluation method that combines components of task-based and insight-based evaluations . In doing so, we attempted to explore and mitigate the interactions or biases that North et al. warn about when combining these approaches <ref type="bibr" coords="7,359.19,546.52,13.74,8.02" target="#b17">[18]</ref>. Other limitations exist as well. A practical consideration in most user studies is the time needed to run each participant, and LITE – like insight-based methods – has an open-ended exploration component that makes it difficult to estimate how long a single participant will take. In our case study, sessions lasted from 30 to 90 minutes. This uncertainty must also be considered when designing the tasks and repetitions in the task-based portion of LITE. Conducting a pilot study is a reasonable way to discover whether the task portion is feasible alongside the insight component. LITE studies with many tasks or visualization conditions might be prohibitively lengthy for participants. A second limitation that follows from splitting time between tasks and exploration is related to the power of the results. The task-based portion of a LITE study design might have fewer trials than a dedicated task-based study design. Therefore, hypotheses could exist about task performance that can be tested in a task-only study but not in a LITE study. Third, participants in a LITE study alternate between blocks of tasks and exploration, and that context-switching might negatively impact how people perform these activities. On the other hand, it is also possible that these switches keep participants engaged and give them a sense of making concrete progress, as mentioned in Section 3. Further study is needed to understand how these context switches affect analysis behaviors with visualizations. Having evaluations of both insight characteristics and task performance is useful for the visual analytics application in our case study; the tool is intended both to promote insights about events and support routine data queries. Other visualizations might be aimed at only one of these purposes, and would be better evaluated using either benchmark tasks or an insight-based evaluation. Evaluators with both aims could opt to run separate studies with those methods, which is more time-consuming than running a single LITE study but might give more powerful results. These tradeoffs should be considered carefully. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Lessons from the Case Study</head><p>We encountered a variety of choices and challenges during our study that suggest guidelines for using the method. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">Reinforcing Instructions for Different Portions of LITE</head><p> Some participants either did not understand the instructions or forgot background information on the data provided during the training period. For instance, one participant commented during her fourth observation prompt that the outbreak " Seems more over the place this time " , even though participants were told that they would explore the same data set multiple times using different visualizations. This detail could be easy to forget since the network layouts changed between blocks of tasks. Participants who investigated the small dataset made no such observations, possibly because they were able to revisit and recognize microblogs between visualization conditions. Other participants answered the initial questions given in the prompt directly rather than providing observations about the data that confirm or disconfirm those questions. For instance, some participants began their list of observations like " 1. Yes. 2. ... " . In a few cases, observations appeared to be numbered according to the three questions in the prompt (i.e., observations specifically for those questions, with no more than three separate observations) rather than being numbered by separate insights about any of the initial questions. We interpreted comments like " yes " as a belief that the corresponding initial question was true. Guideline Be explicit about how participants should record insights . Since participants switch between different types of responses during the task and insight portions of the study, these instructions should be reinforced. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">Coder Agreement for Insights</head><p>Overall, the two coders were fairly consistent in applying the scoring scheme to assess the domain value of insights for each prompt; their scores were within 2 points of each other for 81 out of 96 prompts, or 84.4% of the time. The coding scores are positively correlated, with Pearson's r = 0.87. That said, the coders agreed exactly on a score only in 36 of the 96 prompts, or 37.5% of the time. Evaluating the scoring system in future studies could help improve the scoring rules and coder manual and therefore improve consistency in assessing the domain-value insight characteristic. As far as we know, coder consistency has not been explored in depth in the literature for insight-based evaluations. In some cases, it is unclear whether multiple coders were used to assign domain values, how well they agreed, how coding conflicts were resolved, and what expertise the coders had. We believe that the practice of reporting details of the coding process will generally benefit the development and standardization of insight-based evaluation methodologies. Guideline In the results of a LITE or insight-based evaluation, provide information about the process of coding the domain value of insights. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.3">Reduced Set of Insight Characteristics</head><p>Our study measured a subset of insight characteristics adapted from previous studies <ref type="bibr" coords="9,114.69,214.66,14.19,8.02">[26,</ref><ref type="bibr" coords="9,131.43,214.66,10.65,8.02" target="#b18"> 19]</ref>. Some insight characteristics are difficult to measure using LITE. For instance, we did not measure the time needed to reach each insight, which could be misleading in a within-subjects design that lets participants analyze the same data model over multiple iterations. Instead, the total time for exploration in each visualization condition was used, as in <ref type="bibr" coords="9,146.06,264.47,13.74,8.02" target="#b18">[19]</ref>. We also found it difficult to count the number of individual insights without using a think-aloud protocol. Our LITE case study used an on-screen text field that lets participants record observations in a manner similar to recording task responses. We relied on participants to input observations as a numbered list, but participants had different styles for doing this. One alternative is to guide users in constructing insights and evidence through a user-interface feature. For instance, Jianu and Laidlaw let users click nodes in a protein-signaling visualization to construct visual hypotheses about potential pathways, rather than having them provide unstructured text input <ref type="bibr" coords="9,231.28,364.71,13.74,8.02" target="#b13">[14]</ref> . Another possible solution that we did not test formally is using a think-aloud protocol during the insight portions of LITE. We did not divide insights into categories or label them as breadth versus depth. Instead, the scoring system for domain value distinguishes between claims and supporting evidence. In the datasets used in this study, the range in the types of comments participants made was small and hence we saw no need to impose categories. Distinguishing between insights might be more practical with a dataset that contains more initial questions or in a domain with complicated relationships among data points, like systems biology. Finally, providing the initial questions about the data model rather than asking participants for their initial questions makes it possible that participants had other unreported insights that seemed irrelevant to the specific initial questions but ultimately showed evidence of insight. Because the participants in our study were non-experts, it is a reasonable assumption that the initial questions encapsulated most of what they were able to analyze and observe. With domain experts as participants , however, there might be questions worth analyzing that would be difficult for us to predict and hard-code into the evaluation. In such cases, starting the evaluation by gathering initial questions from participants makes more sense. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Guideline </head><p>Consider the complexity of the data and participant expertise when choosing insight characteristics to measure. With a non-expert study population, provide initial analysis questions rather than requesting them from participants. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.4">Task and Workflow Considerations</head><p>We faced several workflow-related considerations during the design of the case study. First, there is a relationship among the training participants get, the specific tasks they perform, and the types of insights they are likely to report. It is possible that tasks or training direct users toward certain types of exploration activities. We deliberately tried to avoid this scenario in our case study by choosing low-level tasks that were unlikely to lead to insights on their own. An alternative approach used by <ref type="bibr" coords="9,83.11,726.46,39.82,8.02">North et al. </ref>is to give more complex tasks that can be classified into the same categories as the insights, in order to directly compare the activities that each visualization supports and promotes <ref type="bibr" coords="9,526.98,53.38,13.74,8.02" target="#b17">[18]</ref> . However , in that study, task performance and insights were measured using two separate experiments with different participants, and 'insightful' tasks could significantly interact with exploration and insights in a within-subjects design like LITE. Second, we recognized that the results in LITE would be impossible to interpret correctly if the order of visualization conditions was not counterbalanced. Because the same data is explored by each participant repeatedly with different visualizations, an ordering effect on the measured insight characteristics should be expected. In our case study, we found evidence that participants spent more time and reported more valuable observations during the earlier observation prompts than during later ones (see <ref type="figure" coords="9,384.54,173.01,29.06,8.02" target="#fig_10">Figure 7</ref> ). Counterbalancing the orderings of visualization conditions, as we did in the case study, can mitigate the effect of order on the results. Finally, based on our experience in our pilot study, which let participants effectively skip the exploration portion of LITE, we decided to require in our case study a minimum time during each observation prompt. This seemed to motivate participants to explore the data; we did not find that participants sat idly while the clock counted down, or that they ended their exploration as soon as the minimum time was finished. Participants were given as much time as needed to record and explore observations, so this approach does not affect the results as it would in an insight-based study with fixed length. That said, other ways to motivate participants during the insight portion of LITE might be more effective than a time requirement. Guideline In LITE, choose low-level tasks that will not steer participants toward insights, and be sure to counterbalance the ordering of visualizations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>We present and demonstrate a method for evaluating visualizations called layered insight-and task-based evaluation (LITE) that combines predefined tasks and exploration. The method, which measures both task performance and insight characteristics, was applied in a case study of four different designs for a spatiotemporal network visualization in a visual analytics system. The results of our case study helped us assess which design best fit different objectives for the visual analytics system, including optimizing for task efficiency or promoting insights. We also identified several guidelines for using LITE based on the study. @BULLET Choose low-level tasks that are components of realistic analysis scenarios but will not steer participants toward insights. @BULLET Counterbalance the ordering of visualizations to mitigate ordering effects in the insight component of LITE. @BULLET Consider the complexity of the data and participant expertise when choosing insight characteristics to measure. @BULLET Report details of the process of coding insights: who are the coders, how well did they agree, and how were disagreements resolved into one score? </p><p>Opportunities exist to address challenges we encountered using LITE. We are interested in better understanding how to run lightweight, insight-based evaluations of visualizations using the non-experts who are often recruited for task-based visualization studies. This work is a step toward more diverse evaluations of visualization tools and ones that evaluate multiple objectives for tools in a controlled setting. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,163.65,325.26,12.87,3.19;3,174.82,344.83,9.45,3.19;3,122.28,296.12,10.36,3.19;3,100.04,284.18,13.01,3.19;3,116.23,345.57,11.31,3.19;3,99.85,400.68,14.24,3.19;3,150.55,282.56,11.59,3.19;3,204.67,291.87,10.90,3.19;3,212.00,383.31,11.04,3.19;3,214.73,330.41,10.36,3.19;3,91.06,342.84,4.75,3.19;3,220.99,235.50,7.43,4.08;3,220.99,241.93,80.52,2.23;3,220.99,244.67,11.20,2.23;3,282.12,252.19,6.07,2.23;3,136.28,432.07,60.52,6.76"><head>George </head><figDesc>Herman tweeted on April 30 from Downtown. Summarize the content of that tweet in a few words. Submit Space-situated (SS) </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,335.78,265.42,8.51,2.37;3,335.78,277.73,8.51,2.37;3,334.47,290.04,9.86,2.37;3,337.24,302.35,7.10,2.37;3,336.37,314.66,7.93,2.37;3,334.47,326.97,9.86,2.37;3,335.93,339.28,8.37,2.37;3,333.46,351.59,10.88,2.37;3,335.49,363.90,8.80,2.37;3,336.08,376.21,8.22,2.37;3,336.08,388.52,8.22,2.37;3,336.51,400.83,7.79,2.37;3,340.59,413.14,3.71,2.37;3,476.61,234.45,7.91,4.34;3,476.61,241.30,86.10,2.37;3,541.64,249.30,6.46,2.37;3,397.26,432.07,95.85,6.76"><head></head><figDesc>about the Arcade Fire in Cornertown on May 6. Who published that tweet? Submit Time-and space-situated (TSS) </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,577.75,406.76,6.22,11.19;5,50.12,6.07,16.38,5.00;5,100.80,6.07,189.93,5.00;5,363.34,6.16,16.38,5.00;5,414.39,6.16,189.56,5.00;5,87.79,178.83,3.43,6.17;5,84.37,161.24,6.86,6.17;5,84.37,143.64,6.86,6.17;5,84.37,126.05,6.86,6.17;5,84.37,108.46,6.86,6.17;5,80.94,90.87,10.29,6.17;5,80.94,73.28,10.29,6.17;5,80.94,55.69,10.29,6.17;5,115.00,185.16,11.31,6.17;5,161.33,185.16,13.03,6.17;5,207.66,185.16,14.74,6.17;5,253.83,185.16,16.80,6.17;5,125.70,50.84,3.77,6.17;5,160.81,50.84,8.23,6.17;5,200.39,50.84,7.88,6.17;5,239.61,50.84,11.99,6.17;5,374.84,178.83,3.43,6.17;5,371.41,161.24,6.86,6.17;5,371.41,143.64,6.86,6.17;5,371.41,126.05,6.86,6.17;5,371.41,108.46,6.86,6.17;5,367.98,90.87,10.29,6.17;5,367.98,73.28,10.29,6.17;5,367.98,55.69,10.29,6.17;5,401.51,185.16,11.31,6.17;5,446.81,185.16,13.03,6.17;5,492.10,185.16,14.74,6.17;5,537.22,185.16,16.80,6.17;5,410.66,50.84,3.77,6.17;5,445.77,50.84,8.23,6.17;5,485.34,50.84,7.88,6.17;5,524.57,50.84,11.99,6.17;5,160.26,198.76,46.87,6.23;5,339.57,15.51,3.43,6.16;5,366.74,21.84,11.30,6.16;5,413.04,21.84,13.02,6.16;5,459.33,21.84,14.73,6.16;5,505.45,21.84,16.78,6.16;5,343.36,178.72,3.43,6.16;5,339.93,161.15,6.85,6.16;5,339.93,143.57,6.85,6.16;5,339.93,125.99,6.85,6.16;5,339.93,108.42,6.85,6.16;5,336.51,90.84,10.28,6.16;5,336.51,73.27,10.28,6.16;5,336.51,55.69,10.28,6.16;5,370.02,185.05,11.30,6.16;5,415.27,185.05,13.02,6.16;5,460.52,185.05,14.73,6.16;5,505.61,185.05,16.78,6.16;5,379.15,50.85,3.76,6.16;5,414.24,50.85,8.22,6.16;5,453.77,50.85,7.87,6.16;5,492.96,50.85,11.98,6.16;5,413.75,198.76,47.12,6.23"><head>1 errTSS 4.74331473961676 5.84528265619449 11.3255285939435 7.6308283907642 errTSS 12.1148796035322 2.19415316558566 13.826764839755 19</head><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,54.00,217.03,513.00,8.02;5,54.00,226.35,513.00,8.66;5,54.00,236.96,277.22,8.02"><head>Fig. 3: </head><figDesc>Fig. 3: Response times grouped by task type for each visualization type. Each participant completed each task type with each visualization type. Columns show the mean of total time spent (sec) across participants (n=12 in both (a) and (b) dataset groups) and error bars show ±1 standard error. Response times corresponding to incorrect task answers are not shown. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,0.25,4.54,19.18,7.43;6,49.54,2.70,4.22,5.07;6,100.14,4.54,199.96,7.43;6,80.79,50.27,164.95,7.51;6,123.79,58.89,78.96,7.51;6,61.81,188.45,3.48,6.26;6,61.81,169.09,3.48,6.26;6,61.81,149.74,3.48,6.26;6,61.81,130.38,3.48,6.26;6,61.81,111.03,3.48,6.26;6,61.81,91.67,3.48,6.26;6,61.81,72.31,3.48,6.26;6,92.31,194.87,3.82,6.26;6,136.08,194.87,8.35,6.26;6,182.28,194.87,8.00,6.26;6,226.21,194.87,12.17,6.26;6,216.73,77.47,36.88,6.26;6,216.73,85.58,36.20,6.26;6,16.28,71.81,40.71,6.26;6,8.28,187.92,48.72,6.26;6,19.06,125.81,41.41,6.26;6,22.19,133.92,34.80,6.26;6,381.39,50.42,164.95,7.51;6,424.39,59.04,78.96,7.51;6,362.41,188.60,3.48,6.26;6,362.41,169.24,3.48,6.26;6,362.41,149.88,3.48,6.26;6,362.41,130.53,3.48,6.26;6,362.41,111.17,3.48,6.26;6,362.41,91.82,3.48,6.26;6,362.41,72.46,3.48,6.26;6,392.91,195.02,3.82,6.26;6,436.67,195.02,8.35,6.26;6,482.87,195.02,8.00,6.26;6,526.81,195.02,12.17,6.26;6,517.32,77.62,36.88,6.26;6,517.32,85.73,36.20,6.26;6,316.88,71.95,40.71,6.26;6,308.88,188.07,48.72,6.26;6,319.66,125.70,41.41,6.26;6,322.79,133.82,34.80,6.26"><head>stder&lt;m m 0.1929960485281360.4264014327112210.48461168459756 0.414387707005374 " Did the visualization help you understand what is happening in the Did the visualization help you understand what is happening in the </head><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="6,307.62,211.99,250.38,8.02;6,307.62,221.95,250.38,8.02;6,307.62,231.27,250.38,8.66;6,307.62,241.88,37.35,8.02"><head>Fig. 4: </head><figDesc>Fig. 4: Subjective ratings of visualization insightfulness on a 7-point Likert scale collected on the follow-up questionnaire. Columns show the mean response (n=12 in both groups) and error bars show ±1 standard error. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="7,54.00,169.83,513.00,8.02;7,54.00,179.79,395.06,8.02"><head>Fig</head><figDesc>Fig. 5: Preferences for visualization type based on task type. From left to right, the tasks shown are who, what, where, and when queries. Columns show the number of participants (n=12 in both groups) who preferred each visualization for the task. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="8,335.38,432.99,6.82,12.27;8,79.03,2.91,30.74,4.98;8,148.96,2.91,23.55,4.98;8,203.32,2.91,115.66,4.98;8,79.03,7.23,18.55,4.98;8,129.57,7.23,189.42,4.98;8,79.03,17.37,20.21,4.98;8,129.57,17.37,189.41,4.98;8,80.51,178.39,3.42,6.15;8,73.66,157.92,10.26,6.15;8,73.66,137.45,10.26,6.15;8,73.66,116.99,10.26,6.15;8,73.66,96.52,10.26,6.15;8,73.66,76.05,10.26,6.15;8,73.66,55.59,10.26,6.15;8,111.05,184.70,3.76,6.15;8,155.19,184.70,8.20,6.15;8,201.74,184.70,7.86,6.15;8,246.06,184.70,11.96,6.15;8,124.43,50.82,36.24,6.15;8,199.42,50.82,35.56,6.15;8,354.42,2.82,30.74,4.98;8,404.96,2.82,189.41,4.98;8,354.42,7.32,18.55,4.98;8,403.84,7.32,192.08,4.98;8,354.42,17.45,20.21,4.98;8,403.84,17.45,192.08,4.98;8,324.31,178.39,3.42,6.15;8,324.31,160.84,3.42,6.15;8,324.31,143.30,3.42,6.15;8,324.31,125.76,3.42,6.15;8,324.31,108.21,3.42,6.15;8,324.31,90.67,3.42,6.15;8,324.31,73.13,3.42,6.15;8,324.31,55.59,3.42,6.15;8,355.03,184.70,3.76,6.15;8,399.52,184.70,8.20,6.15;8,446.41,184.70,7.86,6.15;8,491.07,184.70,11.96,6.15;8,368.92,50.82,36.24,6.15;8,443.92,50.82,35.56,6.15;8,116.67,198.76,116.04,6.23;8,340.91,434.30,6.84,12.31;8,85.32,178.98,3.43,6.17;8,78.46,158.45,10.29,6.17;8,78.46,137.93,10.29,6.17;8,78.46,117.40,10.29,6.17;8,78.46,96.88,10.29,6.17;8,78.46,76.35,10.29,6.17;8,78.46,55.83,10.29,6.17;8,115.95,185.31,3.77,6.17;8,160.22,185.31,8.23,6.17;8,206.89,185.31,7.88,6.17;8,251.34,185.31,12.00,6.17;8,129.36,51.05,36.34,6.17;8,204.57,51.05,35.66,6.17;8,329.81,178.98,3.43,6.17;8,329.81,161.38,3.43,6.17;8,329.81,143.79,3.43,6.17;8,329.81,126.20,3.43,6.17;8,329.81,108.61,3.43,6.17;8,329.81,91.01,3.43,6.17;8,329.81,73.42,3.43,6.17;8,329.81,55.83,3.43,6.17;8,360.61,185.31,3.77,6.17;8,405.23,185.31,8.23,6.17;8,452.25,185.31,7.88,6.17;8,497.04,185.31,12.00,6.17;8,374.55,51.05,36.34,6.17;8,449.76,51.05,35.66,6.17;8,343.54,198.76,169.54,6.23"><head>1 large dataset 373.49075 390.526 494.469833333333 399.567166666667 s-stderr 30.1772837120888 60.1107794087405 48.2579265723518 113.584414544363 m-stderr 44.9759903891703 49.6094329892527 88.1981433441833 large dataset 4.70833333333333 5.66666666666667 5.45833333333333 3.33333333333333 s-stderr 0.841250272036818 0.950395319131078 0.60875348712004 0.993269649168642 m-stderr 0.619928922286151 0.855758863420784 1.32496188243247 0</head><figDesc>domain value of observations per visualization type </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="8,45.00,217.03,513.00,8.02;8,45.00,227.00,513.00,8.02;8,45.00,236.31,461.03,8.66"><head>Fig. 6: </head><figDesc>Fig. 6: Insight characteristics organized by the visualization type given to participants, each of whom was prompted for observations once per visualization type. The orderings of visualization types were counterbalanced across participants. Columns show the mean of total time spent (sec) (a) and the mean of total domain value (b) across participants (n=12 in both groups) and error bars show ±1 standard error. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10" coords="8,45.00,425.52,513.00,8.02;8,45.00,435.48,513.00,8.02;8,45.00,444.80,500.38,8.66"><head>Fig. 7: </head><figDesc>Fig. 7: Insight characteristics organized by the order in which observation prompts were given to participants, each of whom was prompted once per visualization type. The orderings of visualization types were counterbalanced across participants. Columns show the mean of total time spent (sec) (a) and the mean of total domain value (b) across participants (n=12 in both groups) and error bars show ±1 standard error. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false" coords="2,308.86,27.91,246.21,58.59"><figDesc coords="2,308.86,27.91,44.70,4.58;2,308.86,33.25,28.25,4.58;2,371.87,27.91,33.08,4.58;2,371.87,33.25,46.39,4.58;2,434.02,27.91,45.14,4.58;2,434.02,33.25,56.50,4.58">Describe background of data model Initial questions: from users or provided Training for each task, each visualization condition</figDesc><table coords="2,310.65,49.42,244.42,37.07">T1 T3 Tn 
T2 O2 
… 

Vis 2 

T1 T2 T3 
Tn O1 
… 

Vis 1 
Vis k 

T2 Tn T3 
T1 Ok 
… 
Tn T1 T3 
T2 O3 
… 

Vis 3 
… 

start 
finish 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false" coords="3,60.91,2.89,391.40,381.96"><figDesc coords="3,60.91,12.65,70.92,4.22;3,60.91,20.42,71.95,4.22;3,167.02,3.15,56.63,7.71">Start Date: Sat, 30 Apr 2011 00:00:00 GMT End Date: Sun, 22 May 2011 00:00:00 GMT Location Selection</figDesc><table coords="3,87.66,2.89,364.65,381.96">Northville 
Riverside 
Downtown 
Uptown 
Plainville 

Smogtown 
Westside 
Cornertown 
Southville 
Lakeside 

Suburbia 
Eastside 
Villa 

Select all 
Deselect all 

Task 

George Herman tweeted about an outdoor hot tub on May 15. Where was that tweet 
published? 

Force-directed (F) 

Time
 Range 

Start Date: Sat, 30 Apr 2011 00:00:00 GMT 

End Date: Sun, 22 May 2011 00:00:00 GMT 

Location
 Selection 

Northville 
Riverside 
Downtown 
Uptown 
Plainville 

Smogtown 
Westside 
Cornertown 
Southville 
Lakeside 

Suburbia 
Eastside 
Villa 

Select all 
Deselect all 

Northville 
Riverside 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS </head><p> This work was supported in part by Aptima, Inc., and NSF award IIS- 10-16623. All opinions, findings, conclusions, or recommendations expressed in this document are those of the authors and do not necessarily reflect the views of the sponsoring agencies. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="9,334.88,727.63,105.82,7.13;9,457.01,728.06,109.99,6.15;9,334.88,737.10,179.25,7.13"  xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">Ieee</forename>
				<surname>Vast Challenge</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2014" to="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,54.06,232.12,7.13;10,63.26,63.52,232.12,7.13;10,63.26,72.99,204.58,7.13"  xml:id="b1">
	<analytic>
		<title level="a" type="main">Low-level components of analytic activity in information visualization</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Amar</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Eagan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Stasko</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualization, 2005. INFOVIS 2005. IEEE Symposium on</title>
		<imprint>
			<date type="published" when="2005-10" />
			<biblScope unit="page" from="111" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,82.45,232.12,7.13;10,63.26,91.92,232.12,7.13;10,63.26,101.38,45.17,7.13"  xml:id="b2">
	<analytic>
		<title level="a" type="main">A visual analytics framework for spatiotemporal analysis and modelling</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Andrienko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Andrienko</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="83" />
			<date type="published" when="2013-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,110.85,232.12,7.13;10,63.26,120.31,232.12,7.13;10,63.26,129.78,116.90,7.13"  xml:id="b3">
	<analytic>
		<title level="a" type="main">Exploratory spatiotemporal visualization: an analytical review</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Andrienko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Andrienko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Gatalsky</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Languages &amp; Computing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="503" to="541" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,139.24,232.12,7.13;10,63.26,148.70,232.12,7.13;10,63.26,158.17,96.07,7.13"  xml:id="b4">
	<analytic>
		<title level="a" type="main">D3: Data-driven documents . Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bostock</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Ogievetsky</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Heer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2301" to="2309" />
			<date type="published" when="2011-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,167.63,232.12,7.13;10,63.26,177.10,232.12,7.13;10,63.26,186.56,108.03,7.13"  xml:id="b5">
	<analytic>
		<title level="a" type="main">A multi-level typology of abstract visualization tasks. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Brehmer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Munzner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2376" to="2385" />
			<date type="published" when="2013-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,196.03,232.12,7.13;10,63.26,205.49,232.12,7.13;10,63.26,214.96,218.94,7.13"  xml:id="b6">
	<analytic>
		<title level="a" type="main">Visualization of heterogeneous data. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Cammarano</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Dong</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Chan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Klingner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Talbot</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Halevy</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Hanrahan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1200" to="1207" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,224.42,232.12,7.13;10,63.26,233.88,166.57,7.13"  xml:id="b7">
	<monogr>
		<title level="m" type="main">Multi-faceted visualization of rich text corpora</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Cao</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">H</forename>
				<surname>Gotz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Sun</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">794</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,243.35,232.12,7.13;10,63.26,252.81,232.12,7.13;10,63.26,262.28,52.91,7.13"  xml:id="b8">
	<monogr>
		<title level="m" type="main">Readings in Information Visualization – Using Vision to Think</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Card</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Mackinlay</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Shneiderman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,271.74,232.12,7.13;10,63.26,281.21,232.12,7.13;10,63.26,290.67,179.88,7.13"  xml:id="b9">
	<analytic>
		<title level="a" type="main">Evaluating information visualizations</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Carpendale</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualization</title>
		<editor>A. Kerren, J. T. Stasko, J.-D. Fekete, and C. North</editor>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="19" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,300.14,232.12,7.13;10,63.26,309.60,232.12,7.13;10,63.26,319.07,230.69,7.13"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Goal setting and procedure selection in acquiring computer skills: A comparison of tutorials, problem solving, and learner exploration</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Charney</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Reder</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Kusbit</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition and Instruction</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="323" to="342" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,328.53,232.12,7.13;10,63.26,337.99,232.12,7.13;10,63.26,347.46,203.87,7.13"  xml:id="b11">
	<analytic>
		<title level="a" type="main">How capacity limits of attention influence information visualization effectiveness. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Haroz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Whitney</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2402" to="2410" />
			<date type="published" when="2012-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,356.92,232.12,7.13;10,63.26,366.39,232.12,7.13;10,63.26,375.85,232.12,7.13;10,63.26,385.32,17.93,7.13"  xml:id="b12">
	<analytic>
		<title level="a" type="main">A systematic review on the practice of evaluating visualization. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Isenberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Isenberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Sedlmair</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Moller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2818" to="2827" />
			<date type="published" when="2013-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,394.78,232.12,7.13;10,63.26,404.25,232.12,7.13;10,63.26,413.71,232.12,7.13;10,63.26,423.17,185.07,7.13"  xml:id="b13">
	<analytic>
		<title level="a" type="main">An evaluation of how small user interface changes can improve scientists&apos; analytic strategies</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Jianu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Laidlaw</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;12</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;12<address><addrLine>New York, NY, USA, 2012</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="2953" to="2962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,432.64,232.12,7.13;10,63.26,442.10,232.12,7.13;10,63.26,451.57,128.32,7.13"  xml:id="b14">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Keim</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kohlhammer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Ellis</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Mansmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mastering the Information Age: Solving Problems with Visual Analytics. Eurographics Association</title>
		<meeting><address><addrLine>Goslar, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,461.03,232.12,7.13;10,63.26,470.50,232.12,7.13;10,63.26,479.96,232.12,7.13"  xml:id="b15">
	<analytic>
		<title level="a" type="main">Empirical studies in information visualization: Seven scenarios. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Lam</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Bertini</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Isenberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Plaisant</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Carpendale</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1520" to="1536" />
			<date type="published" when="2012-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,489.43,232.12,7.13;10,63.26,498.89,149.43,7.13"  xml:id="b16">
	<analytic>
		<title level="a" type="main">Toward measuring visualization insight</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>North</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Applications IEEE</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="6" to="9" />
			<date type="published" when="2006-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,508.36,232.12,7.13;10,63.26,517.82,232.12,7.13;10,63.26,527.28,130.04,7.13"  xml:id="b17">
	<analytic>
		<title level="a" type="main">A comparison of benchmark task and insight evaluation methods for information visualization</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>North</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Saraiya</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Duca</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="162" to="181" />
			<date type="published" when="2011-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,536.75,232.12,7.13;10,63.26,546.21,232.12,7.13;10,63.26,555.68,232.12,7.13;10,63.26,565.14,33.53,7.13"  xml:id="b18">
	<analytic>
		<title level="a" type="main">Gremlin: An interactive visualization model for analyzing genomic rearrangements. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>O &apos;brien</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ritz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Raphael</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Laidlaw</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="918" to="926" />
			<date type="published" when="2010-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,574.61,232.12,7.13;10,63.26,584.07,232.12,7.13;10,63.26,593.54,222.81,7.13"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Integrating statistics and visualization for exploratory power: From long-term case studies to design guidelines</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Perer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Shneiderman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Applications IEEE</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="39" to="51" />
			<date type="published" when="2009-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,603.00,232.12,7.13;10,63.26,612.47,232.12,7.13;10,63.26,621.93,195.42,7.13"  xml:id="b20">
	<analytic>
		<title level="a" type="main">It&apos;s about time: a conceptual framework for represetation of temporal dynamics in geographic information systems</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">J</forename>
				<surname>Peuquet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of the Association of American Geographers</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="441" to="461" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,631.39,232.12,7.13;10,63.26,640.94,232.12,6.86;10,63.26,650.32,192.18,7.13"  xml:id="b21">
	<analytic>
		<title level="a" type="main">The challenge of information visualization evaluation</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Plaisant</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Working Conference on Advanced Visual Interfaces, AVI &apos;04</title>
		<meeting>the Working Conference on Advanced Visual Interfaces, AVI &apos;04<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="109" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,659.79,232.12,7.13;10,63.26,669.25,232.12,7.13;10,63.26,678.72,232.12,7.13;10,63.26,688.18,30.55,7.13"  xml:id="b22">
	<analytic>
		<title level="a" type="main">Promoting insight-based evaluation of visualizations: from contest to benchmark repository. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Plaisant</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J.-D</forename>
				<surname>Fekete</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Grinstein</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="134" />
			<date type="published" when="2008-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,697.65,232.12,7.13;10,63.26,707.11,163.92,7.13"  xml:id="b23">
	<analytic>
		<title level="a" type="main">A field study of exploratory learning strategies</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Rieman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput.-Hum. Interact</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="189" to="218" />
			<date type="published" when="1996-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,716.57,232.12,7.13;10,63.26,726.04,232.12,7.13;10,63.26,735.50,50.47,7.13"  xml:id="b24">
	<analytic>
		<title level="a" type="main">A dual-space model of iteratively deepening exploratory learning</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Rieman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">M</forename>
				<surname>Young</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Howes</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Hum.-Comput. Stud</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="743" to="775" />
			<date type="published" when="1996-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,307.62,54.06,250.38,7.13;10,325.88,63.52,232.12,7.13;10,325.88,72.99,192.37,7.13"  xml:id="b25">
	<analytic>
		<title level="a" type="main">An insight-based methodology for evaluating bioinformatics visualizations. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">]</forename>
				<forename type="middle">P</forename>
				<surname>Saraiya</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>North</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Duca</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="443" to="456" />
			<date type="published" when="2005-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,82.45,232.12,7.13;10,325.88,91.92,232.12,7.13;10,325.88,101.38,147.88,7.13"  xml:id="b26">
	<analytic>
		<title level="a" type="main">An insight-based longitudinal study of visual analytics. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Saraiya</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>North</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Lam</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Duca</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1511" to="1522" />
			<date type="published" when="2006-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,110.85,232.12,7.13;10,325.88,120.31,232.12,7.13;10,325.88,129.78,133.04,7.13"  xml:id="b27">
	<analytic>
		<title level="a" type="main">A design space of visualization tasks. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">H.-J</forename>
				<surname>Schulz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Nocke</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Heitzler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Schumann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2366" to="2375" />
			<date type="published" when="2013-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,139.24,232.12,7.13;10,325.88,148.70,232.12,7.13;10,325.88,158.17,232.12,7.13;10,325.88,167.63,17.93,7.13"  xml:id="b28">
	<analytic>
		<title level="a" type="main">Visual analysis of large heterogeneous social networks by semantic and structural abstraction. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Shen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K.-L</forename>
				<surname>Ma</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Eliassi-Rad</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1427" to="1439" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,177.10,232.12,7.13;10,325.88,186.56,232.12,7.13;10,325.88,196.03,232.12,7.13;10,325.88,205.49,232.12,7.13;10,325.88,214.96,146.55,7.13"  xml:id="b29">
	<analytic>
		<title level="a" type="main">Strategies for evaluating information visualization tools: Multi-dimensional in-depth long-term case studies</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Shneiderman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Plaisant</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 AVI Workshop on BEyond Time and Errors: Novel Evaluation Methods for Information Visualization, BELIV &apos;06</title>
		<meeting>the 2006 AVI Workshop on BEyond Time and Errors: Novel Evaluation Methods for Information Visualization, BELIV &apos;06<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,224.42,232.12,7.13;10,325.88,233.88,232.12,7.13;10,325.88,243.35,139.91,7.13"  xml:id="b30">
	<analytic>
		<title level="a" type="main">Configuring hierarchical layouts to address research questions. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Slingsby</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Dykes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Wood</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="977" to="984" />
			<date type="published" when="2009-11" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
