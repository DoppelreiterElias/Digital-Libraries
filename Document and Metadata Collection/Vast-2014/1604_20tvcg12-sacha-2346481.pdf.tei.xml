<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T13:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Knowledge Generation Model for Visual Analytics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Dominik</forename>
								<surname>Sacha</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Andreas</forename>
								<surname>Stoffel</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Florian</forename>
								<surname>Stoffel</surname>
								<roleName>Bum</roleName>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Chul</forename>
								<surname>Kwon</surname>
								<roleName>Member, Ieee</roleName>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Geoffrey</forename>
								<surname>Ellis</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Daniel</forename>
								<forename type="middle">A</forename>
								<surname>Keim</surname>
								<roleName>Member, Ieee</roleName>
							</persName>
						</author>
						<title level="a" type="main">Knowledge Generation Model for Visual Analytics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2014.234648</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms—Visual Analytics</term>
					<term>Knowledge Generation</term>
					<term>Reasoning</term>
					<term>Visualization Taxonomies and Models</term>
					<term>Interaction</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Action Finding Visualization Model Data Hypothesis Insight Knowledge Computer Human Exploration Loop Verification Loop Knowledge Generation Loop Fig. 1: Knowledge generation model for visual analytics: The model consists of computer and human parts. The left hand side illustrates a visual analytics system, whereas the right hand side illustrates the knowledge generation process of the human. The latter is a reasoning process composed of exploration, verification, and knowledge generation loops. Visual analytics pursues a tight integration of human and machine by enabling the user to interact with the system. These interactions are illustrated in Figure 2. Abstract—Visual analytics enables us to analyze huge information spaces in order to support complex decision making and data exploration. Humans play a central role in generating knowledge from the snippets of evidence emerging from visual data analysis. Although prior research provides frameworks that generalize this process, their scope is often narrowly focused so they do not encompass different perspectives at different levels. This paper proposes a knowledge generation model for visual analytics that ties together these diverse frameworks, yet retains previously developed models (e.g., KDD process) to describe individual segments of the overall visual analytic processes. To test its utility, a real world visual analytics system is compared against the model, demonstrating that the knowledge generation process model provides a useful guideline when developing and evaluating such systems. The model is used to effectively compare different data analysis systems. Furthermore, the model provides a common language and description of visual analytic processes, which can be used for communication between researchers. At the end, our model reflects areas of research that future researchers can embark on.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Visual analytics research made great strides in the past decade with numerous studies demonstrating successes in helping domain experts explore large and complex data sets. The power of visual analytics comes from effective delegation of perceptive skills, cognitive reasoning and domain knowledge on the human side and computing and data storage capability on the machine side, and their effective coupling via visual representations. Thus far, many application papers have tested and verified different ways to instigate this human and machine collaboration to reveal hidden nuggets of information. Recent work emphasizes that visual analytics theories must go beyond " human in the loop " to " human is the loop " thinking in order to recognize and integrate human work processes with analytics (Endert et al. <ref type="bibr" coords="1,65.51,595.92,9.41,8.02" target="#b5">[7]</ref>). To achieve this goal, system, human, cognition and reasoning based theories have to be considered. Many theoretical works have also examined the role of visual analytics tools in data analysis, decision making and problem solving. Visual analytics processes span from humans high-level analytic works using their domain knowledge to low-level activities such as interacting with tools. For information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org investigated different levels of activities with regards to humans cognition models (e.g., Green et al. <ref type="bibr" coords="1,437.71,484.95,13.88,8.02" target="#b12">[14]</ref>, Kwon et al. <ref type="bibr" coords="1,504.16,484.95,13.76,8.02" target="#b15">[17]</ref>); interaction models/taxonomies (e.g., Brehmer and Munzner <ref type="bibr" coords="1,499.31,494.91,9.64,8.02" target="#b2">[4]</ref>, Norman <ref type="bibr" coords="1,547.10,494.91,13.76,8.02" target="#b23">[25]</ref>); process models (e.g., Card et al. <ref type="bibr" coords="1,436.52,504.87,9.64,8.02" target="#b3">[5]</ref>, Fayyad et al. <ref type="bibr" coords="1,501.16,504.87,9.70,8.02" target="#b6">[8]</ref>); sensemaking models (e.g., Pirolli and Card <ref type="bibr" coords="1,429.69,514.83,13.59,8.02" target="#b26">[29]</ref>). We initially sought interaction taxonomies that describe the aforementioned models. However, we lack an overarching pipeline that connects all the dots. Previously developed models (e.g., Keim et al. <ref type="bibr" coords="1,443.27,544.72,14.09,8.02" target="#b13">[15,</ref><ref type="bibr" coords="1,459.60,544.72,11.11,8.02" target="#b14"> 16]</ref>) are system-driven and are not describing in detail the human reasoning part in the visual analytics process. In particular, we have little idea how analytical components support knowledge generation processes and how analysts' intents drive the insight collection action forward. It would be valuable for future research to have an integrated framework of all processes and models relevant for knowledge generation with visual analytics. The paper aims to take the first step to establish the knowledge generation model for visual analytics. First, we build our initial process model by significantly extending the previous models <ref type="bibr" coords="1,507.24,635.59,14.09,8.02" target="#b13">[15,</ref><ref type="bibr" coords="1,523.57,635.59,11.89,8.02" target="#b14"> 16] </ref>(Section 2). Comparing with previously developing models and theories, we show how our model fits various kinds of models (Section 3). Using our model, we find areas that existing visual analytics tools can improve (Section 4). We discuss our model showing open issues, model implications and future work (Section 5). Our contributions can be described as follows. The model presented in this paper provides a high-level description of the human and computer processes within visual analytics systems which facilitates an understanding of the functionality and interaction between the components . This can be used in the design of  or in the evaluation of existing ones in terms of how their subcomponents support humans reasoning, decision making, and knowledge generation processes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">KNOWLEDGE GENERATION MODEL</head><p> Visual analytics uses data to draw conclusions about the world, a process , or an application field. It is a structured reasoning process that allows analysts to find evidence in data and gain insights into the problem domain. Our model of the knowledge generation process is based on the visual analytics process of Keim et al. <ref type="bibr" coords="2,201.66,144.57,14.09,8.02" target="#b13">[15,</ref><ref type="bibr" coords="2,217.69,144.57,11.89,8.02" target="#b14"> 16] </ref>and describes how knowledge is generated with this process. Pohl et al. <ref type="bibr" coords="2,228.96,154.54,14.82,8.02" target="#b27">[30] </ref>also discussed relevant theories that should be considered, besides a computer/system based view of the analytical process. They show that visual analytics system components, analytical procedures and human perceptual and cognitive activities and especially the interplay between these elements , lead to a complex process. The theories, namely sensemaking, Gestalt theories (describing problem solving), distributed cognition (interplay between humans and artifacts), graph comprehension theories (derive meaning from graphs/process visual information) and skill-rule-knowledge models (three-fold hierarchy of processing levels) are highlighted as important aspects of the visual analytics process. In the following sections, we define and relate common elements of the aforementioned models/fields/concepts in order to arrive at a better understanding of visual analytics in terms of computing and human processes. Our visual analytics model (see <ref type="figure" coords="2,168.18,304.00,28.85,8.02" target="#fig_5">Figure 1</ref>) is split into two parts. The computer system with data, visualization and analytic models, and the human component modeling the cognitive processes associated with an analytical session. The cloud in the model indicates that there is no clear separation between the computer and human part, as both parts are required for data analysis. Computers miss the creativity of human analysis that allows them to create surprising, often subtle or hidden connections between data and the problem domain. Humans are not able to deal efficient and effectively with large amount of data. In visual analytics the connection between the human and computer uses the humans interaction abilities and perception. Knowledge generation in visual analytics comprises of abductive, deductive, and inductive reasoning processes. For a detailed definition and discussion of these reasoning processes see Peirce <ref type="bibr" coords="2,264.62,433.55,15.06,8.02">[27] </ref>and Magnani <ref type="bibr" coords="2,79.53,443.51,13.83,8.02" target="#b19">[21]</ref>. Abductive reasoning processes formulates hypotheses from observations that are unexpected or cannot be explained with existing knowledge. Assuming that these hypotheses are true, expectations of effects, patterns, or relations in the analyzed data are deduced. Through interactions with visual analytics systems, analysts try to find evidence and detect patterns in data to verify or falsify the hypotheses, which is an inductive reasoning process. We decided to model human cognitive processes with loops, because analysis does not follow deterministic rules but is rather chaotic or spontaneous nature. Analysts are often working on different hypotheses, tasks, or findings and can consequently be working on several loops in parallel. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Computer 2.1.1 Data</head><p>The starting point of all visual analytic systems is data. Data describes facts <ref type="bibr" coords="2,63.96,596.94,10.41,8.02" target="#b6">[8] </ref> in structured, semi-, or unstructured manner. It must be representative and related to the analytical problem, otherwise, the analytical process is unlikely to reveal meaningful relationships in the problem domain. In the visual analytics process, data creation, gathering and selection processes often determines the quality of the data. During an analysis, additional data can be created by automatic methods (e.g., clustering or classification) or by manual annotations. Hence, provenience information about data containing details about creation, gathering, selection , and preprocessing is important to estimate the trustworthiness of analysis results (see also <ref type="bibr" coords="2,143.89,686.61,13.36,8.02" target="#b28">[31]</ref>). The term metadata describes second order data or " data about data " . The usage of this term is ambiguous depending on the domain and interests of users. In addition to provenience data, metadata describing the structure of data is usually handled by visual analytics system to access and display data appropriately. This sort of metadata is usually not subject to analysis as it describes mainly data formats, which is necessity of any kind of data. The term metadata is also often used for data describing or summarizing other data, e.g., keywords or topics for documents or images. In the scope of data analysis this descriptive metadata is treated similar to data and we see no benefit or reason to treat this data differently, therefore the term data also includes this sort of metadata. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Model</head><p>Models can be as simple as descriptive statistics describing a property of a subset of the data or as complex as a data mining algorithm. The KDD process leads to models from data (see <ref type="figure" coords="2,448.85,156.78,29.00,8.02">Figure 3</ref>). These models serve different purposes in the visual analytics process. Simple analysis tasks might be solved by calculating a single number that confirms or rejects a preconceived notion/expectation. For instance, a statistical test can lead to a conclusion whether or not to trust a hypothesis. Complex patterns or abstractions found by data mining methods can be used in visualizations by showing, for instance, clustering or classification results visually. In addition, the automatically created model can be analyzed or visualized to derive insights. For example, logistic regression models learn weights of features, which can be used to identify most important features or feature combination. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Visualization</head><p> A different path from data to knowledge is the information visualization pipeline using data visualizations (see <ref type="figure" coords="2,466.38,300.02,29.68,8.02">Figure 3</ref>). Visualizations use data or models generated from the data and enable analysts to detect relationships in the data. In visual analytics, visualizations are often based on automatic models, for instance, clustering models are used to group data visually. Also, a model itself can be visualized, for instance, a box plot shows the data distribution of a dimension. Visualization methods for a model may vary depending on the state of the visualization. For example, in semantic zooming a visualization might use different properties of a model depending on the zoom level. Visualization is often used as the primary interface between analysts and visual analytics systems whereas understanding the model often requires more cognitive efforts. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Exploration Loop</head><p> The exploration loop describes how analysts interact with a visual analytics system in order to generate new visualizations or models and analyze the data. Analysts explore data supported with the visual analytic system by interactions and observing the feedback. Actions taken in the exploration loops are dependent on findings or a concrete analytical goal. In case a concrete analysis goal is missing, the exploration loop becomes a search for findings, which may lead to new analytical goals. Even when the exploration loop is controlled by an analysis goal, the resulting findings are not necessarily related to it but can lead to insights solving different tasks or opening new analytical directions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Action</head><p>Different meanings of actions are present in the InfoVis community as they may be defined with different granularities or with differing relations. Pike et al. <ref type="bibr" coords="2,380.74,586.51,14.89,8.02" target="#b25">[28] </ref>illustrate that actions may concern user goals and tasks on the one hand and interactive visualizations on the other hand. According to recent interaction taxonomies (e.g., Brehmer and Munzner <ref type="bibr" coords="2,343.74,616.40,9.55,8.02" target="#b2">[4]</ref>), simple interactions, How, are related to higher level concepts, Why. In our definition, actions refer to individual tasks that generate tangible , unique responses from the visual analytics system. For instance, a task can be to visualize a particular data property or calculate a model of a relationship in the data. Actions derived from hypotheses are usually complex actions, for instance, use a specific visualization method that has the potential to show interesting data. Actions derived from findings are normally simple actions, such as changing the visual mapping of a visualization or selecting a different parameter for model building. In visual analytics, analysts freely choose between visualization and modeling or a combination of both for their actions. Actions naturally provoke interactions of analysts with visual analytics systems. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Computer Human </head><p>Fig. 2: Detailed part of the process model including action and cognition paths. Actions can either lead directly to visual analytic components (blue arrows) or to their mappings (blue, dashed arrows). Humans can observe reactions of the system (red arrows) in order to generate findings. We name actions dealing with data gathering or data selection as preparation action because these actions are used to prepare data for the visual analytics process (<ref type="figure" coords="3,157.32,321.15,27.95,8.02">Figure 2</ref>). Actions taken to create models are summarized as model building actions which in turn are related to the KDD process and its configuration. Application of a model is termed as model usage, which refers to actions such as calculating a statistic or cluster data. Visual mapping actions are used to create data visualizations, and model-vis mapping actions are those which map models into visualizations. Manipulation of a visualization changes the viewport or highlights interesting data in the visualization without changing the mapping of data to the visualization. All these actions are observable as interactions between analysts and a visual analytics system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Finding</head><p>A finding is an interesting observation made by an analyst using the visual analytics system. The finding leads to further interaction with the system or to new insights. For example, findings from data inspection can be missing values or other data properties affecting the further analysis and require special data processing. In the case of visualizations or models, a finding can be a pattern, a conspicuous model result, or an unusual behavior of the system. Bertini et al. state that " a pattern is made of recurring events or objects that repeat in a predictable manner. The most basic patterns are based on repetition and periodicity. " <ref type="bibr" coords="3,287.19,535.75,18.76,8.02;3,53.33,545.71,11.88,8.02">[2, p. 13] </ref>Patterns in data can be detected with automatic analytical methods or humans may detect patterns using their visual perception and cognition skills. Findings are in principle not limited to data, visualizations, or models but comprise of anything interesting to an analyst, e.g., an unexpected high number or a word or statement in some text. In our definition, a finding is independent from the problem domain, however to make an analytical use of a finding, the analyst has to interpret them in the context of the problem domain. Although findings are usually associated with detecting a visual pattern, the lack of a pattern, when expected by an analyst, is also considered a finding. As shown in <ref type="figure" coords="3,87.98,646.05,28.44,8.02" target="#fig_5">Figure 1</ref>, findings do not necessarily lead to new insights (see Section 2.3.2) but may trigger basic actions, such as manipulating the viewport of a visualization to show a region in more detail. Analysts come across findings by observing the feedback from the system or examining visualizations and models, which in turn can lead to further actions. The exploration loop can be characterized as a searching activity by using the system to reveal useful findings to solve an analysis task. Analysts might frequently change their exploring strategies and switch between models and visualizations to collect different findings. The strategies and analysis directions in the exploration loop are guided by an exploration goal defined in the verification loop. The actions and findings in the exploration loop are closely related to the visual analytics systems. Analysts gain a new insight when they are able to understand the findings and are able to interpret them in the context of the problem domain. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Verification Loop</head><p>The verification loop guides the exploration loop to confirm hypotheses or form new ones. To verify a concrete hypothesis, a confirmatory analysis is conducted and the exploration loop is steered to reveal findings that verify or falsify the hypothesis. Analysts gain insights when they can interpret findings from the exploration loop in the context of the problem domain. Insights may lead to new hypotheses that require further investigation. Analysts gain additional knowledge when they assess one or more trustworthy insights. Findings during exploration my contribute to the verification of a concrete hypothesis but insights emerging from exploration may not be related to the examined hypothesis. It is often the case that new insights solve different analysis questions or open up new ones. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Hypothesis</head><p>Hypotheses play a central role in the visual analytics process. An hypothesis formulates an assumption about the problem domain that is subject to analysis. Analysts try to find evidence that supports or contradicts hypotheses in order to gain knowledge from data. In this respect the visual analytics process is guided by hypotheses. Concrete hypotheses can be tested with statistical tests or data visualizations when the data contains the necessary information. Unfortunately, hypotheses are often vague, such as the assumption that there are unknown factors that have an influence on the problem domain. In such cases an exploratory analysis strategy allows analysts to come up with more concrete hypotheses that are used for further analysis. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Insight</head><p>In the InfoVis community, insight has a variety of definitions. Saraiya et al. define insight as " an individual observation about the data by the participant, a unit of discovery " <ref type="bibr" coords="3,436.47,666.68,33.09,8.02">[33, p. 2]</ref>. North <ref type="bibr" coords="3,500.73,666.68,15.06,8.02" target="#b24">[26] </ref>takes another view and lists some important characteristics of an insight such as being complex, deep, quantitative unexpected and relevant, and going beyond an individual observation of the data. Yi et al. <ref type="bibr" coords="3,482.60,696.57,14.93,8.02" target="#b40">[43] </ref>go one step further and also consider the processes that involve insights. They focus on how people gain insight in information visualization and identify four types of insight-gaining processes, however, they argue that there is no common definition of insight. Chang et al. <ref type="bibr" coords="3,476.56,736.42,10.57,8.02" target="#b4">[6] </ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interaction Taxonomies </head><p>Computer Human Data <ref type="figure" coords="4,45.00,280.48,19.56,8.02">Fig. 3</ref>: Relating the process model for knowledge generation in visual analytics to other models and theories. Similarity is illustrated by color and position. A detailed illustration of interactions between the human and computer is shown in <ref type="figure" coords="4,379.29,290.44,29.02,8.02">Figure 2</ref>. definitions of insight: the cognitive science insight as a moment of enlightenment, an " Ah Ha " moment, which can occur spontaneously, and an advance in knowledge or a piece of information. Our definition is closer to the latter, where the analyst interprets a finding, often with previous domain knowledge, to generate a unit of information. Hence, an insight can be quite small, such as realizing that there is a relation between several properties of the data, to something more important and potentially significant. So, insights are different from findings in the sense that insights have an interpretation in the problem domain, what we not required for findings. For instance, a finding might support a hypothesis, which may convince the analyst and lead to the insight that the hypothesis is reliable. An analyst gains insights by collecting enough evidence to create a new hypothesis about the application or, in the case of very strong evidence, even new trusted knowledge. We consider an insight not directly as knowledge, because weak evidence might lead to an insight that needs further verification and becomes a hypothesis. For instance, finding a cluster in a visualization during an exploratory analysis might lead to the insight that there is a cluster with different properties, but this insight should at first be considered as a new assumption or hypothesis that has to be validated. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Knowledge Generation Loop</head><p> Analysts form hypotheses from their knowledge about the problem domain and gain new knowledge by formulating and verifying hypotheses during the visual analytics processes. When analysts trust the collected insights they gain new knowledge in the problem domain that may also influence the formulation of new hypotheses in the following analysis process. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Knowledge</head><p> Data analysis usually starts with data and one or more analysis questions . In addition, analysts bring in their knowledge about the data, the problem domain, or visual analytic tools and methodology. This prior knowledge determines the analysis strategy and procedure. During the visual analytics process analysts try to find evidence for existing assumptions or learn new knowledge about the problem domain. In general , knowledge learned in visual analytics can be defined as " justified belief " <ref type="bibr" coords="4,71.34,686.61,9.40,8.02" target="#b0">[2]</ref>. The reasoning processes in visual analytics enables analysts to gain knowledge about the problem domain from evidence found in data. The evidence has different qualities, which directly affects the trustworthiness of the concluded knowledge. The evidence collection route also impacts the trustworthiness. For example, an outcome of a statistical test of an hypothesis may be perceived more trustworthy than a pattern found in a visualization. Depending on the collected evidence, an analyst has to decide whether enough evidence was collected to trust an insight and accept it as new knowledge or whether it is in need of further examination, e.g., analysis with different data or discussions with domain experts. Assessing the trustworthiness of new knowledge requires a critical review of the overall analysis process starting from data gathering. As well as new knowledge about the problem domain, analysts gain knowledge about data, e.g., patterns in the data or its quality. They also gain experience with the visual analytics systems and methodology. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RELATION TO OTHER MODELS</head><p> This section covers the most important related models that have influenced the model presented in the paper and also aims to offer a big picture of the whole knowledge generation process in visual analytics. <ref type="figure" coords="4,307.62,462.76,29.31,8.02">Figure 3</ref>illustrates related models and our knowledge generation model for visual analytics. We have used the same color codes of the original model <ref type="bibr" coords="4,331.97,482.69,14.12,8.02" target="#b13">[15,</ref><ref type="bibr" coords="4,348.33,482.69,11.91,8.02" target="#b14"> 16] </ref>to highlight related areas in our model. Feedback loops of other models (e.g. InfoVis pipeline) are replaced by our extensions on the human side. Each action results in a feedback loop via finding that may lead to new exploration loops or crosses over to higher level loops. Relevant theories are grouped in three areas according to their focus on interaction, human aspects or systems. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Systems</head><p>Card et al. propose the reference model for information visualization <ref type="bibr" coords="4,307.62,576.49,10.50,8.02" target="#b3">[5] </ref>that describes visualizations as data connected to visual mappings perceived by humans. The InfoVis-Pipeline contains the main components of Raw Data, Data Tables, Visual Structures and Views and transformations/mappings between these components which can be manipulated through Human Interactions. Fayyad et al. <ref type="bibr" coords="4,370.40,626.83,10.57,8.02" target="#b6">[8] </ref>describe the Knowledge Discovery Process in Databases (KDD) as follows. KDD is the process of making sense out of data using data mining techniques at the core. The process includes the mapping of low-level data into more compact, abstract or useful forms using data mining models with the goal to discover or extract patterns that can be turned into knowledge. The KDD process consists of nine steps and represents an interactive and iterative process. Examples for interactions are selecting and filtering for the relevant data, choice of appropriate data mining methods or parameter refinement. The goal of these actions is to bring in the domain expertise of the human in order to find meaningful patterns. At each step the user might make and add decisions that cannot be handled automatically. The KDD process steps are included in <ref type="figure" coords="5,180.50,191.75,29.02,8.02">Figure 3</ref>. As a basis for our knowledge generation model for visual analytics we take and extend the process model by Keim et al. <ref type="bibr" coords="5,238.30,212.25,14.09,8.02" target="#b13">[15,</ref><ref type="bibr" coords="5,254.38,212.25,10.57,8.02" target="#b14"> 16]</ref>. The main components of the model are Data, Models, Visualization and Knowledge each representing a stage of the process. Also a Feedback loop is present going from knowledge back to data. At and in between of each stage there are transitions. The visual analytics process consists of the two parts, Visual Data Exploration going from data via visualization to knowledge and Automated Data Analysis going from data via models to knowledge, as well as of their connection. Actions on the data may be performed in order to select, filter or preprocess the data. The data is then mapped to a visualization (visual mapping) and to models (data mining). Model parameters and findings are visualization and the user may interact with the visualization or refine parameters of the model in order to steer the analysis process. Knowledge can be derived from visualizations, automatic analysis and preceding interactions between visualizations, models and the human. <ref type="figure" coords="5,63.96,362.25,31.85,8.02">Figure 3</ref>relates visual analytics components to the InfoVis and KDD system pipelines. The InfoVis pipeline corresponds to data, visualization, and the visual mappings, whereas the KDD process model is represented by data, model, and their mapping. Furthermore the visual analytics process model includes human computer interaction. Actions can be performed at each stage, namely data, visualization, model and their mappings. The economic model of visualization by van Wijk describes contexts in which visualizations operate <ref type="bibr" coords="5,169.04,442.52,15.02,8.02" target="#b37">[40] </ref>(<ref type="figure" coords="5,190.13,442.52,28.47,8.02" target="#fig_2">Figure 4</ref> ). In brief, data is transferred into a visualization that can be perceived by a human through an image. Based on perception, the human generates knowledge over time which drives interactive exploration through changes to the visualization specification. Green et al. <ref type="bibr" coords="5,161.70,482.37,14.82,8.02" target="#b12">[14] </ref>add to van Wijk model, arguing that perception has an important role in interactive exploration and that the act of exploration and associated reasoning often leads to knowledge acquisition. These relate to the exploration and knowledge generation loops of our model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Interaction</head><p>Norman describes a model for actions containing Seven Stages of Action <ref type="bibr" coords="5,79.19,566.49,13.77,8.02" target="#b23">[25]</ref>. At the beginning of each action each human needs a goal to be achieved. Afterwards, the human has to perform an action to manipulate something. The last step is to check if the goal was achieved. These two subprocesses are called Execution and Evaluation. Based on previous actions the action cycle is traversed several times. The model also explains two major problems that occur when interacting with computer systems. The Gulf of Execution indicates if humans do not know how to perform an action while the Gulf of Evaluation indicates that humans are not able to evaluate the result of their actions. The Goal concept of the stages of interaction model matches to our Hypothesis as a starting point. The Execution path is leading from Goal via an action to the World. As a result analysts evaluate observations of the World in several steps (see <ref type="figure" coords="5,164.62,686.04,28.89,8.02">Figure 3</ref>). Several interaction taxonomies exist which focus on different aspects , fields and domains and attempt to structure different kinds of interaction at different levels of abstraction. Most of the well-known taxonomies focus on one or two fields, e.g. visualizations (Shneider- man <ref type="bibr" coords="5,72.15,736.42,13.59,8.02" target="#b33">[36]</ref>), reasoning (Gotz et al. <ref type="bibr" coords="5,177.27,736.42,14.49,8.02" target="#b10">[12]</ref>) or data processing (<ref type="bibr" coords="5,270.49,736.42,33.90,8.02;5,316.62,53.38,20.82,8.02">Bertini et al. [2]</ref>), rather than all possible interactions in visual analytics. Recent publications attempt to structure interaction using the dimensions of Why (the purpose of the task), How (methods used to achieve this) and What (necessary inputs/outputs) (Brehmer and Munzner <ref type="bibr" coords="5,519.08,83.27,9.50,8.02" target="#b2">[4]</ref>, Schulz et al. <ref type="bibr" coords="5,327.45,93.23,13.34,8.02" target="#b31">[34]</ref>). There are also recent taxonomies that try to integrate existing taxonomies out of different fields into a sound interaction taxonomy for visual analytics (e.g. von Landesberger et al. <ref type="bibr" coords="5,502.80,113.16,13.59,8.02" target="#b38">[41]</ref>). Taking the taxonomy of Brehmer and Munzner <ref type="bibr" coords="5,446.49,123.12,10.39,8.02" target="#b2">[4] </ref>as an example there are higher level goals that an analyst might pursue (why) and lower level operations that can be performed (how) on a specific target (what). High and low level interactions are both covered by the action concept. However they can be distinguished when considering the associated loops. High level actions are inspired by the verification loop and are based on insights and hypotheses whereas low level actions are influenced by the exploration loop that covers a sequence of simple actions and findings. Our process model implies that each action results in a feedback loop and is perceived and processed by the human. Our model description of action-types also shows the relevant interactions for visual analytics that are both visualization and model centric. Also mentionable are two mantras characterizing the analysis process for information visualization and visual analytics because they shed light on human analysis strategies. Shneiderman proposes the Visual Information Seeking Mantra that summarizes the basic principles of many visual design guidelines <ref type="bibr" coords="5,455.70,282.99,14.07,8.02" target="#b33">[36]</ref>: Overview first, zoom and filter, then details-on-demand. Also Keim proposes a slightly different Visual Analytics Mantra <ref type="bibr" coords="5,409.00,302.92,14.08,8.02" target="#b14">[16]</ref> : Analyse First -Show the Important - Zoom, Filter and Analyse Further -Details On Demand. Both start with an overview/aggregation approach and end in a refinement of their hypothesis and analysis. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Human Cognition, Sensemaking and Reasoning</head><p>Humans can observe visualization or model changes that can be used for the knowledge generation process. The data may also be inspected directly. Pirolli and Card present the Sensemaking Process <ref type="bibr" coords="5,506.63,396.76,14.92,8.02" target="#b26">[29] </ref> as a description of intelligence analysis. Central terms are the shoebox, schemas (that are a set of patterns around the important elements in the tasks), hypotheses and a representation. Sensemaking tasks are described as processes consisting of information gathering, the information representation as a schema, the generation of insight and finally the generation of some knowledge product. The first loop is called the foraging loop followed by the sensemaking loop. Bottom-up or top-down-procesess are possible. That indicates that the model does not have a fixed entry point which depends on the type of task. The model shows the data and process flow with many feedback loops. Our model splits the Sensemaking Loop in three sub loops. In visual analytics it is also possible that the system may learn from the analysts actions allowing the system to support the user with visualization or action propositions. That is why the loop is leading through the system (see <ref type="figure" coords="5,473.13,536.24,29.10,8.02">Figure 3</ref>). Hypotheses are generated as an entry point for an analysis process leading to repeated exploration cycles. The field of reasoning and decision making both depend on the construction of mental models or scenarios of relevant situations. According to Legrenzi et al. <ref type="bibr" coords="5,393.47,586.52,14.97,8.02" target="#b17">[19] </ref>the key components of decision making are Information Seeking, Making Hypotheses, Making Inferences, Weighing Advantages and Disadvantages and Applying Criteria to make Decisions. The Human Cognition Model (HCM) proposed by Green et al. <ref type="bibr" coords="5,552.10,626.83,14.90,8.02" target="#b12">[14] </ref> can also be applied to visual analytics. A major problem in visual analytics is that human cognition is often assumed to be an over simplified black box. Information discovery and knowledge building are at the core of the HCM. Information is presented by the computer that humans can perceive and directly interact with in order to focus their attention. The process of discovery of patterns or relations is a primary stage of knowledge that can be created within the knowledge building process. The computer works to counter the humans limited working memory as well as some cognitive biases, such as confirmation bias. Central parts of the HCM are shown in <ref type="figure" coords="5,409.07,726.46,28.69,8.02">Figure 5</ref>. The HCM also includes guidelines for discovery and knowledge building. The cognition of relevant terns and schema that can be derived from insights (verification loop) and finally to some knowledge product (knowledge generation loop) plays a central role in the human part of our model. All elements of the HCM can also be found in the knowledge generation model. The key element Discovery describes the overall process, whereas the other subconcepts all can be placed into our model and related to our concepts. For example, the generation and analysis of hypotheses is a central part of our model, because evidence (proof/disproof) is collected as the basis for drawing conclusions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MODEL APPLICATION</head><p>In this section we illustrate that our model can be applied to systems on several levels. Firstly, the interaction possibilities can be examined according to our definition of actions in Section 2.2.1 and shown in <ref type="figure" coords="6,45.00,343.51,28.43,8.02">Figure 2</ref>. Secondly, we can check if and how a system supports each of the individual loops. Thirdly, we can use our model for a comparative assessment. In the following we will demonstrate a detailed model application with Jigsaw <ref type="bibr" coords="6,130.50,373.40,9.61,8.02" target="#b7">[9,</ref><ref type="bibr" coords="6,141.86,373.40,11.89,8.02" target="#b36"> 39] </ref>and a comparative high level assessment of systems from different application domains. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Actions in Jigsaw</head><p>In the following section, we investigate Jigsaw in terms of supported actions. It is important to note that in our model each of these actions leads to its own feedback loop. Therefore, we pay special attention to system components that are capable of accepting human inputs beyond fully automated implementations. We also highlight some areas of the system that might accept more user input for amplifying user interactions. Data preparation is not fully supported. While loading the data, the user has no possibility of adjusting any of the data preprocessing or transformation steps. It is also not possible to change those once the data has been parsed and loaded. Users may find missing data, but such manipulation must be done outside Jigsaw. Model building is done automatically, but some views provide possibilities of adjusting the underlying models. For example, the Document Cluster View allows users to select documents as a cluster seed, which can be used when the document clusters are computed. After that, the user-generated cluster seeds become part of the model used by the application. In terms of the visual mapping, Jigsaw offers some basic functionalities . In some views, users can select the background of the visualization or choose which attribute is mapped to the color of a visualization entity. Taking the color mapping as an example, there are a number of different possibilities to define such mappings, like a non-linear color scale, or the selection of the mapped colors. In this application, the authors left out any of those manipulation possibilities, and force the user to accept their pre-defined color mapping schemes. Model usage is supported implicitly, because most of the visualizations require special models. In some views, like the Document Grid, there are different document orderings and similarity measures to choose from. This is an example of a per-visualization model usage, which can be adjusted by the user. The model-vis mapping is available in almost all views, but only at a basic level. This includes various ordering, sorting and filtering options. </p><p>In general, though, this mapping is done as the developers designed it, and does not allow the user to change much. Visualization manipulation capabilities are mostly used to highlight document instances. There are also possibilities of manipulating and changing the visual appearance of a view. For example, in the Circular Graph View, single terms can be selected, and the connections of this term to all others are displayed. In this examination, we show that Jigsaw supports all actions we proposed in our model. It allows the visualization of different models based on the same data set, the visual mapping can be adjusted as designed by the authors, and the model-vis mapping can be modified to fit different analytical questions. In order to achieve a stronger coupling between the visualization and the underlying model, the interactions could be extended to modify the underlying model or algorithm parameters , for example when the user moves a document to another cluster in the Document Cluster View. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Knowledge Generation in Jigsaw</head><p>Having examined what actions are supported by Jigsaw, we now focus on an evaluation of the three loops, which are part of the reasoning process as defined in Section 2. Undoubtedly, describing the human reasoning processes using a visual analytic system is complicated. This involves a variety of aspects from perception, cognition and reasoning. The detailed description and evaluation of these processes exceed the scope of this paper and requires a study with expert users. We therefore limit this examination to a description of how Jigsaw supports human reasoning. The exploration loop is broadly supported by Jigsaw, by providing a number of specialized visualizations for different analytical questions. For example, users can explore given data sets, to get an impression of the contained topics, by opening the Document Cluster view which gives a labeled view of document clusters. It is also possible to modify the number of generated clusters while exploring a once-generated cluster view. The history of consecutive runs of the clustering algorithm with different parameters is stored. This allows for assessment of parameter changes with respect to topic changes. All views include a bookmark feature, which can be used to switch between different saved states of the visualization. As a result, users can capture and annotate findings that might be of further interest or of high importance for further analysis. Bookmarks can be used to store the result of different runs of the exploration loop, which in turn is done by utilizing the actions as described in the previous Section 4.1. The verification loop, tightly integrated with the exploration loop, guides users to develop findings into insights. These findings from the exploration loop can be used to verify or falsify a concrete hypothesis, which is the beginning of knowledge generation. The second investigative scenario given by Görk et. al. in <ref type="bibr" coords="6,437.12,516.85,10.33,8.02" target="#b7">[9] </ref>contains some questions which can only be answered by using the verification loop. In one of the examples, Jigsaw is used to examine the sentiment of car reviews. This is done to verify the car rating, which is given as a numeric score. The sentiment, displayed in the Document Grid, is expected to agree with the score in a way, that highly rated cars have more positive reviews and those with bad ratings have more negative reviews. In this example, the positive correlation of two measures is used to verify a hypothesis, which had been inferred based on product reviews contained in the analyzed data set. Natively, Jigsaw does not support the concepts of findings nor hypotheses. Although, the Tablet View displays bookmarked states of visualizations that can be organized, annotated and connected manually. This can be used to structure findings, derive insights, and connect insights to hypotheses which can be added to the view and refined by the user during the analysis process. This must be done manually, because Jigsaw does not provide any automated support of this process. <ref type="figure" coords="6,364.28,676.25,34.01,8.02">Figure 6c</ref>shows an example for hypotheses validation using the Tablet View. Support for the knowledge generation loop is challenging, because knowledge generation is a process done entirely by the user, and involves concepts like trust or reasoning. In addition to these human factors, user's domain knowledge plays an important role, which is hard to incorporate, because it is difficult to externalize. Depending Fig. 6: Illustration of validation steps using Jigsaw. In 6a left, the person Daniel Keim (left list) is connected to the concept of text, displayed on the right. To find evidence for this fact, the Document Cluster View of the publications is opened (6b). After inspection of the cluster labels, a document from the visualizing,interaction,text cluster is examined in detail. This document is evidence that the fact presented in the list view in 6a is true. An example for the Tablet View can be seen in 6c. on the nature of the problem, the required kind and necessary level of support varies. An example would be the automatic search and suitable presentation of further evidence for a given hypothesis, which has been already verified, but is not yet trusted enough to qualify as knowledge. If the Tablet View has been used during the verification loop to externalize the analysis process, the view can be helpful in the knowledge generation loop too. We have showed that Jigsaw supports the three feedback loops which are part of the inductive reasoning process, and the amount of possible automated support varies. Starting with the exploration loop, automated support is based mainly on predefined models, and is therefore limited by the analytic possibilities of the system. Going a step further to the verification loop, it gets harder to provide adequate automated support. The variety of different hypothesis types is an important reason for this. It is even more difficult to extend a system to support the knowledge generation loop, due to the increasing influence of human and other external factors, which cannot easily be learned and represented by computers. This makes it difficult to incorporate them in an automated process supporting knowledge generation. Further implications of loop automation are discussed in Section 5.3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparative System Assessment</head><p> In this section, we provide a high level assessment of different systems from data mining, information visualization, visual analytics and provenance domain. The different natures of these systems illustrate the general applicability of our model on applications that deal with data, provide visualizations, and are designed to generate knowledge. The comparison is shown in <ref type="figure" coords="7,156.85,477.23,29.01,8.02" target="#fig_4">Figure 7</ref>. At first, we assess Knime <ref type="bibr" coords="7,162.58,487.27,11.34,8.02">[1]</ref>(Version 2.9.1), which supports the interactive creation and execution of data mining pipelines. Data preparation and inspection, model building, model observation, and the model-vis mapping support is excellent, which is a good foundation for the exploration loops. The available data visualizations are on a basic level and allow brushing interactions only. Besides that, Knime provides no explicit support for the verification and knowledge generation loops, because there exist no tools to organize findings, derive insights, or connect hypothesis with insights. As a substitute, separate paths for the organization of findings and hypotheses can be added to an already existing pipeline. This is a possible way of recording the actions leading to a pipeline outcome, which can contribute to the knowledge generation process. Next, we assess Tableau Desktop (Version 8.2 PE), which offers a number of visualizations that can be interactively adjusted by the user. Tableau is a representative of applications from the information visualization domain. Therefore, it has strong support for model-vis mapping, which is also the case for data preparation and data inspection. When it comes to model building, Tableau provides basic functionality. For specific data sets, it is possible to add a trend line or compute a forecast, where the model can be adjusted in designated bounds. The various manipulation and visualization options provide strong support for the exploration loops. Verification loops and knowledge generation loops support is also available with the story module, which allows free creation of reports and references to visualizations. In addition, all three loops are supported by the annotation tool, which allows the  Jigsaw represents visual analytics, Knime data mining, Tableau information visualization, and HARVEST applications from the provenance domain. Strength of support for functionalities/components of our model is indicated by the weight of the lines. addition of persistent annotations to data points or specific locations and areas in the visualization. Jigsaw is an example for a visual analytics application, which we already examined in detail in Sections 4.1 and 4.2. It supports all the actions we included in our model. In addition, all three loops are supported, but there is some potential for improvements. For example, a good support of the verification loops can be easily achieved by a tighter integration of the Tablet View in the system. Also, providing histories of actions leading to a specific state of a visualization (bookmark) is a step towards better support of the verification and knowledge generation loops. At last, we examine HARVEST <ref type="bibr" coords="7,442.73,524.95,14.30,8.02" target="#b9">[11,</ref><ref type="bibr" coords="7,459.59,524.95,10.72,8.02" target="#b34"> 37]</ref>, a system which supports provenance. While using HARVEST, all interaction is recorded and can be used in order to understand the way findings have been detected. Using this data, the system is able to support analysts during the exploration and verification loops, for example by an automatic ranking of manually created notes based on the users behavior. This comes close to our definition of the knowledge generation process. The system also supports the analysis process by providing visualization recommendations or ordering of notes connected insights, or findings. Similar to Jigsaw's Tablet View, the note-taking-interface is capable of organizing, grouping, and ordering items, which supports the knowledge generation loops. The assessment of the tools from different application domains shows that the model can be applied on applications, which work with data and visualization in general. The result also clearly separates the different application domains. </p><formula>V M D D M EL VL KL D V EL VL KL D V M Knime Tableau Jigsaw KL basic strong weak EL VL M V M EL VL KL HARVEST D V Legend: </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SUMMARY AND DISCUSSION</head><p> This study identifies new perspectives on visual analytic processes beyond weaving existing frameworks into one. Our model highlights that human and machine are a loop in the knowledge generation process using visual analytics. While existing models focus on one of the these, the interplay between each subcomponent can be influenced by human decision making and reasoning processes. This is important for researchers as it enables discussions of specific functions and their impacts on reasoning processes more explicitly because our model can describe the whole path from data to knowledge and vice versa. Besides connecting to system components, the model also defines human concepts and introduces three self-contained loops/stages of reasoning/thinking. We can also use our model to assess visual analytics system in terms of its functions toward human analytic outputs. For instance, we can detect areas of visual analytics systems that tend to cause biases within the knowledge generation process by aligning experts' analytic processes and outcomes against our model. Then, designers could improve corresponding visual analytics components to enhance early detection of such analytic failures: wrong hypotheses, conflicts between findings and insights, and dead ends of exploration cycles. We also find results that resonate with sensemaking, cognition and reasoning models (e.g. Pirolli and Card <ref type="bibr" coords="8,211.16,282.52,13.59,8.02" target="#b26">[29]</ref>). Our model even specifies where our current visual analytics systems fall short of, which is to support higher level loops, namely the exploration, verification and knowledge generation loops. Supporting higher level loops is more complex, however this would be a useful addition to many of the current systems <ref type="bibr" coords="8,75.64,332.34,13.74,8.02" target="#b28">[31]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Collaboration and Communication</head><p>Our model describes the knowledge generation processes for visual analytics. There are specific types of visual analytics, which our model does not explicitly mention. Visual analytics processes could be collaborative , so multiple stakeholders asynchronously or synchronously analyze data together and gain insights through verbal communication between them. Our model currently assumes an individual's analytic process, so it is missing collaborative components. We can simplify this collaboration process with different but possibly shared knowledge generation loops of all humans (i.e., white nodes in <ref type="figure" coords="8,230.81,446.86,28.89,8.02" target="#fig_5">Figure 1</ref>). We can explain that a number of users perform actions and interpret findings together to improve the quality of their knowledge. Also distributed cognition theories have to be considered when examining representations and interactions among humans and artifacts (Liu et al. <ref type="bibr" coords="8,276.56,486.71,13.59,8.02" target="#b18">[20]</ref>). Nobarny et al. <ref type="bibr" coords="8,100.23,496.68,15.06,8.02" target="#b22">[24] </ref> already developed a system and performed studies focusing on distributed cognition in order to support collaborative visual analytics. Especially the externalization and communication of information plays a crucial role that needs more detailed investigations with regards to the presented concepts of findings, insights or knowledge. The importance of externalization in visual analytic processes can be observed by heavy reliance on note-taking throughout analysis processes <ref type="bibr" coords="8,279.61,567.06,13.87,8.02" target="#b20">[22]</ref>. In real world, groups of users often take a variety of approaches to synthesize information with their own organizational language <ref type="bibr" coords="8,279.61,586.98,13.87,8.02" target="#b29">[32]</ref>. Communicating knowledge in visual analytics is actually the communication of evidence found in data supporting a belief. This evidence is shared with findings or insights, e.g., a commented visualization revealing an interesting relationship in data. The communication counterpart can follow the evidence and, depending on the level of trust, gain own insights or knowledge out of it. Collaborative analysis scenarios allow communication partners to verify this evidence with the system. We should also note that collaboration between multiple analysts open up chapters about maintaining exploration awareness <ref type="bibr" coords="8,240.01,676.65,13.84,8.02" target="#b35">[38]</ref>. In case of presentations or static documents the missing visual analytics system is replaced by the presenter or reporter. During presentations questions and answers are able to replace the knowledge generation loops. Static documents have to convey all information from hypotheses, findings , and insights in a way that readers can follow the conclusions. Interactive reports or documents (e.g., infographics) go beyond the aforementioned scenario as they can be seen as a report combined with a limited visualization that is tailored to show the relevant findings of insights. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Visual Analytics of Streaming Data</head><p>In addition to collaborative visual analytics, we can apply our model to visual analytics of data streams (e.g., monitoring twitter data). In this situation, our data node is dynamically changing, so our model reformulates its visual representations and analytic models according to substantial changes made by the data streams. Further investigation is necessary since a number of requirements on data management, knowledge discovery and visualization need to be researched due to the dynamic nature of streams. Mansmann et al. <ref type="bibr" coords="8,480.05,174.24,14.84,8.02" target="#b21">[23] </ref>illustrate this and highlight that the analyst role changes since exploration is extended to include real-time monitoring tasks where situational awareness and complex decision making come into play. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Automatic Support of Knowledge Generation</head><p>We will now consider how novice users can be given guidance using the system and supporting analysis can aid knowledge generation. Systems can make automatic suggestions based on their current state, e.g., choosing a suitable color mapping or selecting parameters based on data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Exploration Loop</head><p>The exploration loop is the basis of all knowledge generation in visual analytics. An important trigger to observe findings is how the system handles interactions. Analysts can learn from the causality between interactions and reaction, hence, supporting the exploration loop requires a system to respond with an immediate observable reaction to any interaction . Many algorithms in data analysis require complex computations and are not able to calculate a complete result immediately. In these cases, analysts should at least receive feedback that the algorithm is still running. Systems should provide the ability to switch between the states before and after calculation so analysts can learn from interactions . If the final result can be estimated, for instance, by intermediate results of an incremental algorithm, the estimation could be shown to the analysts with the additional ability to abort the calculation. Findings are related to unexpected results or patterns in models or visualizations. Automatically detecting unexpected results is complicated , because it requires a definition of what analysts are expecting, which is usually not known to systems. On the other side, pattern mining algorithms are extracting patterns directly from data and in visualization , patterns could be detected with automatic methods as well. Even automatic methods to judge the usefulness of visualization exists, e.g., Bertini et al. <ref type="bibr" coords="8,371.87,505.74,10.45,8.02" target="#b1">[3] </ref>gives an overview of quality metrics approaches. Actions are dependent on findings and the goal of the analysis. Visual analytic systems could provide suggestions for further actions in the analysis process, as in behavior-driven visualization recommen- dation <ref type="bibr" coords="8,332.66,545.71,13.86,8.02" target="#b8">[10]</ref>. Based on findings, these suggestions could offload some burden from analysts of having to choose the right action from all different possibilities. Novice users would benefit from such suggestions, because the system would present proper actions allowing users to learn the abilities of the system. For expert users the interaction with the system would be more efficient compared to navigating a large set of options. It is important to find an adequate level of suggestions based on user experience. A solution to this problem could be a learning technique, such as active learning (e.g., Settles <ref type="bibr" coords="8,481.81,625.41,13.59,8.02" target="#b32">[35]</ref>), that adapts the suggestions to users and minimizes the interaction costs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Verification Loop</head><p>The verification loop is the central part in the knowledge generation loops. Analysts combine findings from data with their domain knowledge and gain new insights into the problem domain. The knowledge of analysts play an important role in the verification loop, therefore automatic support for the verification loop is limited to helping analysts record their analysis results. Systems are not directly generating insights but analysts gain new insights from data when they are able to interpret findings. In this respect systems can support this process by providing useful summaries of findings by allowing analysts to organize findings, hypotheses, or insights. Often insights are not dependent on a single finding but are hidden in complex relationships in the data and often difficult to find without prior knowledge. Systems addressing this problems are, for instance, Shrinivasan et al. <ref type="bibr" coords="9,151.67,103.20,14.94,8.02" target="#b34">[37] </ref>and Wright et al. <ref type="bibr" coords="9,231.36,103.20,13.74,8.02" target="#b39">[42]</ref>. To formulate hypotheses about the problem domain, findings are not enough as analysis requires insights into the domain. However, systems can automatically formulate hypotheses about the analyzed data from findings. Theses hypotheses can help analysts get a faster overview of unknown data sets but their use for complex analysis tasks is limited, because only hypotheses about relations in data can be generated automatically. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Knowledge Generation Loop</head><p>Automating the steps from insights to knowledge or from knowledge to new hypotheses is according to our definition not possible. Analysts gain new knowledge when the evidence collected with a visual analytics system is convincing. The best way to support knowledge generation with visual analytics are systems with the ability to look at data from different perspectives. This gives analysts the possibility to collect versatile evidence and increases the level of trust in findings or insights. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Future Investigations on Visual Analytics Systems</head><p>Our model specifies some areas that our current research can further investigate. We find some interaction types missing in many systems and interaction models, especially in the model construction or the coupling of models and visualizations. Many visual analytics tools tend to maintain preloaded models or to provide a very limited capability to manipulate models by adjusting some parameters. We observe that data become more and more dynamic and unstructured and human interaction on the model part is therefore crucial to analyze such data. Secondly, we see that many improvements could be made to further support human actions. Systems can actively learn from user behavior and adapt its models and visualizations, too. Visual analytics systems could proactively seek next candidate actions based upon user-generated logs. Our model points out that we need more explicit support to transfer findings, insights, and knowledge. As Endert et al. <ref type="bibr" coords="9,244.09,425.55,10.57,8.02" target="#b5">[7] </ref>states, visual analytics should recognize and integrate human working processes into the system. Different ways of how systems could offload some burdens from human users exist. The key is the interaction with visual analytics, although we should be aware of interaction costs (Lam <ref type="bibr" coords="9,288.36,465.40,13.72,8.02" target="#b16">[18]</ref>, van Wijk <ref type="bibr" coords="9,89.97,475.36,13.59,8.02" target="#b37">[40]</ref>). Frequent interactions triggered by the system could demand too much effort, which may discourage user's exploration. After analysis, the results have to be documented or communicated to others. An interesting ability of visual analytics systems could be a semi-automatic approach for generating documentations. Algorithms could detect interesting new findings and put them together in a convincing form, removing dead ends and duplicate findings. Such intelligent journals would make creation of reports or presentations much easier. Alternatively, written reports could be enriched with findings supporting statements in the document. The analysis process often follows one direction and many findings are not explored in depth. Visual analytics systems could provide functionalities to backtrack former analysis results and suggest interesting but not investigated findings for further analysis. This would require algorithms to judge the interestingness of findings in context of the conducted analysis results. This functionality together with a short summary of previous results could be helpful for continuing an interrupted analysis session. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Real World Scenario</head><p>Our model reflects an ideal scenario where an analyst uses one single visual analytics system that is capable of handling all requirements but real world scenarios are different. On the one hand, users are often not aware of the systems capabilities and lack the required expertise to understand complex analysis methods (Gulf of Execution). On the other hand, the system's capabilities are not sufficient to solve an analysis task. As an outcome, analysts may stop their analysis in order to consult domain experts or continue their analysis with another system. In addition our model implies that each action ends in an observable reaction of the system. Real world systems often lack of this capability, which is a known problem in interaction science (Gulf of Evaluation). The analysis of real world problems requires both expertise about the analysis and the domain. Domain experts often lack experience in understanding computer systems, visualization techniques and analysis methods, whereas visual analytics experts lack of sufficient domain knowledge. Thus, analysis requires collaboration between them. Without domain knowledge a visual analytics analysts is able to generate findings and insights concerning the data, not the domain. The domain expert is responsible for the formulation of problem hypotheses, the detection and interpretation of patterns. Domain experts need to be familiar with visual analytics methods and systems. On the other hand analysts have to learn about the problem domain. One thing to keep in mind is that our model simplifies many different processes, and it contains inherent fuzziness, especially on the human side. That is the reason why our model consists of various loops that represent several levels of thinking. Obviously, no visual analytics tools can differentiate exactly between reasoning processes. Furthermore, the processes can disseminate many influences into other processes, which may not clearly appear in our model. Often many conflicting hypotheses are investigated in parallel and derived findings, insights or knowledge may affect each other. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Teaching Visual Analytics</head><p>Our model can be useful to provide a general overview for novice students, designers, and researchers in visual analytics. Teaching visual analytics often require teachers to provide fundamental concepts commonly appearing throughout applications, which inevitably involves domain knowledge. Our model can be used to explain the knowledge generation process without the need for such expert language. In addition , this model touches upon various components of visual analytics, such as interactions and automatic algorithms, in the perspectives of visual analytics applications. This guideline could point researchers to relevant literature in case they want to find out about specific methods. Our model also highlights the importance of the interplay and collaboration between human and machines. This rather obvious but easily forgotten notion could be highlighted, as illustrated in <ref type="figure" coords="9,511.97,438.38,29.02,8.02" target="#fig_5">Figure 1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper we present a process model for knowledge generation in visual analytics that integrates system and human aspects. The model defines and relates relevant concepts and provides a knowledge generation process from knowledge to data and vice versa. The model embeds concepts into a three loop framework and illustrates possible human machine pairings that are fundamental in visual analytics. We illustrated that our model integrates with existing models and theories that focus on specific parts within the overall context. We demonstrated the models application using Jigsaw as an example system as well as undertaking a comparative assessment of three other well-known applications . Finally, we discussed model implications, named open issues, and pointed to future directions. The right hand side (human part) of our model is not restricted to visual analytics and can also be relevant for other disciplines as it combines computer and human based theories. The model aims to give a basis for more detailed compositions of theories . Whilst it is not our intention to cover every single details of such processes, we do provide a overview that commonly appears in visual analytics processes. We also acknowledge that human's knowledge processes cannot be linear or clearly subdivided into components of our model (e.g., insight). However, we provide inherently limited but meaningful distinction between human's knowledge gaining processes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REFERENCES </head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,238.32,645.73,66.06,8.02;1,56.99,675.75,239.49,7.52;1,65.96,685.87,117.96,6.86;1,55.99,699.32,250.39,6.86;1,84.39,708.78,93.04,6.86;1,205.87,708.78,17.93,6.86"><head></head><figDesc>Many prior works @BULLET Data Analysis and Visualization Group, University of Konstanz. E-mail: forename.lastname@uni-konstanz.de Manuscript received 31 Mar. 2014; accepted 1 Aug. 2014. Date of publication 2014; date of current version 2014. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,54.00,162.72,250.38,8.02;5,54.00,172.69,23.16,8.02"><head>Fig. 4: </head><figDesc>Fig. 4: Van Wijks model including Green et al.'s changes [13, 14] and labels. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,316.62,357.10,251.95,8.02;7,316.45,367.06,252.03,8.02;7,316.62,377.03,250.38,8.02;7,316.62,386.99,250.53,8.02;7,316.62,396.95,161.14,8.02"><head>Fig. 7: </head><figDesc>Fig. 7: Comparative model application to different kinds of systems. Jigsaw represents visual analytics, Knime data mining, Tableau information visualization, and HARVEST applications from the provenance domain. Strength of support for functionalities/components of our model is indicated by the weight of the lines. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="9,320.61,708.70,247.39,7.13;9,334.88,718.17,232.12,7.13"><head>[1] </head><figDesc>M. R. Berthold, N. Cebron, F. Dill, T. R. Gabriel, T. Kötter, T. Meinl, P. Ohl, K. Thiel, and B. Wiswedel. Knime -the konstanz information </figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,63.26,54.06,232.12,7.13;10,63.26,63.52,232.12,7.13;10,63.26,73.07,233.44,6.86;10,63.26,82.45,232.13,7.13;10,62.66,91.92,63.66,7.13"  xml:id="b0">
	<analytic>
		<title level="a" type="main">Surveying the complementary role of automatic data analysis and visualization in knowledge discovery</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Bertini</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Lalanne</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD Workshop on Visual Analytics and Knowledge Discovery: Integrating Automated Analysis with Interactive Exploration</title>
		<meeting>the ACM SIGKDD Workshop on Visual Analytics and Knowledge Discovery: Integrating Automated Analysis with Interactive Exploration</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="12" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,101.38,232.12,7.13;10,63.26,110.85,233.52,7.13;10,63.00,120.31,137.14,7.13"  xml:id="b1">
	<analytic>
		<title level="a" type="main">Quality metrics in high-dimensional data visualization: An overview and systematization</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Bertini</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Tatu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Keim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2203" to="2212" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,129.78,233.44,7.13;10,63.26,139.24,233.12,7.13;10,62.66,148.70,81.25,7.13"  xml:id="b2">
	<analytic>
		<title level="a" type="main">A multi-level typology of abstract visualization tasks. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Brehmer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Munzner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2376" to="2385" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,158.17,232.12,7.13;10,63.26,167.63,197.76,7.13"  xml:id="b3">
	<monogr>
		<title level="m" type="main">Readings in information visualization: using vision to think</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">K</forename>
				<surname>Card</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Mackinlay</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Shneiderman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,177.10,232.12,7.13;10,63.26,186.56,233.12,7.13;10,63.26,196.03,61.32,7.13"  xml:id="b4">
	<analytic>
		<title level="a" type="main">Defining insight for visual analytics</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Chang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Ziemkiewicz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">M</forename>
				<surname>Green</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Ribarsky</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Applications IEEE</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="14" to="17" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,205.49,233.44,7.13;10,63.26,214.96,232.12,7.13;10,63.26,224.42,170.16,7.13"  xml:id="b5">
	<analytic>
		<title level="a" type="main">The human is the loop: new directions for visual analytics</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Endert</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hossain</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Ramakrishnan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>North</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Fiaux</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Andrews</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Information Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,233.88,232.12,7.13;10,63.26,243.35,206.44,7.13"  xml:id="b6">
	<monogr>
		<title level="m" type="main">From data mining to knowledge discovery in databases. AI magazine</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Fayyad</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Piatetsky-Shapiro</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Smyth</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,252.81,232.12,7.13;10,63.26,262.28,233.44,7.13;10,63.26,271.74,232.12,7.13;10,63.26,281.21,162.60,7.13"  xml:id="b7">
	<analytic>
		<title level="a" type="main">Combining Computational Analyses and Interactive Visualization for Document Exploration and Sensemaking in Jigsaw</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Görg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Liu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kihm</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Choo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Park</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">T</forename>
				<surname>Stasko</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1646" to="1663" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,290.67,233.51,7.13;10,63.26,300.14,232.12,7.13;10,63.12,309.60,192.29,7.13"  xml:id="b8">
	<analytic>
		<title level="a" type="main">Behavior-driven visualization recommendation</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Gotz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Wen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Intelligent User Interfaces</title>
		<meeting>the 14th International Conference on Intelligent User Interfaces<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page">315324</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,319.07,232.12,7.13;10,63.26,328.53,233.51,7.13;10,63.26,337.99,232.12,7.13;10,63.12,347.46,233.25,7.13;10,63.26,356.92,39.75,7.13"  xml:id="b9">
	<analytic>
		<title level="a" type="main">Harvest: An intelligent visual analytic tool for the masses</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Gotz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>When</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Lu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Kissa</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Cao</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">H</forename>
				<surname>Qian</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">X</forename>
				<surname>Liu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">X</forename>
				<surname>Zhou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Workshop on Intelligent Visual Interfaces for Text Analysis, IVITA &apos;10</title>
		<meeting>the First International Workshop on Intelligent Visual Interfaces for Text Analysis, IVITA &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,366.39,232.25,7.13;10,63.26,375.85,207.93,7.13"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Characterizing users&apos; visual analytic activity for insight provenance</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Gotz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">X</forename>
				<surname>Zhou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="42" to="55" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,385.32,233.45,7.13;10,63.26,394.78,232.12,7.13;10,62.81,404.25,233.96,7.13"  xml:id="b11">
	<analytic>
		<title level="a" type="main">Visual analytics for complex concepts using a human cognition model</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Green</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Ribarsky</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Fisher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Analytics Science and Technology, 2008. VAST &apos;08. IEEE Symposium on</title>
		<imprint>
			<date type="published" when="2008-10" />
			<biblScope unit="page" from="91" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,413.71,232.12,7.13;10,63.26,423.17,233.11,7.13;10,63.11,432.64,32.54,7.13"  xml:id="b12">
	<analytic>
		<title level="a" type="main">Building and applying a human cognition model for visual analytics</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">M</forename>
				<surname>Green</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Ribarsky</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Fisher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2009-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,442.10,232.12,7.13;10,63.12,451.57,232.25,7.13;10,62.97,461.03,59.55,7.13"  xml:id="b13">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Keim</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kohlhammer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Ellis</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Mansmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mastering the Information Age -Solving Problems with Visual Analytics. Eurographics Association</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,470.50,233.51,7.13;10,62.77,479.96,178.45,7.13"  xml:id="b14">
	<monogr>
		<title level="m" type="main">Visual analytics: Scope and challenges</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Keim</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Mansmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Schneidewind</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Thomas</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Ziegler</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,489.43,232.12,7.13;10,63.26,498.89,232.12,7.13;10,62.81,508.36,123.22,7.13"  xml:id="b15">
	<analytic>
		<title level="a" type="main">Visual analytic roadblocks for novice investigators</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">C</forename>
				<surname>Kwon</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Fisher</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">S</forename>
				<surname>Yi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE Conference on Visual Analytics Science and Technology (VAST)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="3" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,517.82,233.51,7.13;10,62.77,527.28,233.80,7.13;10,62.66,536.75,53.46,7.13"  xml:id="b16">
	<analytic>
		<title level="a" type="main">A framework of interaction costs in information visualization. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Lam</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1149" to="1156" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,546.21,232.12,7.13;10,63.26,555.68,167.95,7.13"  xml:id="b17">
	<analytic>
		<title level="a" type="main">Focussing in reasoning and decision making</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Legrenzi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Girotto</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">N</forename>
				<surname>Johnson-Laird</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="66" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,565.14,232.12,7.13;10,63.26,574.61,232.12,7.13;10,63.00,584.07,218.94,7.13"  xml:id="b18">
	<analytic>
		<title level="a" type="main">Distributed cognition as a theoretical framework for information visualization. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Liu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">J</forename>
				<surname>Nersessian</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">T</forename>
				<surname>Stasko</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1173" to="1180" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,593.54,232.12,7.13;10,63.01,603.00,92.88,7.13"  xml:id="b19">
	<monogr>
		<title level="m" type="main">Abduction, Reason and Science: Processes of Discovery and Explanation</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Magnani</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,612.47,232.12,7.13;10,63.26,621.93,232.12,7.13;10,63.06,631.39,232.32,7.13;10,62.66,640.86,65.31,7.13"  xml:id="b20">
	<analytic>
		<title level="a" type="main">A closer look at note taking in the co-located collaborative visual analytics process</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Mahyar</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Sarvghad</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Tory</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE Symposium on Visual Analytics Science and Technology (VAST)</title>
		<imprint>
			<date type="published" when="2010-10" />
			<biblScope unit="page" from="171" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,650.32,232.12,7.13;10,63.26,659.79,232.12,7.13;10,63.26,669.25,152.52,7.13"  xml:id="b21">
	<analytic>
		<title level="a" type="main">Dynamic visual analytics facing the real-time challenge</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Mansmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Fischer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Keim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Expanding the Frontiers of Visual Analytics and Visualization</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="69" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,678.72,232.12,7.13;10,63.26,688.18,232.12,7.13;10,63.26,697.73,233.12,6.86;10,63.26,707.11,99.75,7.13"  xml:id="b22">
	<analytic>
		<title level="a" type="main">Facilitating the reuse process in distributed collaboration: a distributed cognition approach</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Nobarany</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Haraty</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Fisher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work</title>
		<meeting>the ACM 2012 conference on Computer Supported Cooperative Work</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1223" to="1232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,716.57,208.07,7.13"  xml:id="b23">
	<analytic>
		<title level="a" type="main">The Design of Everyday Things</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Norman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Basic Books</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,63.26,726.04,232.12,7.13;10,63.26,735.50,132.83,7.13;10,307.62,54.06,251.78,7.13;10,325.88,63.52,67.30,7.13"  xml:id="b24">
	<analytic>
		<title level="a" type="main">Toward measuring visualization insight Collected papers: Elements of Logic</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>North</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Applications, IEEE</title>
		<editor>27] C. S. Peirce</editor>
		<imprint>
			<publisher>Belknap Press</publisher>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="6" to="9" />
			<date type="published" when="1965" />
			<publisher>Belknap Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,72.99,232.12,7.13;10,325.88,82.45,189.80,7.13"  xml:id="b25">
	<analytic>
		<title level="a" type="main">The science of interaction</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">A</forename>
				<surname>Pike</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Stasko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Chang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">A</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="263" to="274" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,91.92,232.26,7.13;10,325.88,101.38,233.44,7.13;10,325.88,110.85,233.12,7.13;10,325.88,120.31,54.01,7.13"  xml:id="b26">
	<analytic>
		<title level="a" type="main">The sensemaking process and leverage points for analyst technology as identified through cognitive task analysis</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Pirolli</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Card</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Intelligence Analysis</title>
		<meeting>International Conference on Intelligence Analysis</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="2" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,129.78,233.44,7.13;10,325.88,139.24,233.52,7.13;10,325.74,148.70,170.34,7.13"  xml:id="b27">
	<analytic>
		<title level="a" type="main">The user puzzle: Explaining the interaction with visual analytics systems. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Pohl</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Smuc</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Mayr</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2908" to="2916" />
			<date type="published" when="2012-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,158.17,233.11,7.13;10,325.88,167.63,233.45,7.13;10,325.88,177.10,232.12,7.13;10,325.39,186.56,74.82,7.13"  xml:id="b28">
	<analytic>
		<title level="a" type="main">From Ill- Defined Problems to Informed Decisions</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">C</forename>
				<surname>Roberts</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Keim</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hanratty</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">R</forename>
				<surname>Rowlingson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Walker</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hall</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Jacobson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Lavigne</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Rooney</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Varga</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroVis Workshop on Visual Analytics</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">2014</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,196.03,232.12,7.13;10,325.68,205.57,233.32,6.86;10,325.88,214.96,61.98,7.13"  xml:id="b29">
	<analytic>
		<title level="a" type="main">Collaborative synthesis of visual analytic results</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Robinson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Visual Analytics Science and Technology, 2008. VAST &apos;08</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="67" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,224.42,232.26,7.13;10,325.88,233.88,232.12,7.13;10,325.59,243.35,177.10,7.13"  xml:id="b30">
	<analytic>
		<title level="a" type="main">An insight-based methodology for evaluating bioinformatics visualizations. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Saraiya</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>North</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Duca</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="443" to="456" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,252.81,232.12,7.13;10,325.68,262.28,233.64,7.13;10,325.88,271.74,110.70,7.13"  xml:id="b31">
	<analytic>
		<title level="a" type="main">A design space of visualization tasks. Visualization and Computer Graphics</title>
		<author>
			<persName>
				<forename type="first">H.-J</forename>
				<surname>Schulz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Nocke</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Heitzler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Schumann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2366" to="2375" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,281.21,233.52,7.13;10,325.55,290.67,83.91,7.13"  xml:id="b32">
	<monogr>
		<title level="m" type="main">Active learning literature survey</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Settles</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="55" to="66" />
			<pubPlace>Madison</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,300.14,232.26,7.13;10,325.88,309.60,233.51,7.13;10,325.74,319.07,160.71,7.13"  xml:id="b33">
	<analytic>
		<title level="a" type="main">The eyes have it: A task by data type taxonomy for information visualizations</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Shneiderman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Languages Proceedings., IEEE Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="336" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,328.53,233.52,7.13;10,325.88,337.99,232.12,7.13;10,325.68,347.46,133.71,7.13"  xml:id="b34">
	<analytic>
		<title level="a" type="main">Connecting the dots in visual analysis</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Shrinivasan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Gotz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Lu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2009-10" />
			<biblScope unit="page" from="123" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,356.92,232.12,7.13;10,325.88,366.39,233.12,7.13;10,325.88,375.85,79.48,7.13"  xml:id="b35">
	<analytic>
		<title level="a" type="main">Supporting exploration awareness in information visualization</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Shrinivasan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Van Wijk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="34" to="43" />
			<date type="published" when="2009-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,385.32,233.45,7.13;10,325.88,394.78,232.12,7.13;10,325.28,404.25,71.06,7.13"  xml:id="b36">
	<analytic>
		<title level="a" type="main">Jigsaw: Supporting Investigative Analysis through Interactive Visualization</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">T</forename>
				<surname>Stasko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Görg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Liu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Singhal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE VAST</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="131" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,413.71,233.52,7.13;10,325.74,423.17,96.73,7.13"  xml:id="b37">
	<analytic>
		<title level="a" type="main">The value of visualization</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Van Wijk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization, 2005. VIS 05. IEEE</title>
		<imprint>
			<date type="published" when="2005-10" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,432.64,233.51,7.13;10,325.88,442.10,233.45,7.13;10,325.88,451.57,233.51,7.13;10,325.88,461.03,49.05,7.13"  xml:id="b38">
	<analytic>
		<title level="a" type="main">Interaction taxonomy for tracking of user actions in visual analytics applications</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Von Landesberger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Fiebig</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Bremm</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Kuijper</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">W</forename>
				<surname>Fellner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Human Centric Visualization</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="653" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,470.50,232.32,7.13;10,325.88,479.96,232.12,7.13;10,325.62,489.43,232.38,7.13;10,325.88,498.89,142.35,7.13"  xml:id="b39">
	<analytic>
		<title level="a" type="main">The sandbox for analysis: Concepts and methods</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Wright</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Schroh</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Proulx</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Skaburskis</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Cort</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;06</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;06<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="801" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,325.88,508.36,232.12,7.13;10,325.88,517.82,232.12,7.13;10,325.68,527.28,232.32,7.13;10,325.88,536.75,233.52,7.13;10,325.59,546.21,39.75,7.13"  xml:id="b40">
	<analytic>
		<title level="a" type="main">Understanding and characterizing insights: how do people gain insights using information visualization?</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">S</forename>
				<surname>Yi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Kang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">T</forename>
				<surname>Stasko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">A</forename>
				<surname>Jacko</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Workshop on BEyond time and errors: novel evaLuation methods for Information Visualization</title>
		<meeting>the 2008 Workshop on BEyond time and errors: novel evaLuation methods for Information Visualization</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
