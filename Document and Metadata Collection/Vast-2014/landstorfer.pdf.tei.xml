<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T13:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Weaving a Carpet from Log Entries: A Network Security Visualization Built with Co-Creation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Johannes</forename>
								<surname>Landstorfer</surname>
							</persName>
							<affiliation>
								<orgName type="department">Department of Design</orgName>
								<orgName type="institution">University of Applied Sciences Potsdam</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ivo</forename>
								<surname>Herrmann</surname>
							</persName>
							<affiliation>
								<orgName type="department">Department of Design</orgName>
								<orgName type="institution">University of Applied Sciences Potsdam</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Jan-Erik</forename>
								<surname>Stange</surname>
							</persName>
							<affiliation>
								<orgName type="department">Department of Design</orgName>
								<orgName type="institution">University of Applied Sciences Potsdam</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Marian</forename>
								<surname>Dörk</surname>
							</persName>
							<affiliation>
								<orgName type="department">Department of Design</orgName>
								<orgName type="institution">University of Applied Sciences Potsdam</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Reto</forename>
								<surname>Wettach</surname>
							</persName>
							<affiliation>
								<orgName type="department">Department of Design</orgName>
								<orgName type="institution">University of Applied Sciences Potsdam</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Weaving a Carpet from Log Entries: A Network Security Visualization Built with Co-Creation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pixel-oriented techniques</term>
					<term>task and requirements anal- ysis</term>
					<term>multidimensional data</term>
					<term>network security and intrusion</term>
				</keywords>
			</textClass>
			<abstract>
				<p>We created a pixel map for multivariate data based on an analysis of the needs of network security engineers. Parameters of a log record are shown as pixels and these pixels are stacked to represent a record. This allows a broad view of a data set on one screen while staying very close to the raw data and to expose common and rare patterns of user behavior through the visualization itself (the &quot; Carpet &quot;). Visualizations that immediately point to areas of suspicious activity without requiring extensive fltering, help network engineers investigating unknown computer security incidents. Most of them, however, have limited knowledge of advanced visualization techniques, while many designers and data scientists are unfamiliar with computer security topics. To bridge this gap, we developed visualizations together with engineers, following a co-creative process. We will show how we explored the scope of the engineers&apos; tasks and how we jointly developed ideas and designs. Our expert evaluation indicates that this visualization helps to scan large parts of log fles quickly and to defne areas of interest for closer inspection.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A CO-CREATIVE APPROACH T O DATA VISUALIZATION</head><p> In the following section, we briefy elaborate on specifcs differentiating our approach from other work, then report about individual steps of our process, and fnally describe the user goals and design requirements extracted together with the stakeholders. We provide general guidelines based on the refection of our experiences in section 8. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Motivation</head><p>Innovation methods that involve the intended users early on are an established part of today's product development as well as visualization research <ref type="bibr" coords="1,378.30,633.85,13.72,9.00" target="#b23">[24]</ref>, <ref type="bibr" coords="1,398.48,633.85,13.82,9.00" target="#b28">[29]</ref>. We wanted to extend the " classic set " of ethnographic methods and feedback sessions (as in e.g. <ref type="bibr" coords="1,545.30,643.85,9.48,9.00" target="#b4">[5]</ref>, <ref type="bibr" coords="1,317.90,653.85,14.40,9.00" target="#b20">[21]</ref>) by elements from co-creation. The core idea of co-creation is to not only research about and design for a target group but to make them part of the team and design together with them <ref type="bibr" coords="1,540.70,673.85,13.80,9.00" target="#b26">[27]</ref>. Co-creation techniques typically focus on creating/making something together and aim at gaining insights by discussing the resulting artifacts. The intended benefts are a better understanding be- *E-mail: {landstorfer, ivo.herrmann, stange, doerk, wettach}@fh-potsdam.de tween groups with different traditions and " languages " , namely network security practitioners, security research, data visualization , and interface design. Furthermore, an even deeper involvement of all stakeholders, a broader spectrum of ideas, and a " builtin " validation: if the users take part in the design process, the designs are more likely to meet their needs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Process and Methods</head><p>To build up domain understanding, extract insights, and jointly create new ideas we conducted interviews, made observations, and an ideation workshop. We describe further steps later, such as visualization design (section 4) and feedback sessions (section 5). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Interviews and Observations</head><p> Our core group consisted of 7 different people from 6, mostly scientifc , institutions. Professional backgrounds were network security engineer, network administrator, security researcher, in operative as well as managing roles. We enlarged the team later, especially for the workshop session. Our questions referred to the workplace and tool setup, important data types, typical tools and processes for incident management , and the role of visualizations in their work. Examples are: " What data do you usually work with during a usual day? What role do raw data (such as NetFlow) play in contrast to generated alerts? " " What kind of visualization are you familiar with in your professional environment? Where do you use it? Where do you prefer a raw/text view on your data? " We tried to avoid direct questions about which visualization they wanted, as the answer relies very much on the existing knowledge of the interviewees about visualizations. Instead, we deducted common tasks, implicit and explicit needs, and the role of visualization from their statements and our observations. We could combine only half of the interviews with observations on location due to the limited availability of the busy experts and the sensitive nature of the domain. We were particularly interested in the physical setup of a workplace (such as number and arrangement of screens, personal and " public " screens), location of and relation to colleagues, communication devices, analog means such as white boards, and further details that the interviewees might take for granted. We summarized the fndings from our interviews and refected the identifed needs with the interviewees to avoid misinterpretations . We also included a refection on requirements later on in our ideation workshop. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Ideation Workshop</head><p>As input for our one day workshop, we used needs and statements from the interviews, market research on security data visualization , and further material contributed by the participants. The goal was to come up with a visualization idea for an individually selected problem. The participants sketched out their ideas (<ref type="figure" coords="2,267.30,557.25,20.21,9.00">Fig. 1</ref>), presented, commented, and refned, in single and team sessions. We also clustered the workshop results to identify common directions (see 2.3 for details). Creating ideas for selected challenges in groups helped to build up mutual understanding as a side effect. Half of the day, a group of participants worked directly with their computers on data sets that we asked them to bring to the workshop (we called this session the " data picnic " ). The idea was to create sketchy visualizations or at least an early analysis tool for one of the data sets. Besides, the participants would share tools and strategies which would facilitate later collaboration. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">High-Level User Goals</head><p>In many larger computer networks, intrusion detection systems (short: IDS) scan for signatures of known attacks and issues. In various situations, the security experts told us that they were skeptical about automated detection systems. Some said they were too resource heavy and expensive, for some " they keep admins busy with false positives " (also in <ref type="bibr" coords="2,423.50,261.05,9.45,9.00" target="#b0">[1]</ref>). In general, they did not like that the internal mechanics of these systems are often hard to understand , thus alerting decisions diffcult to reconstruct, resulting in a loss of control. " If it's not transparent, it might be better to stay with the raw data. " While all had automated systems in place, they wished to combine them with tools dedicated to human pattern recognition and decision making. This discussion was particularly intense during the " data picnic " at the ideation workshop. The security engineers might not know exactly what they are looking for when they start an inspection: " Analysis tools should encourage the use of gut feelings, e.g. through highlighting anomalies , " as one interview partner put it. It is their experience and intuition during an explorative inspection that often guides them to suspicious incidents. Additionally, log fles can come from any place and various devices in a network during an investigation. This causes a high variety of data structures that need to be investigated . " The complicated part is: how to choose the right flter settings? How to fnd the right characteristics? This needs some trial and error, an iterative approach. " Considering their workfow, the network engineers were more focused on ex-post incident analysis than on, e.g. live traffc monitoring . This relates to the wish for exploration which can hardly be done in real-time and aims more for detecting e.g., hidden root causes. Based on this use case, we can also assume that some " framing " information can be used to limit the amount of data (such as a time range, IP ranges, etc.). For the sake of complete ness , we also want to mention that long term correlations or otherwise long ranging searches still require huge amounts of data to be parsed. Discussions and output of the needs and requirements analysis touched many topics, from raw data information to e.g. team collaboration . We bundled goals to form different coherent threads of conversations and research efforts but the full scope is beyond the scope of this paper. In the following, we want to focus on a tool that supports user-driven, exploratory, post-incident analysis. It would complement the automatic systems that scan for the more well known attacks and do the bulk of routine checks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Requirements for Our Visualization</head><p>Based on the high-level goals discussed before, we worked out key design requirements (DR). It is a synthesis from smaller ideas that the workshop participants came up with and refned. DR1: Display raw data. Security experts had a strong preference for retaining easy access to unprocessed or hardly processed log data that could complement automatic warning tools. With the <ref type="figure" coords="2,318.20,207.84,18.86,7.99">Fig. 1</ref> : A security researcher mapping his ideas for a crossinstitutional monitoring system during the ideation workshop. help of a compact visualization, security experts want to inspect the data on their own in the hope to fnd patterns that the algorithms missed. They wished for raw data to be readily available as context information to assess automatically generated alerts. DR2: Visualize extrema. Either the exception or the food of data are suspicious. While many current tools highlight mass effects , the security engineers were also looking for solutions that support the investigation of targeted attacks with " low profle " , i.e. few events. A consequence for visualizations is to highlight rare events over frequent ones. DR3: Encourage explorative analysis. Stumbling across anomalies besides the known and obvious can be a strength of human perception <ref type="bibr" coords="3,112.40,175.25,13.80,9.00" target="#b31">[32]</ref>. The visualization must strive to show a large range of events that the human eyes can scan. It should present events by their parameters and avoid classifying – the goal is to leave decisions about classifcation to the human operator. The tools should further offer elements for fexible manipulation of views and user defnable flters. The use case in focus can include a diverse set of log fles of various data types and data structures. Well labeled and structured data sets allow for meaningful semantics in the visualization. As the security engineers frequently face unlabeled data sets, they recommended a straightforward tool instead that would not require them to structure the data before they could " see something " . When we went into more concrete design activities, we relied on our collaborating security experts to pick a relevant data set. They chose an ssh log fle because it is frequently inspected after incidents and ssh servers are very important access points into net- works <ref type="bibr" coords="3,78.60,447.25,13.80,9.00" target="#b33">[34]</ref>. Besides, it was good to start with because of its fewer felds and clearly defned use cases. As we discussed data sets and use cases throughout the project, we later added a web server (Apache) access log <ref type="bibr" coords="3,129.20,477.25,13.80,9.00" target="#b30">[31]</ref> . Web server logs can help understand security breaches involving the application layer which our experts reported has become more relevant in recent years. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">SSH Log</head><p>Our ssh log captures the login activity via the ssh protocol to a server of a large scientifc institution. Our specifc set was from a previous incident analysis and we knew already that it contained two successful breaches. Stripped down to the entries relevant for login violations, it contains 13,199 lines (7 days). From the seven parameters of each record, we selected time stamp, log message (authentication method and whether it was successful), source IP, and user name for our visualization as they are most relevant for detecting login violations. Source port and destination port numbers , and protocol were not relevant or constant. Together with the fle, we got two " challenges " from the security engineer working with us on this phase. One was to fnd a " brute force attack " , i.e. an attacker tries a series of passwords (usually via a computer program) and when she guesses the password , she will be granted access. In the log, we would see a series of failures, followed by an " accepted password " indicating the success. The difference between failures from typos of a legitimate user and a (usually scripted) brute force attack are not always clearly assessable and then require inspection by a security expert. The other was a suspected public key theft. Public keys are usually stored on a computer and used instead of a password. They are too complex to be guessed. We had to look for an " accepted public key " , where the other parameters or the context were unusual. This log fle was also meant to be a " training " or " test " fle: while it would be possible to solve the use case itself automatically , we wanted to develop our visualization with the help of a well known challenge. To fnd evidence about malicious activity, we needed to inspect complex data: multi-variate data, where one record has several parameters , and also multi-event data, where only a combination of records indicates malicious behavior. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Apache Access Log</head><p>The Apache (web server) access log records requests from clients, most commonly when someone accesses a web page, with images , stylesheets, etc. We used logs from the web presence of a medium sized company (146,655 lines spanning seven days) and a private website (4,481 lines, one day; 33,060 lines, seven days). With the standard logging settings, there were eight different variables: source IP/host, time stamp, URL (i.e. requested resource), response code (which tells whether the request was acknowledged or produced some kind of error), bytes sent, and user agent. For most of our work, we chose host, response code, URL, and the time stamp. With these parameters, we can answer who did what with which result. We added the source country for each IP via a IP-to-geolocation service. Recorded activities in Apache logs are more diverse and the communication is less restricted. We worked with a security engineer and a web master, who wanted to investigate the activities on their web server. A deducted use case is to fnd attackers via traces in this log when they try to get access to restricted fles. This will be a rare event as regular visitors only access public fles. Another example are calls of scripts with unusual parameters, such as SQL injections to break into an application running on the web-server. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PIXEL CARPETS F O R MULTIVARIATE DATA</head><p>Based on the data and the design requirements elaborated before, we developed a visualization in the form of a pixel map. Next, we discuss our design decisions regarding visual mapping and inter- action. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Reasons For a Pixel Map</head><p> Early ideas for a tool that puts raw data visualizations next to automatically fltered alerts already arose during the workshop (called the " split screen " , <ref type="figure" coords="3,413.70,521.25,20.40,9.00" target="#fig_3">Fig. 2</ref>). Building on this and the strong requirement for a transparent tool (regarding the processing of raw data, DR1) that invites for exploration (DR3), we were looking for a way to bring lots of data records onto one screen (DR4). We found pixel maps <ref type="bibr" coords="3,399.60,561.25,14.89,9.00" target="#b13">[14] </ref>particularly appealing as we deal with very large datasets, require decent overview, and did not want to conceal details by binning the data. They offer the best " data to space ratios " by using the smallest building block on a computer screen (1 pixel) per data record, at least in the extreme. For high density displays (&gt;100 pixels per inch), the minimum size has to be adjusted. Overview is important when the security engineer needs to explore the dataset frst and does not know what to look for initially (DR3). With several hundred thousand lines recorded per day, traditional displaying techniques fail this task <ref type="bibr" coords="3,474.40,661.25,13.80,9.00" target="#b19">[20]</ref>. Binning would be a common technique to visually compress a dataset: aggregating several data records and representing them just with their average value (the most common form for this is a histogram). But when looking for exceptions and outliers (DR2), this technique can blur away the rare and hence important records quickly. Additionally, binning works best for numeric values. But in network security, most values are categorical in nature (e.g. IPs) which have no average value and are therefore hard to bin. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Carpet Layout and Multi-Pixel Structure</head><p>We decided to give three parameters of a record their own pixels, creating columns of " multi-pixels " per record (see <ref type="figure" coords="4,239.10,117.25,20.01,9.00">Fig. 3</ref>). For the ssh analysis, three parameters are suffcient and it is easy to read. An example for such an analysis is the detection of a dictionary attack. Source country and user name would stay the same but log message changes from " failed password " to " accepted password " . We built the multi-pixels as vertical columns and arranged them from left to right. As <ref type="figure" coords="4,135.60,177.25,21.99,9.00">Fig. 3</ref>shows, each record is lined up after the other, each pixel representing the value by color, with line breaks as the screen layout or the application requires. This allows an intuitive fow of reading from old (top left) to new (bottom right, for western reading habits). The result of this layout, together with the coloring, is what we call the " Pixel Carpet " . Triple pixels decrease our " data record to space ratio " from 1/1 to 1/3 but we gain a much better insight into details (we need to balance DR1 and DR4). For the Apache log, we also tested fve parameters per record. To enhance readability and to better separate the multi-pixels, we added a padding of one pixel horizontally and four pixels between the lines. We usually worked with 16 screen pixels per data item (4×4) because pixels are better readable and easier accessible with a mouse for additional info on hover (<ref type="figure" coords="4,80.84,317.25,19.87,9.00">Fig. 3</ref> ). This results in a " data/space ratio " of 3/80 including the padding. On a medium sized screen with a resolution of 1600×1200 (1.920.000 Pixels), we could show 24.000 entries at a " three parameter-resolution " simultaneously. For larger datasets, this can be reduced down to one pixel for data points and paddings (two to separate lines), yielding a ratio of 3/10. A magnifying tool for the cursor will then be necessary, such as a fsh eye (more on scalability in section 7). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Color Mapping</head><p> While the focus on pixels is space effcient, it limits the parameters available for visual mark-up. Pixel color is the most important option. Outlines/borders and patterns, as two examples, require their own pixels just for making them visible. A distinct color for each value would be a good option, but human perception is quite limited in freely discerning colors, ruling out this option <ref type="bibr" coords="4,258.60,469.25,13.80,9.00" target="#b31">[32]</ref>. We want rare values to stand out and frequent values to fade into the background (DR2). For this, we colorize pixels based on the value frequency in the dataset, similar to a heat map. We focus on parameters, i.e. frequency is calculated for each parameter in relation to all other values of this parameter in the dataset, independently of the record it belongs to (also independently of the occurrences of other parameters). Example: if " accepted password " can be found fve times in all log message felds of the dataset, this is its frequency and determining its color, regardless of the values for source IP or URL in the corresponding records. To map frequencies onto color values, we started with counting the occurrence of each parameter across the data set. We then segmented this frequency distribution into ten slices of varying " width " : the frst group consists of the rarest 0.5% of frequencies, the next color for frequencies up to 2%, then in increasing steps from 5%, 10%, 20%, 32%, 46%, 62%, 80% to the most frequent parameters. We did so to " sharpen " the rare groups that we are most interested in and have a more coarse representation of frequent values. We then created 10 different colors between bright red and dark blue by segmenting the hue and luminance " distances " between these colors in a HSL (hue, saturation, luminance ) color model into equal steps. Finally, we mapped the groups from the value frequency to the corresponding color, with red for rare and blue for frequent (as in <ref type="figure" coords="4,196.80,709.25,19.71,9.00">Fig. 3</ref>). Coloring by value frequency can result in two different parameter values, such as two different user names, having the same color because they occur equally often. Especially when these pixels appear next to each other, this misleads the user to (intuitively) think the two values were identical. To avoid this impression, we vary colors for different parameter values by small random changes in the luminance. Two pixels that stand for values of equal frequency will thus vary slightly but noticeably. This is also possible because the exact frequencies are not important for the security expert whose main goal is getting a general understanding of the dataset and fnding regions of interest. We implemented a straightforward algorithm for our experiments with the aim to make its mechanics transparent and gain the users' trust. We do not rely on felds that only occur in specifc logs so that the color mapping works for quite different types of log fles (DR5). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Exploration and Filtering</head><p>Complementing the visual representation of the Pixel Carpet, we now describe its interaction techniques designed with the aim to support open exploration of log fles (DR3 and DR4). <ref type="figure" coords="4,334.30,462.84,3.31,7.99">3</ref> : A look at the construction of the Pixel Carpet with multipixels and the " implementation " at screen resolution. One " column " is representing one data record. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Highlighting Identical/Similar Records</head><p>Hovering over a multi-pixel representing a single record, all other records with identical parameters are highlighted (<ref type="figure" coords="5,246.22,410.85,21.48,9.00" target="#fig_4">Fig. 4</ref>). This dynamic effect complements the static visualization: where the visualization makes regional similarities catch attention, such as several rare records forming a red block, the highlighting tool fnds matches across the whole set. This reveals activity over time. Via checkboxes in the interface, users can choose which parameters are taken into account for the matching: maybe they want to inspect a series of login attempts and want to see whether there were any successful guesses. They then switch off matching on log message and the tool will highlight all entries with the same source country (or source IP), same user name, but any kind of log message. With this highlighting tool, users can inspect elements and verify hypotheses that they built based on their visual impression. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Clear Text Display</head><p>Besides highlighting similar records, the hover operation also shows a clear text display of the corresponding log record (DR1), as a tool tip and in a dedicated log fle window below the visualization (<ref type="figure" coords="5,85.12,600.85,20.19,9.00" target="#fig_4">Fig. 4</ref>). The log fle window also shows the neighboring log lines to provide more context and allow for faster reading. The users could even scroll through the log fle via the visualization, but the power of the visual representation is a non-linear reading. In effect, the users get a quick overview over the contents of the dataset. Experienced network engineers know many IP addresses and user names in their network. They can put the values they fnd in context and thus classify them swiftly and precisely. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Filtering records</head><p> Clicking on a multi-pixel will remove all entries with identical parameters from the visualization. The users can get rid of, e.g., very frequent and thus uninteresting log records. The colors for the dataset will be recomputed based on the frequencies of all data remaining on display (<ref type="figure" coords="5,392.90,416.85,19.35,9.00" target="#fig_4">Fig. 4</ref>). With some of the values removed, the range of frequencies (we could also say " dynamic range " ) gets smaller. The limited set of (discernible) colors can then be spread across a narrower band of frequencies, letting smaller differences show up. This makes the flter actually a sort of zoom into the data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.4">Additional Binning</head><p>For some log fles (especially our Apache ones), highlighting just identical values can be too strict. For example, logs of dynamically generated websites will contain records of many slightly varying requests. A strict coloring would render all of these requests as very rare and red (<ref type="figure" coords="5,422.42,536.85,21.06,9.00">Fig. 7</ref>top), while in fact, they are all part of the published online resources. For this reason, the visualization allows to " summarize " variations via text matching. All of the affected parameters will be considered " the same " , represented by the same color (<ref type="figure" coords="5,388.89,576.85,46.75,9.00">Fig. 7 bottom</ref> ). In effect, this bins the parameters . As mentioned in the previous section, this helps to fnd the abnormal activity and separate it from just individual but legitimate requests. A simple text flter as in our demonstrator, however , is hardly capable of reliably differentiating trusted URLs from malicious requests in practice. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Color patterns encoding activity</head><p> Our idea is that different " classes " of records become easily visi ble to the human eye when we colorize the individual parameters (i.e. pixels) of each record (i.e. multi-pixel). Certain combinations of colors within a multi-pixel would then indicate certain activity. These combinations can be found quickly when visually scanning the Pixel Carpet (DR1). This is clearly visible in the ssh log fle: there are two types of " entirely frequent " entries with three blue pixels (<ref type="figure" coords="6,240.19,65.25,20.62,9.00">Fig. 5</ref>). Closer inspection (details in 4.4 Exploration and Filtering) reveals that one is a service the institution installed, the other is a brute force attack on " root " . While we initially thought that the attack should look more alarming, our security expert agreed with the modest appearance as the attack obviously did not succeed (otherwise it would have a red bottom pixel for an " accepted password " ). We can also see a record in <ref type="figure" coords="6,147.60,135.25,22.19,9.00">Fig. 5</ref>with a pink middle pixel, which comes from an attack that tries out user names. Another example shows the same intention but originating from a computer from a different country. Besides single record classifcation, the Pixel Carpet also allows to view records in context (DR4). Especially in the quite homogenous ssh log fle example, we can observe time spans " full " of regular behavior and then one record standing out because of a colored pixel. Or we have series of malicious activities that are visible as reddish blocks or even stretches of color (also in <ref type="figure" coords="6,266.80,225.25,19.71,9.00">Fig. 5</ref>). For an Apache log fle, the initial appearance is less clear. To a large part, this is due to the huge variety of normally available resources such as web pages and images. While this might hide smaller items and single records, we can see high frequency activity and repeatedly occurring events very clearly in <ref type="figure" coords="6,249.70,275.25,21.37,9.00" target="#fig_5">Fig. 6</ref>. This way, patterns evolve from a log fle visually that would be hard to recognize with other techniques, especially with the traditional " plain text and grep " method. To better separate truly suspicious activity from the diversity of legitimate activities such as the case for URLs in web-server logs, we also created a special binning mechanic, by which the security expert can infuence the coloring (details in 4.4). Finding " classes " of activity from the visual appearance already works to a certain extent but also has its limits. The algorithm we apply for color mapping is straightforward but also rather basic. Evaluating a " group " of records that come from the same IP/user,would allow a second pass for fne tuning colors or intensities . If, in an ssh-example, " root " would " normally " log in via key-fle but now logged in (successfully) via password, this " accepted password " is very abnormal, while other users might login via password regularly. In " 7 Discussion " , we discuss how colorizing by value frequency could be replaced with more sophisticated mechanics to (pre)discover anomalies. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION</head><p>The co-creation process comprised a continuous feedback loop, throughout which our collaborators informed the design of the visualization with their observations and feedback. In the following, we summarize the most important fndings we gained with regard to the Pixel Carpet visualization. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Expert Feedback on the Pixel Carpet</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Setup of Feedback Sessions</head><p> In this phase, we worked with people or groups from four different organizations. Two took part in our interviews and workshop: one person was responsible for network planning and computer security at a scientifc supercomputing centre (#1) and the others were product managers from a security appliance vendor (#2). Two people joined later: a security manager in a company for electronic payment (#3) and a system and security administrator of a medium sized company (#4). Each evaluation session was one to one, on location or web based with screen sharing. We briefy explained how the visualization got generated and how the main tools worked and then let the experts explore the visualization and the datasets. All participants investigated ssh-and Apache-examples. Each session took between one and two hours and got audio recorded if allowed by the interviewee. We also worked in a team of two and took notes. Later, we analyzed our fndings in categories such as general security strategies at this organization , feedback on the visualization, and feedback on the interaction and the software interface. With interviewees #1 and #3, we also discussed different approaches to visualizing the ssh log fle that also evolved from the same co-creative process: parallel coordinates and a combination of scatter plot and slope graphs. <ref type="figure" coords="6,318.20,211.24,18.86,7.99">Fig. 5</ref>: Specifc color combinations that represent specifc activities on an ssh server: regular access (left), password guessing (middle), user name guessing (right) <ref type="figure" coords="6,318.20,567.14,18.86,7.99">Fig. 7</ref>: Effects of " binning " different values of a parameter together. In this case, we instructed the color mapping to treat all jpeg images (as part of the URL) as if it was one and the same. While each image on its own is rarely accessed (indicated by red pixels in the top band), jpegs in general are a usual request (blue pixels in the bottom band). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Important Overarching Findings</head><p>In case of the ssh log fle, the experts could quickly check wide spread, automated login attempts with the help of pixel colors and the highlighting tool. These are usually turned away by the authentication system ( " failed password " ) but in one case, the attempt was successful. The change in the colors of the multi-pixels at the end of one of the series caught the attention of expert #1 early on in the investigation : " The 'accepted password'-pixel stands out clearly. " (<ref type="figure" coords="7,128.68,138.25,20.01,9.00" target="#fig_6">Fig. 8</ref>) The login with the (most likely) stolen key fle was initially harder to see. It came to light when the expert fltered away all records he knew were legitimate and from trusted machines. It gave itself away by its rare source IP. Considering the color mapping algorithm, experts #2 and #4 wanted to have a better " semantic " differentiation, i.e. a " failed password " should not resemble an " accepted password " . They would prefer two clearly distinct color hues. Investigating and interpreting the Apache log fles turned out to be more complicated to start with. As mentioned earlier, it is quite diverse in regards of visitors (source countries), web-server response codes, and resources (URLs) accessed. Binning trustworthy entries together and/or removing them from display was highly effcient, although the experts missed regular expressions and boolean search to better specify their flter criteria. After some flter iterations, the visualizations cleared up. The log from the private web-server showed huge amounts of requests that were obviously checking for fawed plugins and potential misconfgurations: a typical preparation for attacks on applications. Several experts suggested to save their manually constructed flters to apply them automatically in future sessions. Even more, They liked the idea to construct a flter this way with visual and interactive support , a feature they were missing in their IDS rules creation tools. The web master #4 commenting on this use case wished for an option to automatically classify " legitimate visits " , " search engine robots " , and everything else. The multi-pixels themselves were ambiguous in this area. The two experts #1 and #3 pointed out that they liked the visualization because they stayed in control of classifcation, and that no automated system had fltered the data by some hidden algorithms. But they also stated that they preferred a tool that shows more and requires less clicks. This topic needs careful balancing. For the approach described here, we focused not on making the root causes of incidents immediately clear from the visualization but to fnd areas of interest and get a " feeling " for the dataset. Our aim was guiding the focus of the experts so that they fnd the items to inspect more quickly, not clas sifying the dataset automatically. Due to space constraints, we do not discuss the alternative visualizations (parallel coordinates and scatter plot variant) in greater detail Two key differences are: In contrast to the Pixel Carpet, they do not show events in chronological order which we found important to understand activities. The parallel coordinates need at least user input in the form of brushing to detect patterns. Especially with the huge number of different values in the Apache log, both approaches suffered from overplotting. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Additional Findings</head><p>It turned out that the experts could comment best on Pixel Carpets based on data from their own networks (the dataset itself, however , could be unknown to them or previously uninspected). Data from other systems still revealed patterns to our test participants but it was harder to classify them: activity that is normal in one system can be exceptional in another. Regularly repeating patterns can originate from a script that the administrators implemented themselves or from an automated attack from the outside. The frst time the participants saw the Pixel Carpet, it was quite unfamiliar to all experts. As the highlighting tool reacts on hover, they were drawn towards exploring how the visualization works and what they can actually see. Generally, the participants responded interested and favorably to the interface: " I have never seen something like this, which I mean in a positive way. " (#2) The mechanics of fltering and binning needed some explanations from our side. All experts agreed that the visualization was particularly suited for the inspections of log fles after an incident ( " post mortem " analysis) and " when you don't know (yet) what you are looking for " (#3). It would even help understand unfamiliar datasets because of the clear and easy to understand visualization mechanics. They admitted that log fle inspection was known as an important measure that they should perform more often but see as too tedious . " Continuous monitoring should still be done by automated scanners. But if I had a tool like this, I would certainly look at logs more often. " (#4) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RELATED WO R K</head><p> After we have laid out the key idea of the Pixel Carpet and the cocreative approach that led us to it, we want to put it into context with existing approaches. Livnat et al. combine several visualization techniques (circular layout, network graph, geographical maps) to reveal various kinds of relations and anomalies <ref type="bibr" coords="7,423.00,495.35,13.80,9.00" target="#b18">[19]</ref>. Their main goal is situational awareness, i.e. the big picture, but they also allow access to traffc details. The remarkable effectiveness of their tool comes from a design tailored to fow records (e.g. network topology) that would not easily translate to web server logs (our DR5). In contrast to that, Humphries et al. follow a log type agnostic approach with ELVIS <ref type="bibr" coords="7,347.10,555.35,13.80,9.00" target="#b9">[10]</ref>, which features smart mechanics to determine the type of data felds and to propose adequate (basic) visualizations. These basic mini visualizations already provide some statistical overview on a per feld level. They can be easily combined (drag and drop) to form new visualizations. While the feld extraction and statistics features are promising, the Pixel Carpet brings overview capabilities and a chronological view that are less developed in ELVIS. Phan et al. <ref type="bibr" coords="7,366.90,635.35,14.89,9.00" target="#b24">[25] </ref>rely on external triggers to start an investigation with their system " Isis " . Once the investigation is narrowed down to a single IP, they offer a smart matrix view to analyze and reconstruct the course of events. While their display of time in an " ordi nal space " is similar to the Pixel Carpet, it needs signifcant fltering before it shows up and details are revealed. Phan et al. <ref type="bibr" coords="7,366.60,695.35,14.89,9.00" target="#b24">[25] </ref>and even more Xiao et al. <ref type="bibr" coords="7,479.00,695.35,14.89,9.00" target="#b34">[35] </ref>describe in detail how the analyst is involved in the classifcation of events. gowitz and Goodman have the notion of a " human in the loop " <ref type="bibr" coords="8,54.10,65.25,14.90,9.00" target="#b25">[26] </ref>that describes a man and machine system that combines the pattern recognition abilities of both and includes a feedback mechanism for iterative analysis. This resonates with the requirements that our interview partners had (DR1, DR3). Shneiderman emphasizes that the system's operations should be transparent to the people so they can trust the results and take on responsibility for the conclusions they draw <ref type="bibr" coords="8,162.80,125.25,13.80,9.00" target="#b27">[28]</ref>. Conti et al. <ref type="bibr" coords="8,108.10,135.25,10.40,9.00" target="#b2">[3] </ref>and Weseloh <ref type="bibr" coords="8,172.50,135.25,14.89,9.00" target="#b32">[33] </ref>propose pixel maps directly for computer security visualizations. They use a simple form with one (data) dimension and a single color. Especially Conti et al. point out, how this solution lets patterns emerge visually and thus supports human pattern recognition. Both visualizations are embedded into analysis tools that at least in parts are used in productive workfows. Interaction with these visualizations, however, appears to be limited to viewing results and retrieving clear text/context information. Direct manipulation in the sense of visual analytics seems not to be implemented (DR4), such as fltering from within the visualization or dynamically displaying flter matches, something that our user group found very valuable. Chung et al. <ref type="bibr" coords="8,54.10,255.25,10.40,9.00" target="#b1">[2] </ref>show pixel oriented techniques for big security data sets, using a very large physical screen for overview with smaller, individual screens for detail inspection. They do not discuss the option of stacking pixels and instead distribute different aspects over different views. Pixel maps are fairly straightforward visualizations and have been around for a long time. This enabled us to build on a stack of work, such as Keim et al. <ref type="bibr" coords="8,148.20,325.25,14.89,9.00" target="#b13">[14] </ref>and Lammarsch et al. <ref type="bibr" coords="8,245.70,325.25,13.80,9.00" target="#b16">[17]</ref>. Keim et al. have thoroughly researched display techniques and applications and offer sophisticated ways to map data to various visualization properties (x, y coordinates, display sections, color, intensity ). They usually distribute parameters of a record into different " sub windows " of their display. It is easier to read but makes it harder to fnd differences in combinations of parameters. In our approach, we integrated those parameters, which brings us closer to the idea of Levkowitz' Color Icons <ref type="bibr" coords="8,227.80,405.25,13.80,9.00">[18]</ref>. This concept suggests to create matrices of pixels, with one matrix representing one entry of a multi-dimensional dataset. The advantage is that a whole data record is shown close together. As Levkowitz points out, this improves revealing patterns and relationships when combined with the matrices of the rest of the data, without the need for user activity, such as brushing. We found huge amounts of matrices visually confusing, however, and limited ourselves to a single " column " of pixels per dataset entry. Working with categorical data (such as source countries) in pixel maps needs some transformations as pixel color is easiest mapped to numerical values. Keim et al. have shown an implementation in <ref type="bibr" coords="8,104.70,525.25,14.89,9.00" target="#b14">[15] </ref> but it is quite limited in the number of categories it can hold so that we saw room for improvement. While pixel maps are mostly used because of their overview capabilities , Janetzko et al. put their focus on highlighting anomalies <ref type="bibr" coords="8,54.10,565.25,13.56,9.00" target="#b10">[11]</ref>. The results from their expert evaluation indicate that analysts can fnd anomalies quickly and easily (DR2) while maintaining overview and their orientation in time (DR4). We also share the chronological pixel arrangement with their work but extend it towards stacked pixels and the work with categorical data. Visualization projects and research follows user centered design principles on a regular basis <ref type="bibr" coords="8,160.10,625.25,9.48,9.00" target="#b4">[5]</ref>, <ref type="bibr" coords="8,175.58,625.25,13.80,9.00" target="#b15">[16]</ref>, <ref type="bibr" coords="8,195.66,625.25,13.83,9.00" target="#b19">[20]</ref> . Meyer et al. have defned a profound framework for the process and the validation of important steps <ref type="bibr" coords="8,113.30,645.25,13.80,9.00" target="#b21">[22]</ref>. They have also defned a set of roles that a larger data visualization project can involve and that need to col laborate for optimal results <ref type="bibr" coords="8,158.90,665.25,13.80,9.00" target="#b15">[16]</ref>. It involves the domain experts and visualization experts, of course, but also specialists for highthroughput computing. Truly participatory processes are still quite rare in this feld. The occurrences we found in security visualization (e.g. <ref type="bibr" coords="8,90.90,705.25,9.39,9.00" target="#b8">[9]</ref>), described the techniques and results quite briefy. </p><p>We provide a case study that implements participatory elements, something that Meyer et al. wish to happen more in this domain. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Moving to Larger Data Sets</head><p>For most of our exploration, we worked with excerpts containing less than 10,000 lines which is over a magnitude below the intended target application at larger data centers. We worked with datasets exceeding the available screen size and one general fnding is that the coloring algorithm works better the more data it covers (the larger the mass, the more the exceptions stand out). We did not investigate " big data " issues in practice, mainly because of the considerable engineering efforts required, instead our interest was in rapid prototyping of visualizations. We do not propose the Pixel Carpet as " frst line of defense " , e.g. in live monitoring . We rather think that it is used to explore alerts with vague indications, which means that the range of time windows or machines (IPs) is already somewhat limited. The advantage (e.g., over the previously discussed " Isis " <ref type="bibr" coords="8,451.50,246.25,14.40,9.00" target="#b24">[25]</ref>) is that the indicator can be quite imprecise because of the overview capabilities of the Pixel Carpet. Beyond that, we see several options for visual compression techniques that try to preserve small values, such as anomalies (e.g. <ref type="bibr" coords="8,375.60,286.25,13.43,9.00" target="#b11">[12]</ref>). The Pixel Carpet can also be combined into other visualizations without giving up its advantages (<ref type="bibr" coords="8,515.39,296.25,42.23,9.00">Fisher et al. </ref>provide ideas in this direction <ref type="bibr" coords="8,433.00,306.25,9.39,9.00" target="#b7">[8]</ref>). Assuming that most security engineers work in dedicated offces, we also see the option to increase the number of physically available pixels by working with a wall of screens (building on Chung et al. <ref type="bibr" coords="8,472.90,336.25,10.12,9.00" target="#b1">[2]</ref>) ￼ </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Human and Machine Based Detection</head><p>As laid out before, the system should prepare and present the data with the goal to harness human pattern detection. Major decisions should be left to the user to provide room for exploration and intervention. User-driven does not mean purely manual: We have an early and fairly simple algorithm already in place to " preprocess " the data in our current proposal. Researching more powerful algorithms, including cluster analysis and anomaly scoring (as, e.g. in <ref type="bibr" coords="8,357.80,438.25,14.08,9.00" target="#b10">[11]</ref> ) and selecting one that fts with our goals is an important area for future improvements. The Pixel Carpet is meant to complement highly automated systems (such as IDS) in a future security workbench as it has been suggested in on of the workshops (<ref type="figure" coords="8,345.15,478.25,20.90,9.00" target="#fig_3">Fig. 2</ref> ) . We need to carefully balance automated processing , visualization, and user control. Based on our experience with ssh-and apache-log fles, we see testing with a broader user base and a wider set of use cases as a useful next step. A structured comparison, e.g. with the " sub window " approach of Keim <ref type="bibr" coords="8,411.40,528.25,13.80,9.00" target="#b13">[14]</ref>, is necessary for assessing specifc features of the Pixel Carpet. A formalized evaluation process also complements the more empathic co-creation very well and corresponds to the " validation " requirements of Meyer et al. <ref type="bibr" coords="8,540.70,558.25,13.80,9.00" target="#b21">[22]</ref>. While continuous feedback is a part of co-creation anyways, the distinct levels of their " Nested Model " will help to create focused sessions at the right moment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Insights into Co-Creation in Data Visualization</head><p>From our work as designers, we had experience with several of co-creative methods. Some more general principles of co-creation held true also for the area of data visualization, such as profting from highly diverse teams, fast exchange of information, no hierarchies , and an encouraging and inspiring atmosphere. Asking everyone to work visually with pen and paper (instead of, e.g., writing down requirements) also helped to output frst ideas and to get to their essence. Then again , we had not put enough effort in integrating data into these " analog " exercises, which lead to overly optimistic as -sumptions in the sketches about data structures or values. For evaluation (and refnement), a " quick and dirty " tool or method to check an idea would be necessary. So far, we are still looking for a method that is quick and accessible enough to ft into a fast paced, trial and error-based ideation workshop. This became also apparent in the subgroup directly focusing on software tools and trying to put together analysis code during the workshop. We had underestimated the amount of time it takes for getting a common understanding of the structure and contents of the data. Starting with programming more or less from scratch under these conditions and within few hours turned out to be impossible . The participants reported that the intensity of fruitful exchange in this session was extremely high. Without the " crazy endeavor " of live coding, it might not have happened. An improvement for future meetings would be to work with a single dataset, that everyone can analyze beforehand, possibly already write code fragments for it , and also to have more modular data analysis and visualization tools in place. In many cases, some features of a dataset must be extracted algorithmically to create a really meaningful visualization on top of it. Data can be considered the original material a visualization is crafted from, data comes frst, visualizations should match its conditions . We have to pay attention, however, so that the rather abstract data sets do not damp the generation of concrete ideas in the early phases. Distilling data structure, some special features or defning challenges could be a way to get it integrated productively . It is also worth mentioning that getting hands on datasets of reasonable size and quality from the domain in question needs enough time to solve organizational, technical, or privacy questions . Putting datasets right into the early ideation processes is a highly promising strategy for adapting the co-creative approach. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">PRINCIPLES F O R CO-CREATION I N DATA VISUALIZATION</head><p>Based on our experiences and the refection of what worked and what did not (s. section 7.3), we formulate tentative guidelines for a co-creative approach to data visualization projects. They are organized roughly by project phases but loops and iterations are a typical feature of this approach. Recruiting. Try to establish a team of volunteers (stakeholders) that can commit enough time to participate in the process. You do not want to " touch and go " , obtaining an interview and continuing on your own. McLachlan et al. have a good description of challenges in recruiting highly busy experts and in iteratively adding new stakeholders <ref type="bibr" coords="9,118.60,487.25,13.80,9.00" target="#b20">[21]</ref>. Domain understanding. Get immersed into the topic as deeply as possible. We used the ethnographic methods of interviews and observations as described by D'Amico et al. <ref type="bibr" coords="9,222.90,517.25,9.56,9.00" target="#b4">[5]</ref>. An even better approach is to aim for a shared understanding on both sides (security and visualization) through joint, explorative, hands-on creation sessions (D'Amico et al. propose " hypothetical scenario construction " , Sanders has a more in-depth description and argument in <ref type="bibr" coords="9,63.70,567.25,9.69,9.00" target="#b6">[7]</ref>). Discuss how your collaborators work with data, and try to pin down the results precisely as use cases. It forces you to be very clear about the individual steps and details, and structures the process into operational modules (D'Amico proposes Cognitive Task Analysis <ref type="bibr" coords="9,108.40,607.25,9.56,9.00" target="#b4">[5]</ref>, Cooper has tasks as part of his Goal Directed Design <ref type="bibr" coords="9,81.90,617.25,9.39,9.00" target="#b3">[4]</ref>). Requirement defnition. Defne and refne challenges with all stakeholders, ideally in a face-to-face workshop. Achieving a common understanding is extremely valuable to focus further efforts . Converging on a few essential requirements with a diverse team, however, is not always possible. Defning the goals together also strengthens commitment for the process ahead (also reported i n <ref type="bibr" coords="9,64.40,687.25,9.39,9.00" target="#b8">[9]</ref> ). It might be worth noting that this co-creative way of requirement distillation builds on communication rather than quantitative evaluation. Why and how something is relevant is given more weight than how many fnd it relevant (group sizes are comparatively small, too). Data acquisition and inspection. Try to get real-world data sets from your target users that are typical and relevant for them. Take care of this as early as possible as privacy and the sensitive information contained may pose considerable and time-consuming hurdles. Investigate the data with the tools of your choice to get an understanding of its structure and quality (McLachlan et al. even set up their own monitoring tools in their network <ref type="bibr" coords="9,499.70,135.25,13.43,9.00" target="#b20">[21]</ref>). Ideation. Brainstorm and sketch ideas together. Pen and paper are quick and easily accessible. They are well suited to frame ideas and describe the goals for a tool. Ideation tasks for these sessions must be well defned and " entry barriers " kept low to encourage all participants (example schedules and tools in <ref type="bibr" coords="9,521.40,185.25,13.43,9.00" target="#b28">[29]</ref>). Ideas from data. Work and sketch with data as a " material " early on and incorporate it into creative sessions. Characteristics and challenges of real data are valuable input for new solutions. As it takes considerable amounts of time to familiarize with a data set, workshop participants should get the (same) data sets beforehand and inspect them as a " homework " . This requires digital tools which bring their own challenges for joint creative work. Software that accepts a wide range of data types and offers a large number of presets seems promising, such as Tableau <ref type="bibr" coords="9,508.80,275.25,13.80,9.00" target="#b29">[30]</ref>. Prototyping and validation. Focus on the aspects (such as design requirements) you want to validate frst with early versions of the visualization. Adapt your questions and evaluation methods to the state and focus of your sketches (s. Munzner et al. for ade quate methods <ref type="bibr" coords="9,375.50,325.25,13.43,9.00" target="#b22">[23]</ref> ). Rapid prototyping methods have been described at length so that you can choose what fts your needs and taste. Depending on the skill set of your stakeholders, they might be even able and willing to contribute their own code modules. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION</head><p>We have shown how the visualization approach of a pixel map variant can turn unlabeled data into an image that makes this data easier to survey and inspect. With different multivariate datasets we explored how to better show their structures and the activity patterns they contain. Our proposal also encompasses interactive tools that allow users to analyze their data visually. The intended audience of network security engineers welcomed this visual approach to " their " log fles because it allows them to understand large amounts of logs more quickly and fnd patterns they could not fnd with their current tools. The early prototype that we describe in this paper led to valuable suggestions for improvements and new extensions. Throughout the process, we involved security experts as user group and experienced how valuable continuously available consultants and feedback partners are. As visual analytics becomes even more important with large datasets ( " Big Data " ), new expert tools need to be developed. They can only be effective (and accepted ) when visualization specialists understand the domain experts' needs so that they can design appropriate tools. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,62.60,235.25,231.36,9.00;3,54.10,245.25,239.35,9.00;3,54.10,255.25,239.34,9.00;3,54.10,265.25,239.31,9.00;3,54.10,275.25,239.49,9.00;3,54.10,285.25,239.44,9.00;3,54.10,295.25,239.51,9.00;3,54.10,305.25,128.38,9.00;3,62.60,315.25,137.18,9.00"><head></head><figDesc>DR4: Combine overview and quick fltering. Visual tools should help to stay in context, correlate events, fnd patterns. Our participants wanted to have a fuid interaction when investigating an incident, for fltering out items they are interested in and switching back to an overview when needed. For a visualization, this means as much log records on one screen as possible to fnd patterns at large but also quick access to single records to inspect and flter them whenever necessary. DR5: Support various log fle types. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,318.70,462.84,219.43,7.99;4,318.70,472.34,235.92,7.99;4,318.70,481.84,112.86,7.99"><head>Fig</head><figDesc> Fig. 3: A look at the construction of the Pixel Carpet with multipixels and the " implementation " at screen resolution. One " column " is representing one data record. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,318.70,213.54,236.44,7.99;4,318.70,223.04,189.70,7.99;4,318.70,232.54,138.64,7.99"><head>Fig. 2: </head><figDesc>Fig. 2: One of the sketches where the workshop participant wanted to have a direct visualization of raw data (red arrows), complementing an automated analysis. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,54.50,345.04,501.92,7.99;5,54.50,354.54,496.32,7.99;5,54.50,364.04,398.28,7.99"><head>Fig. 4: </head><figDesc>Fig. 4: Video showing the main interactive techniques currently implemented for the Pixel Carpet: highlighting of identical records, tool tips and clear text display, and fltering/removal on click. The numbers in the Carpet refer to the hours from the time stamp. Two consecutive numbers mean that all records in between got fltered away. (Data from ssh log fle, IP addresses replaced for publication). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="6,318.20,383.44,216.82,7.99;6,318.20,392.94,234.88,7.99;6,318.20,402.44,110.16,7.99"><head>Fig. 6: </head><figDesc>Fig. 6: Detail view on a large Apache access log fle. Note the bands of similar activity. In the upper right corner, close to hour 10, there is a block of rare records. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="7,317.20,215.24,231.05,7.99;7,317.20,224.74,225.65,7.99;7,317.20,234.24,219.34,7.99;7,317.20,243.74,224.36,7.99;7,317.20,253.24,152.35,7.99"><head>Fig. 8: </head><figDesc>Fig. 8: Detecting a successful brute force attack in an ssh log: the red pixel in the lowest row of a multi pixel indicates a rare value, while the other parameters appear to stay the same (top). The highlighting tool reveals a series of attempts (middle, enlarged), confrmed by the clear text output (bottom). </figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="10,72.00,68.60,222.16,8.00;10,72.00,78.10,191.42,8.00"  xml:id="b0">
	<monogr>
		<title level="m" type="main">Tao of Network Security Monitoring, The: Beyond Intrusion Detection</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Bejtlich</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Addison-Wesley Professional</publisher>
		</imprint>
	</monogr>
	<note>1st. ed</note>
</biblStruct>

<biblStruct coords="10,72.00,87.60,221.73,8.00;10,72.00,97.10,221.11,8.00;10,72.00,106.60,168.00,8.00"  xml:id="b1">
	<analytic>
		<title level="a" type="main">Pixel-oriented treemap for multiple displays</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Chung</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<forename type="middle">J</forename>
				<surname>Cho</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Self</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>North</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Conference on Visual Analytics Science and Technology (VAST)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="289" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,116.10,222.16,8.00;10,72.00,125.60,222.16,8.00;10,72.00,135.10,222.16,8.00;10,72.00,144.60,77.78,8.00"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Visual Reverse Engineering of Binary and Data Files</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Conti</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Dean</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Sinda</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Sangster</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Workshop on Visualization for Computer Security</title>
		<meeting>the 5th International Workshop on Visualization for Computer Security<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,154.10,222.16,8.00;10,72.00,163.60,128.69,8.00"  xml:id="b3">
	<monogr>
		<title level="m" type="main">About Face 3: The Essentials of Interaction Design</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Cooper</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Reimann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Cronin</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,173.10,221.90,8.00;10,75.06,182.60,218.65,8.00;10,72.00,192.10,221.27,8.00;10,72.00,201.60,206.19,8.00"  xml:id="b4">
	<analytic>
		<title level="a" type="main">Achieving Cyber Defense Situational Awareness: A Cognitive Task Analysis of Information Assurance Analysts</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">D</forename>
				<surname>Amico</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Whitley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Tesone</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>O &apos;brien</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Roth</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Hum. Factors Ergon. Soc. Annu. Meet</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="229" to="233" />
			<date type="published" when="2005-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,211.10,222.16,8.00;10,72.00,220.60,222.10,8.00;10,72.00,230.10,58.00,8.00"  xml:id="b5">
	<analytic>
		<title level="a" type="main">A survey on security visualization techniques for web information systems</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">K</forename>
				<surname>Dang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">T</forename>
				<surname>Dang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Web Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="6" to="31" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,239.60,222.16,8.00;10,72.00,249.10,180.60,8.00"  xml:id="b6">
	<analytic>
		<title level="a" type="main">Virtuosos of the Experience Domain</title>
		<author>
			<persName>
				<forename type="first">Elisabeth</forename>
				<surname>Sanders</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2001 IDSA Education Conference</title>
		<meeting>the 2001 IDSA Education Conference</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,258.60,222.24,8.00;10,72.00,268.10,221.61,8.00;10,72.00,277.60,222.16,8.00;10,72.00,287.10,221.53,8.00;10,72.00,296.60,215.40,8.00"  xml:id="b7">
	<analytic>
		<title level="a" type="main">BANKSAFE: A visual situational awareness tool for large-scale computer networks: VAST 2012 challenge award: Outstanding comprehensive submission , including multiple vizes</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Fischer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Fuchs</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Mansmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Keim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Analytics Science and Technology (VAST), 2012 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="257" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,306.10,222.02,8.00;10,72.00,315.60,221.32,8.00;10,72.00,325.10,144.20,8.00"  xml:id="b8">
	<analytic>
		<title level="a" type="main">Matrixexplorer: a dual-representation system to explore social networks</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Henry</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J.-D</forename>
				<surname>Fekete</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Comput. Graph. IEEE Trans. On</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="677" to="684" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,334.60,222.16,8.00;10,72.00,344.10,221.42,8.00;10,72.00,353.60,166.70,8.00"  xml:id="b9">
	<analytic>
		<title level="a" type="main">ELVIS: Extensible Log VISualization</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Humphries</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Prigent</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Bidan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Majorczyk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Workshop on Visualization for Cyber Security</title>
		<meeting>the Tenth Workshop on Visualization for Cyber Security</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,363.10,221.89,8.00;10,72.00,372.60,221.39,8.00;10,72.00,382.10,107.10,8.00"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Anomaly detection for visual analytics of power consumption data</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Janetzko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Stoffel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Mittelstädt</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Keim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="27" to="37" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,391.60,221.76,8.00;10,72.00,401.10,221.37,8.00;10,72.00,410.60,209.60,8.00"  xml:id="b11">
	<analytic>
		<title level="a" type="main">The Information Mural: a technique for displaying and navigating large information spaces</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">F</forename>
				<surname>Jerding</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">T</forename>
				<surname>Stasko</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="257" to="271" />
			<date type="published" when="1998-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,420.10,221.44,8.00;10,72.00,429.60,68.98,8.00"  xml:id="b12">
	<analytic>
		<title level="a" type="main">Announcing the Release of Splunk Enterprise 6</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Kalra</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Splunk Blogs</title>
		<imprint>
			<date type="published" when="2013-10-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,439.10,221.75,8.00;10,72.00,448.60,222.09,8.00;10,72.00,458.10,82.00,8.00"  xml:id="b13">
	<analytic>
		<title level="a" type="main">Designing pixel-oriented visualization techniques: Theory and applications</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Keim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Comput. Graph. IEEE Trans. On</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="78" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,467.60,221.63,8.00;10,72.00,477.10,219.67,8.00;10,72.00,486.60,124.70,8.00"  xml:id="b14">
	<analytic>
		<title level="a" type="main">Pixel Bar Charts: A Visualization Technique for Very Large Multi-Attribute Data Sets †</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Keim</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">C</forename>
				<surname>Hao</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Dayal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hsu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Vis</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="20" to="34" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,496.10,221.94,8.00;10,72.00,505.60,222.07,8.00;10,72.00,515.10,42.00,8.00"  xml:id="b15">
	<analytic>
		<title level="a" type="main">Visualization Collaborations: What Works and Why</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">M</forename>
				<surname>Kirby</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Meyer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Appl. IEEE</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="88" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,72.00,524.60,221.73,8.00;10,72.00,534.10,222.16,8.00;10,72.00,543.60,221.38,8.00;10,72.00,553.10,218.60,8.00"  xml:id="b16">
	<analytic>
		<title level="a" type="main">Hierarchical temporal patterns and interactive aggregated views for pixel-based visualizations</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Lammarsch</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Aigner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bertone</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Gartner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Mayr</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Miksch</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Smuc</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualisation 13th International Conference</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="44" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,317.90,55.60,239.82,8.00;10,335.80,65.10,221.39,8.00;10,335.80,74.60,222.04,8.00;10,335.80,84.10,81.98,8.00"  xml:id="b17">
	<analytic>
		<title level="a" type="main">Color Icons: Merging Color and Texture Perception for Integrated Visualization of Multiple Parameters</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Levkowitz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2Nd Conference on Visualization &apos;91</title>
		<meeting>the 2Nd Conference on Visualization &apos;91<address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="164" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,93.60,221.58,8.00;10,335.80,103.10,221.52,8.00;10,335.80,112.60,147.70,8.00"  xml:id="b18">
	<analytic>
		<title level="a" type="main">Visual correlation for situational awareness</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Livnat</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Agutter</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Moon</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Foresti</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualization, 2005. INFOVIS 2005. IEEE Symposium on</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="95" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,122.10,214.76,8.00"  xml:id="b19">
	<monogr>
		<title level="m" type="main">Applied Security Visualization. Pearson Education</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Marty</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,131.60,221.62,8.00;10,335.80,141.10,221.83,8.00;10,335.80,150.60,220.95,8.00;10,335.80,160.10,145.10,8.00"  xml:id="b20">
	<analytic>
		<title level="a" type="main">LiveRAC: interactive visual exploration of system management time-series data</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Munzner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Koutsofos</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>North</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1483" to="1492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,169.60,221.91,8.00;10,335.80,179.10,221.45,8.00;10,335.80,188.60,222.16,8.00;10,335.80,198.10,107.80,8.00"  xml:id="b21">
	<analytic>
		<title level="a" type="main">The four-level nested model revisited: blocks and guidelines</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Meyer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Sedlmair</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Munzner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 BELIV Workshop: Beyond Time and Errors-Novel Evaluation Methods for Visualization</title>
		<meeting>the 2012 BELIV Workshop: Beyond Time and Errors-Novel Evaluation Methods for Visualization</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,207.60,221.84,8.00;10,335.80,217.10,221.87,8.00;10,335.80,226.60,50.00,8.00"  xml:id="b22">
	<analytic>
		<title level="a" type="main">A nested model for visualization design and validation</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Munzner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Comput. Graph. IEEE Trans. On</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="921" to="928" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,236.10,222.26,8.00;10,335.80,245.60,221.75,8.00;10,335.80,255.10,221.33,8.00;10,335.80,264.60,156.50,8.00"  xml:id="b23">
	<analytic>
		<title level="a" type="main">Technology transition of network defense visual analytics: Lessons learned from case studies</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">F</forename>
				<surname>O &apos;brien</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">D</forename>
				<surname>Amico</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">E</forename>
				<surname>Larkin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Technologies for Homeland Security (HST) IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="481" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,274.10,221.92,8.00;10,335.80,283.60,221.78,8.00;10,335.80,293.10,221.73,8.00;10,335.80,302.60,115.26,8.00"  xml:id="b24">
	<analytic>
		<title level="a" type="main">Visual Analysis of Network Flow Data with Timelines and Event Plots</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Phan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Gerth</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Lee</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Paepcke</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Winograd</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VizSEC</title>
		<editor>J. Goodall, G. Conti, and K.-L. Ma</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="85" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,312.10,222.16,8.00;10,335.80,321.60,221.91,8.00;10,335.80,331.10,114.98,8.00"  xml:id="b25">
	<monogr>
		<title level="m" type="main">Integrating human-and computer-based approaches to feature extraction and analysis</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">E</forename>
				<surname>Rogowitz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Goodman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="82910" to="82910" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,340.60,222.16,8.00;10,335.80,350.10,188.20,8.00"  xml:id="b26">
	<analytic>
		<title level="a" type="main">Co-creation and the new landscapes of design</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">B N</forename>
				<surname>Sanders</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Stappers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoDesign</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="18" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,359.60,222.16,8.00;10,335.80,369.10,222.06,8.00;10,335.80,378.60,18.00,8.00"  xml:id="b27">
	<analytic>
		<title level="a" type="main">Inventing discovery tools: combining information visualization with data mining1</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Shneiderman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Vis</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="12" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,388.10,221.74,8.00;10,335.80,397.60,222.20,8.00;10,335.80,407.10,79.90,8.00"  xml:id="b28">
	<analytic>
		<title level="a" type="main">Contextmapping: Experiences from practice</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Sleeswijk-Visser</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Stappers</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">V</forename>
				<surname>Der Lugt</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">B N</forename>
				<surname>Sanders</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoDesign</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="119" to="168" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,416.60,222.02,8.00;10,335.80,426.10,57.95,8.00"  xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">Tableau</forename>
				<surname>Software</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Tableau</surname>
			</persName>
		</author>
		<imprint>
			<publisher>Tableau Software</publisher>
			<pubPlace>Seattle, Washington, United States</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,435.60,221.44,8.00;10,335.80,445.10,221.84,8.00;10,335.80,454.60,222.06,8.00;10,335.80,464.10,45.89,8.00"  xml:id="b30">
	<monogr>
		<title level="m" type="main">The Apache Software Foundation Log Files -Access Log</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>T T P S E R V E R</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2014-02-25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,473.60,222.07,8.00;10,335.80,483.10,18.00,8.00"  xml:id="b31">
	<monogr>
		<title level="m" type="main">Information Visualization: Perception for Design</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Ware</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,492.60,221.90,8.00;10,335.80,502.10,222.26,8.00;10,335.80,511.60,222.09,8.00;10,335.80,521.10,18.00,8.00"  xml:id="b32">
	<analytic>
		<title level="a" type="main">Network Security Visualization Techniques in Early Warning Systems</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Weseloh</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">presented at the 1 st European Workshop on Internet Early Warning and Network Intelligence</title>
		<meeting><address><addrLine>Hamburg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,530.60,222.16,8.00;10,335.80,540.10,222.08,8.00;10,335.80,549.60,45.89,8.00"  xml:id="b33">
	<monogr>
		<title level="m" type="main">OpenSSH, 2013. [Online] Available: http://en.wikibooks.org/wiki/OpenSSH/Logging</title>
		<author>
			<persName>
				<surname>Wikibooks</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page" from="25" to="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,335.80,559.10,221.94,8.00;10,335.80,568.60,222.16,8.00;10,335.80,578.10,222.16,8.00;10,335.80,587.60,102.98,8.00"  xml:id="b34">
	<analytic>
		<title level="a" type="main">Enhancing Visual Analysis of Network Traffc Using Knowledge Representation</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Xiao</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Gerth</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Hanrahan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Analytics Science And Technology</title>
		<meeting><address><addrLine>Baltimore , MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="107" to="114" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
