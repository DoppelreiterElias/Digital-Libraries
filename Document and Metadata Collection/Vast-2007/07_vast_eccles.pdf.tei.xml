<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T13:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Stories in GeoTime</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Ryan</forename>
								<surname>Eccles</surname>
							</persName>
							<affiliation>
								<orgName type="institution">Oculus Info Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Thomas</forename>
								<surname>Kapler</surname>
							</persName>
							<affiliation>
								<orgName type="institution">Oculus Info Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Robert</forename>
								<surname>Harper</surname>
							</persName>
							<affiliation>
								<orgName type="institution">Oculus Info Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">William</forename>
								<surname>Wright</surname>
							</persName>
							<affiliation>
								<orgName type="institution">Oculus Info Inc</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Stories in GeoTime</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CR Categories: H12 [User/Machine Systems]: Human Information Processing – Visual Analytics</term>
					<term>H52 [Information Interfaces &amp; Presentations]: User Interfaces – Graphical User Interfaces (GUI)</term>
					<term>Keywords: human information interaction, visual analytics, sense-making, narrative, pattern detection, story making, story telling</term>
				</keywords>
			</textClass>
			<abstract>
				<p>A story is a powerful abstraction used by intelligence analysts to conceptualize threats and understand patterns as part of the analytical process. This paper demonstrates a system that detects geo-temporal patterns and integrates story narration to increase analytic sense-making cohesion in GeoTime. The GeoTime geo-temporal event visualization tool was augmented with a story system that uses narratives, hypertext linked visualizations, visual annotations, and pattern detection to create an environment for analytic exploration and communication, thereby assisting the analyst in identifying, extracting, arranging and presenting stories within the data The story system lets analysts operate at the story level with higher-level abstractions of data, such as behaviors and events, while staying connected to the evidence. The story system was developed and evaluated in collaboration with analysts.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION </head><p>Narrative theory <ref type="bibr" coords="1,126.77,424.34,10.51,9.96" target="#b0">[1] </ref>suggests that people are essentially storytellers and have an implicit ability to evaluate a story for consistency, detail, and structure. From an analyst perspective, a story offers a common form of communication for investigating the feasibility of a connected collection of characters and their motives. For these reasons a story narrative presents a potent way of capturing the analysts' insights that can promote sharing of observations and understanding of complex phenomenon. Beyond communication, a story allows people to build spaces in which to think, act, and talk in a framework <ref type="bibr" coords="1,181.82,517.52,9.53,9.96" target="#b4">[5]</ref>. In this sense a story serves as an internal communication tool – a method of organizing the daily observations into meaningful knowledge. It is the ability to pull information together into a coherent story that guides the organization of observations into meaningful structures and patterns. To an intelligence analyst, a story acts as an artifact of tacit and gained knowledge applied to raw observed data. </p><p>The prototype GeoTime Stories system introduces three sets of features intended to allow analysis at a higher level of abstraction than traditional visualization tools. The first is a space-time pattern finding system that relieves the analyst from the need to search for some common behaviors and relationships among events and moving entities. Found patterns are passed to an annotation system that visually highlights the pattern events with an expressive graphic. The annotation system also tags the internal data model with information about the annotation. Finally a specialized text editing panel is provided allows the analysts to author narratives and explanations (reports) containing links to bookmarked views of events in time and space. The text system also provides a means to categorize content to support collaboration or multiple story threads. This system was developed following a cognitive task analysis of analysts. Reviews with analysts suggest that this system could increase the descriptive capability and clarity of their insights and reports. An example of an analytic story using GeoTime visualization was published <ref type="bibr" coords="1,357.15,253.70,15.02,9.96" target="#b16">[18] </ref>prior to completion of the capabilities described here. It serves as one example of the type of story that GeoTime Stories is intended to support. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND RELATED WORK</head><p>A story or narrative is essentially a means of communicating a sequence of events related to the experience of characters. Plowman <ref type="bibr" coords="1,356.59,337.40,15.00,9.96" target="#b12">[13] </ref>clarifies that although both terms narrative and story are typically seen as synonymous, a narrative specifically refers to the macro-structure of a document whereas a story refers to both structure and content. In Plowman, the narrative macrostructure was considered more problematic and more worthy of investigation than supporting content exploration. In intelligence analysis, however, the content of a story is also of particular importance and they both need to be equally addressed. </p><p>Classically, Aristotle, in Poetics, describes the objects of a tragedy (or story) as plot, character and thought. Thought is described as the processes of reasoning that lead characters to behave as they do. Plots are " arrangements of incidents " and tragedies are most importantly the representation of actions, not of characters. However, plots do more than organize events into a coherent structure. The authors of tragedies, or poets, grasp and represent the internal logic in a story that underlies the necessity of the outcome of the events. Laurel <ref type="bibr" coords="1,454.51,513.02,15.03,9.96" target="#b10">[11] </ref>states that a story offers a context to understand and communicate activities and plots played by characters or actors. Context helps an audience apply their tacit knowledge in order to better comprehend the point being communicated by the author. When applied to analysis, a story can therefore be a very useful medium for clearly communicating a situation and related information. </p><p>Various approaches to connect information visualization with the communicative power of story-telling have been investigated, each with advantages and drawbacks in the context of its usage by intelligence analysts. A common technique is to use hypertext links to multimedia <ref type="bibr" coords="1,391.52,636.86,15.00,9.96" target="#b13">[14] </ref>or additional textual <ref type="bibr" coords="1,484.67,636.86,10.90,9.96" target="#b7">[8]</ref><ref type="bibr" coords="1,495.57,636.86,14.54,9.96" target="#b14">[15] </ref>content. The LifeLines project allowed for the incorporation of multimedia and interactions for creation and playback of connected temporal data <ref type="bibr" coords="1,318.24,667.88,13.75,9.96" target="#b11">[12]</ref>, using interactively linked 2-D displays. The MyLifeBits system incorporates a lifetime's worth of media to tell a story <ref type="bibr" coords="1,542.06,678.26,9.54,9.96" target="#b2">[3]</ref>. In Vaucelle <ref type="bibr" coords="1,372.02,698.60,13.75,9.96" target="#b13">[14]</ref>, video content can be retrieved and associated with text in a system called a Textable Movie. This paradigm allows the author to assemble pre-recorded video clips together to form a movie based on the text content. The focus of the Textable Movie system is to add narrative structure to existing content, rather than address both content and structure. In systems such as the Textable Movie, linked content is immutable and limited in its context. The system is limited in that links are intended to be viewed but not manipulated and investigated further. </p><p>Zellweger <ref type="bibr" coords="2,106.00,136.58,15.03,9.96" target="#b14">[15] </ref>presented another interesting visualization technique for the hyperlink story through the Fluid Reader. It has been observed that stories should be more or less linear with minimal context switches to connected information <ref type="bibr" coords="2,265.87,167.66,9.71,9.96" target="#b1">[2]</ref>; an apparent contradiction for hyperlinked documents. To address this issue, Fluid Text includes links that expand in place to allow the text to still be read linearly. This is advantageous for providing footnotes and additional context on demand. The concept of a dynamic content story that can be read linearly is very interesting; however it is not amenable to an important requirement for some analytical techniques: the ability to compare and contrast different versions of stories that share some key aspects. Analysis of Competing Hypotheses is a common analytical method in which multiple possible explanations for an observation are explored. In order to support multiple story threads and collaborative analysis, the system should be able to remove, mix, and categorize content across the entire document. For example, if different characters tell parts of a story, hiding one character's contribution could significantly change its meaning. This is more like a filter on the story content, rather than a link to other content. A system that explores collaborative authoring mixed with annotation on visualization is Sense.us <ref type="bibr" coords="2,201.61,363.92,13.76,9.96" target="#b15">[16]</ref>. Although GeoTime uses a similar approach, Senus.us uses a blog-type discussion workflow as a textual foundation, whereas GeoTime is designed for authoring and presenting a single coherent story, which is more suited to the types of reports generated by analysts. In addition, the annotations made by sense.us are implemented as vector graphics that are overlaid above a visualization, whereas in GeoTime, annotations are semantically connected to the underlying data and become part of the time-space data itself. This makes it possible to trace an information path from a sentence in a story to the actual event data that it refers to. Manyeyes .com <ref type="bibr" coords="2,93.06,477.74,14.98,9.96">[17] </ref>offers a similar discussion blog-based system. However, instead of providing graphical annotation tools, it allows users to highlight data points in a linked view. This method does allow specific data to be semantically linked to a comment, but does not provide for graphical expressiveness. Finally, it has been suggested that visualization itself can be augmented using animation, voice narration, and visual annotations to tell a story about analysis <ref type="bibr" coords="2,200.85,560.18,9.52,9.96" target="#b3">[4]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">GeoTime – Unified Temporal and Geospatial Analysis</head><p>The Stories system is built on the GeoTime time-space visualization framework, which is designed to improve the perception and understanding of entity movements, events, relationships and interactions over time within a geospatial context <ref type="bibr" coords="2,84.68,650.96,10.37,9.96" target="#b8">[9]</ref><ref type="bibr" coords="2,95.05,650.96,13.83,9.96" target="#b9">[10]</ref>. GeoTime supports representations for the base elements of a story: events, people, objects, places and relationships. Its ability to display these elements in time and space make it a suitable platform on which to build representations and interactions with stories. GeoTime represents events within an X, Y, T coordinate space in which the X and Y plane represents geographic space, and the Z axis represents temporal space. Analyzing observations over time and geography is a common task but typically requires multiple, separate tools. The objective of GeoTime is to enable the analysis of information connectedness over time and geography within a single, highly interactive 3D view as shown in <ref type="figure" coords="2,437.53,126.27,29.41,9.96" target="#fig_0">Figure 1</ref>. Events are animated in time through the 3D space as the slider bar is moved. A previous evaluation of GeoTime found that its unified geo-temporal representation increased analysts' understanding of entity relationships and behaviors <ref type="bibr" coords="2,419.68,167.67,13.76,9.96" target="#b9">[10]</ref>. GeoTime allows the perception of who and what in the where and when. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DESIGN AND CONTEXT</head><p>The objective is to enable analysts to perform analysis at a higher level of abstraction than currently possible. Rather than working with raw or atomic data, the analyst should be able to work and think in terms of behaviors, events and plots such that it leads to comprehension, discovery, hypothesis generation and communication. In preparation for the GeoTime Stories investigations, a brief cognitive task analysis (CTA) study was completed including structured interviews, examination of work place artifacts and a review of the literature <ref type="bibr" coords="2,491.92,498.74,9.89,9.96" target="#b5">[6]</ref><ref type="bibr" coords="2,501.81,498.74,9.89,9.96" target="#b6">[7]</ref>. From the structured interviews, conducted with fourteen analysts, it was clear that the idea of " story " is broadly applicable to analysis. Deciding which dots to connect and how, what the context is, what the alternatives and the implications are, how one story leads to an-other, and how to share observations and collaborating is a daily and critical task. The following are illustrative interview excerpts: " Coherence and narrative are principles that guide the organization of observations into meaningful structures and patterns … Plots are formed of dominant concepts or leading ideas that the analyst uses to postulate patterns of relationships among the data ... a story must form a logical and coherent whole and be internally consistent as well as consistent with the evidence. " " It's good to put all the factoids together. See how they relate to hypotheses. Trajectories of factoids over time can tell a story. " " A hypothesis is an assertion. An elaborate hypothesis, a story. " " Once you have the data observations, and can see the links, in time and geography, you need to go to generation of hypotheses. <ref type="bibr" coords="3,54.00,74.84,40.79,9.96">[You need] </ref>to think of new possibilities and new lines of inquiry. " A theme emerged that suggests incremental hypothesis generation and the need to tie a story back to evidence was particularly important. A simple model of story emerged, as shown in <ref type="figure" coords="3,91.58,283.82,30.41,9.96" target="#fig_1">Figure 2</ref>, that helped to conceptualize the relationship between story concepts and the analytical workflow. The model defines a spectrum that ranges from low level facts and details to higher-level organizational structures, such as character and intent. Frequently used analytical concepts were located within this space. There are two workflows represented in this model, roughly described as bottom-up and top-down. Visualization and pattern detection within raw data serve as bottom-up methods for building information into higher level concepts. In contrast, a topdown workflow occurs when analysts apply their tacit knowledge to guide the search for information and patterns in the raw data from experience. The role of visualization in this model is to spark rapid recognition of those internalized stories by expressing patterns of activity in an easily digestible form. Bridging between experience and raw information is the basic activity of analysis. It enables prediction by mapping the known facts onto the familiar plotlines that an analyst has previously seen. We seek to facilitate this process in GeoTime. </p><p>Using the story spectrum model, two different approaches were defined to close the gap between the analytic stories and data visualization. The first was to help the analyst recognize patterns by creating higher-level visual pattern representations. This should stimulate faster recognition of tacit stories in the mind of an analyst. An early concept sketch, shown in <ref type="figure" coords="3,226.24,531.86,29.79,9.96" target="#fig_2">Figure 3</ref>, explored the use of expressive annotation to summarize complex, raw data for rapid recognition by the analyst. The second approach was to work from the other end of the story spectrum to support the analysts' application of tacit knowledge and organizational structures. The system should enable analysts to capture thoughts, and then allow them to bridge from thoughts to patterns and all the way to raw evidence. The assembly and organization of story elements is also important. A story provides a unique representation of events that are not necessarily linear. In timeline visualizations, events are ordered chronologically. In a story, however, events can be arranged in an order relevant to the topic. The author of a story can move the reader's attention forward and backward in time to provide context. We refer to this important concept of sequencing the presentation of information as chronotopic time. The three key workflow objectives for the prototype were to: @BULLET Integrate new and existing pattern matching tools to drive annotated expressive visualizations. This should assist the process of story discovery. @BULLET In a narrative text, provide links to supporting visualizations of events in time and space that invoke a complete analysis context and allow jumping off points for further analysis. This assists with story authoring and story telling. @BULLET Support authoring and comparison of multiple versions of story sub-components and elements. This helps make visible alternative sequences, explanations and hypotheses. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SYSTEM IMPLEMENTATION</head><p>The GeoTime Stories prototype includes three main components: Annotated pattern detection, narrative text authoring, and story threading. Each of these is designed to provide particular analytical capabilities and is discussed individually. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Pattern Detection and Expressive Annotation</head><p>A common problem for analysts is that they must wade through large volumes of low-level data and painstakingly extract behaviors and patterns in order to understand a situation. This process reduces both the amount of data that can be analyzed and the number of observations that can be discovered. To address this, the stories system provides functions for detection of simple patterns in movement activity, including discovery of possible meetings, speed of movement, percentage of time spent at unique locations, and identifying gaps in observations. The results of these functions are then fed into the annotation system in order to reduce the cognitive effort required to recognize these low-level incidents in the data. This allows the analyst to work at a higher level of abstraction, thereby stimulating faster recognition of larger behaviors or plots <ref type="bibr" coords="3,408.33,596.96,13.77,9.96" target="#b17">[19]</ref>. It was not our focus to develop new pattern discovery functions; rather, it was our intent to understand how they could be leveraged into the analytic workflow for maximum benefit. Although pattern detection is a separate area of research of great complexity, the pattern functions we implemented were useful in testing and refining interaction between pattern detection, visualization, and a story. The pattern system uses a plug-in architecture so that additional external pattern detection functions can be integrated. </p><p>GeoTime makes use of visual annotations to highlight the results of pattern searches within the visualization display. Annotations are graphic cues that can be added to a space-time scene in order to mark and describe important events in a given view. An individual pattern function applies specific annotations to the data points identified with an instance of a pattern. For example, in <ref type="figure" coords="4,105.10,116.24,32.53,9.96" target="#fig_3">Figure 4</ref>, the movement speed pattern function annotates a geo-temporal path with a visual indicator of velocity. It can also annotate this with icons that express speed by indicating a mode of transportation such as moving by foot, car, or aircraft as shown in <ref type="figure" coords="4,136.79,157.64,29.17,9.96" target="#fig_4">Figure 5</ref>. Annotations may also be manually applied to events by an analyst to highlight events and direct the attention of the story " reader " . The analyst selects events in the scene and then chooses from a palette of annotations, including curves, arrows, callouts, outlines and enlargement, shown in <ref type="figure" coords="4,184.08,565.70,29.17,9.96" target="#fig_5">Figure 6</ref>. </p><p>GeoTime annotations are unique in that they are implemented as data objects referenced to the actual event data, rather than as a separate graphical overlay. This approach is required due to the dynamic nature of the GeoTime 3D display. In order to remain attached to the events they reference, annotations need to be rerendered each time the scene updates in response to user interactions. Although this adds complexity to the software, a significant benefit to this approach is that annotations retain a semantic connection to their events and patterns. It also allows for richer graphical and data-specific expressions, such as enlargement or re-coloring of events, and even supports interactions such as mouseovers and menus on annotation graphics themselves. One possible downside is that annotation options are limited and not as simple as 2D sketch interfaces. Annotations are implemented such that their display is tied to a saved " snapshot " , which is an embedded link in the text of the story window. The story window is the authoring environment where the visualization of events in space and time, including annotations, are meaningfully connected to a story. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Story Window</head><p>The story window, as shown in <ref type="figure" coords="4,442.36,358.34,31.83,9.96" target="#fig_6">Figure 7</ref> is the focus of storyauthoring functionality in GeoTime. It enables the analyst to review pattern search results, author and present stories about events in time and space, capture moments of insight, and collaborate with other analysts. </p><p>A story document is comprised of a title and one or more text sections. Each text section can be any length or number of paragraphs and has an optional title bar. Story templates are outlines that can be selected when a new document is created. For example, a template may contain empty sections titled " Introduction " , " Body " , and " Conclusion " , or may include detailed instructions for how to do certain types of analysis. Story templates are meant to jumpstart analysis or provide instruction to new users about tools and techniques. The content of the templates is configurable. GeoTime currently contains very simple templates as examples. </p><p> The story window is designed to address a top-down storybased workflow by allowing the analyst to capture their insights, thoughts, explanations, and conclusions about events visualized in GeoTime. The tool provides the analyst with a familiar text editor interface for assembling a story but adds the capability to embed clickable links to captured GeoTime visualization states, called snapshots. A distinction should be drawn here between this implementation and common hypertext systems. In this case, the link affects the display of the GeoTime scene and does not change context or content in the text window where the click occurs. Also, the link invokes a view of events in space and time, which are the basic elements of a story that one is reading. A suitable analogy of what is possible is that of a person reading a novel who can instantly invoke corresponding scenes from a movie version of the novel on a nearby screen. Envisioning this in the context of GeoTime analysis, the analyst is therefore able to save a view of a time-space region containing events that support their stated analytical claims. Similarly, Geotime also allows them to annotate and describe ideas about specific events. For example, one could use the text of the story " Little Red Riding Hood " and include annotated snapshots of exactly where in the forest the Wolf and Red Riding Hood's space-time paths meet (assuming GPS tracking data were available). Digging deeper, one could then point out if they just happened to cross paths or if the wolf was waiting for someone to walk by (this distinction would be apparent in GeoTime). Snapshots are essentially references to a display state in GeoTime. They capture all the required parameters to reproduce a view, including geographic extents, time range, annotations, point-of-view, and visibility of each data element. Snapshots are created by clicking on the " take snapshot " button, which then saves a snapshot and embeds a link to it in the text at the cursor. Each snapshot is uniquely named and placed in the preview list below the text editor, which contains thumbnail images of all snapshots in the current document. Snapshots can be dragged from the preview list into the text body to create a new link or one can simply type the name of a snapshot in the text and it will be automatically detected and highlighted. Links use the same syntax as the references in this paper – numerals inside square brackets. Snapshots can be placed anywhere in the text any number of times. A preview image of a snapshot pops-up when mousing over a text link. </p><p>When a snapshot link is invoked, GeoTime reproduces the exact view state when it was created. This is not a static view; the user is able to adjust any parameters or continue analyzing as usual from this point on. This allows the reader to examine the exact data that the author has referenced, using the same tools that were used during authoring. For example, one could zoom out to see more context or animate the events over time. One can also add additional annotations and analytical depth and then feed this back into the story as a new snapshot or text section. Existing snapshots can be updated in the preview panel. It is worth noting that two different temporal systems are linked together through the snapshots. GeoTime presents events in chronological order and the nature of text provides the ability to arrange information sequence in any order – part of the art of story telling. For instance, an analyst may wish to insert a reference to events that occurred twenty years prior to the rest of the story. Using story text and snapshots, this sequence can be laid out for a reader to read and click through. If only the GeoTime view existed, the reader would have to scroll through the data linearly in time and be left to guess at the relevance of the earlier events. In some cases, a linear view of the events in a story may be desirable as an alternate and objective perspective to the text. This is accomplished by simply turning attention to the GeoTime visualization and scrolling through events using the time slider. One feature for future exploration is to show snapshot boundaries in time and space and then provide links back to relevant story text, thereby closing the loop between the two views. </p><p>The story window is also leveraged by the pattern matching system for displaying results to the user. Each time a pattern search is executed against the dataset, a new text section is generated containing a textual description of the nature of the pattern and a summarization of the results. Links to snapshots of the pattern instances in time and space that can be clicked for rapid review and/or confirmation by the analyst are also included. In <ref type="figure" coords="5,328.52,312.50,29.66,9.96" target="#fig_6">Figure 7</ref>, the text section titled " Pattern: Meeting Result " is an example of this. The text and links can be incorporated anywhere in the text using standard cut and paste actions. </p><p>Aside from the formal application of the story window in developing a story, the system can also be used to aid in unstructured free flowing thinking. The story window and snapshot system can be used to generate view mementos or bread crumbs of an analyst's progression through information. In this sense the story window serves as a note pad and provides a convenient location to assemble thoughts and threads of exploration. Some users have used one text section as a scratch pad while authoring a final report in another text section. Although elements of the story window are familiar, the underlying implementations and focus on storytelling for events in time and space make it uniquely suited to many analytical tasks. Similarity with standard interfaces helps to improve trainability and potential adoption by analysts. The ability of the story window to organize visualizations in a user-centered unstructured or structured narrative space is a concept that has potential to extend to other visualization systems. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Story Comparison and Collaboration</head><p>An important analysis technique is to evaluate alternative explanations that may account for some given evidence <ref type="bibr" coords="5,528.04,578.84,9.51,9.96" target="#b5">[6]</ref>. The ability to enumerate multiple possible explanations within a story is therefore desirable. Further, multiple analysts may be involved in contributing to the analysis or providing feedback about a story. The story window supports these activities by providing a simple system for categorizing and filtering sections of story text. </p><p>Every text section includes a color bar on the left side and the colors can be changed with a right-click option. <ref type="figure" coords="5,523.85,661.28,34.16,9.96" target="#fig_6">Figure 7</ref>illustrates how this appears in the interface. This mechanism allows the analyst to define categories within the text body. The meaning of the colors is not predefined and the analyst can define this based on task. For instance, in the context of " red team " analysis (i.e., the devil's advocate point-of-view), a useful application of color would be to mark core sections of a report blue and use red sections for red team input. If the use case was to indicate the correctness of another analyst's work, red may be used to indicate a problematic section. Feedback, role-playing, versioning, change tracking, brainstorming, war gaming, details, back story, alternatives, and comments can also be indicated. Immediately below the story window is a row of filter buttons that allow the user to toggle the display of text sections by color. By switching content on and off, the analyst is able to include or exclude certain threads, details, or opinions in a story, thereby changing its possible readings. One application would be to colorcode one version of the story blue, and a competing version of the story green. Common elements could be yet another color. The filters would allow the analyst to quickly flip from one version to another to compare explanations for the same set of observations. Story branches can also be set up by providing instructions within the text to turn certain section on and off at key points. For example, one could write in the text " click green sections ON if you agree or red sections ON if you disagree. " Flexibility and simplicity for the analyst were favored over task specialization in the design. We believe there are many ways to use text sections that we have not considered. Further investigation is necessary to determine utility and scalability. It is our intent that an analyst or organization will develop techniques and protocols that suit their needs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">TECHNICAL ARCHITECTURE</head><p>The stories system consists of four primary components: the Visualization, the Pattern Matching System, the Story window and the Capture Management System, shown in <ref type="figure" coords="6,241.38,395.90,30.92,9.96" target="#fig_7">Figure 8</ref>. The capture management system acts as a hub for view storage and routing invocations to visualizations. The stories system is written as a Java plug-in for GeoTime. Although the implementation described here is specific to GeoTime, the architecture is flexible enough to integrate with other visualizations provided they can store and recall snapshots. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Capture Management System</head><p>The capture management system stores and invokes snapshots of visualizations – in this case GeoTime space-time views. It uses the inversion of control design pattern. A visualization must provide the ability to capture its current view upon request. This snapshot is stored along with an image of the snapshot scene and is given a unique reference. Invoking the reference at a later date will direct the visualization to recall the exact view state. It is our assumption that any visualization that implements a capture system can be leveraged as supporting evidence within a story. For example, a story about a corporate scandal could include snapshots linked to organization charts or stock price visualizations. Recent work <ref type="bibr" coords="6,424.43,85.16,15.03,9.96" target="#b15">[16] </ref>and <ref type="bibr" coords="6,459.75,85.16,15.03,9.96">[17] </ref>demonstrates this use case with charting visualizations utilized in discussions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Story Window</head><p>The story window is essentially an HTML text editor that supports embedded references as hypertext links. The system monitors a list of available named snapshots in the document and highlights the names if they appear in the text. Clicking on one of these links invokes the capture manager to fetch and display the stored snapshot in the visualization. The story window contains additional functionality to display multiple html viewers (the text sections) by a color-defined category. This category is used by the filter interface to hide or show text sections. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Visualization and Annotation System</head><p>GeoTime was used as the visualization system in this research because of its applicability for representing stories about events in time and space. The application is capable of capturing the complete state of the visualization, including geospatial and temporal bounds, viewpoint, and visible data. These can be recalled by the capture management system. GeoTime's interface and rendering system was extended to include the annotation types described previously. These can be captured and recalled by the snapshot system Annotations can be activated by external functions, as in the case of patterns, or can be manually added by the analyst. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Pattern Matching System</head><p>The pattern matching system interacts with the GeoTime data system, the story window, the capture management system, and the annotation system in order to run searches and display results. The pattern matching system includes an API to allow third party developers to write patterns that scan over the GeoTime data. The function must set up annotations and add them to the data and then output a text description of the results, including snapshot descriptions, to the story window. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">INFORMAL EVALUATION</head><p>Over a period of six months, the Stories capabilities were reviewed with intelligence analysts for feedback and the pattern annotations system was tested against both reference data sets and actual operational data. Test data included GPS vehicle tracks, personal transaction billing data, including phone calls and credit card transactions, and proprietary operational data sets of varying size and nature. In order to support these different data types, the pattern system was enhanced with controls to adjust for data precision, frequency, and scale. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Procedure</head><p>In all cases, the test data sets were loaded into GeoTime and presented to analysts by the researchers. The pattern search and annotation functions were executed, generating results in the story window, then reviewed by clicking the links provided in the text to zoom and highlight instances of patterns in the GeoTime view. Examples of stories based on the sample data were presented. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Feedback</head><p>In all cases, feedback was enthusiastic. It was noted that the methods used by GeoTime Stories to display pattern search results are well-suited to support rapid review by an analyst. In some cases, analysts were working on their own pattern finding functions, but did not have a way to present results effectively. Other feedback referred to the story-telling capabilities and how they could be used in analysis tradecraft training and for reporting discovery to peers and decision makers. Feedback quotes include: " The annotated story is something that could be presented to high-level decision makers. It is obvious to see what is happening without having to know details of the data. " " The potential for using GeoTime Stories to capture and communicate tradecraft processes for both reporting and training is significant. " " Stories would be good for explaining tradecraft. Each type of data and situation is different, with its own properties and patterns. You need to be able to look at it – turn it around and understand and explain to someone new: 'These are the important things you will see in data– you might think this artifact looks like behavior X, but in fact it might be something else…' This can be explained with examples using Stories. " " We need to be able to capture and communicate the analytical process. Stories let us follow a sequence of steps towards a solution but also go back and follow-up on branches that were missed. " </p><p>Analysts had several informal recommendations for improving the prototype system, including: @BULLET Expand the number of different graphical options for manual annotation of the event data. @BULLET Hide annotated events so that only the annotation is displayed, in order to simplify the display. @BULLET Enhance the story system to support snapshots to other visualization systems was also an expressed desire @BULLET Provide a way to tag and add more categories of story text sections is necessary. @BULLET Export story documents as standard Microsoft-compatible formats. </p><p>Additional pattern functions and tuneable pattern parameters were deemed necessary. Specific proprietary pattern functions were of interest. Additional work would be required to integrate them with the Stories pattern API. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Findings</head><p>Our findings mostly pertain to the utility of the pattern system in finding and expressing patterns reflecting the bottom-up aspect of the GeoTime Stories capabilities. For almost every data set, it was necessary to adjust pattern-finding parameters to manage the relevancy of results. This was expected due to differences in geospatial scale, precision, frequency, and other characteristics of the data. For example, a meeting may be defined as two people located within 50m and 5 minutes of each other, or, at a global level, it might be two people in the same city on the same day. The utility of a pattern algorithm will depend on many factors, including the character of the data and the analytical task. It was beyond the scope of this research to automatically tune algorithms for any given data set; however we believe such a capability is necessary to provide a truly automated pattern annotation system. </p><p>In the sample data we tested, the meeting finder successfully identified potential meeting times and locations. Analysts liked being able to step through snapshots of each meeting result set in the text window. Feedback on the movement speed annotation function was that it provided a quick sense of the behaviour of a track. Annotating extreme-speed movements was considered especially useful because it could indicate errors in the data and other conditions of special analytical value. </p><p>There was expressed interest and encouragement to continue the work and pursue ongoing tests and development in operational environments. Analysts noted, " You are going in the right direction with Stories in all three areas – patterns, annotation, and narrative. We could use this now. " </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Future Evaluation and Development</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>Storytelling is an effective means of communication and collaboration and is used by analysts for reporting complex events to other analysts and decision-makers. In this paper, we have investigated how the concept of story relates to the process of analysis and how it can be supported in the GeoTime visualization software. A model of story concepts was developed and two approaches were identified to guide the design of the system: @BULLET A bottom-up approach, in which patterns in a visualization of low-level data are annotated so that analysts can quickly recognize higher-level behaviors using their tacit knowledge. @BULLET A top-down approach, in which the analyst can preserve moments of insight and explain them to others in the form of a story that can be told to, or read by others. </p><p>We have implemented mechanisms to support these approaches. First, to support a bottom-up approach, the pattern system automatically detects basic pattern types in event data and then graphically annotates them within GeoTime. To support a top-down approach, the story window allows for authoring and telling of analytic stories and provides the means to connect explanation to views of events in time and space. Thus, the analyst can link analytical thought and hypotheses to moments in information time and space. We have also added the ability to categorize parts of a story and toggle their display as a way to insert detail or collaborate on content. We believe this mechanism also enables the representation of multiple versions of stories and perspectives. It is our intent that these capabilities will help analysts communicate insights and explanations in an expressive analytical product and that the ability to perform analyses at a higher-level of abstraction – the level of a story – is made possible. Feedback from reviews with analysts was positive and encouraging and indicates that these capabilities could reduce the time analysts spend on low-level data analysis and report generation. </p><p>We believe that these techniques can be applied in other visualization systems and that visualizations of data are more effective if they are linked to explanations. Ideally, all visualization systems should include a scene-capture mechanism that can be integrated with external systems. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">FUTURE WORK</head><p>Our next steps will include additional testing with analysts and identification of selected story detection, storytelling, and sensemaking capabilities to be included within future versions of the deployed GeoTime analysis product. This should improve GeoTime by reducing visual clutter, increasing scalability, reducing effort and, most importantly, improve the interpretation and comprehension of significant patterns within the data. We also anticipate that GeoTime Stories is an effective way to capture and teach tradecraft to new analysts. The ability to incorporate explanation of tradecraft within an actual analytical tool is a significant benefit. This could be superior to classroom training, manuals, on-line training, and other common techniques. It seems that GeoTime Stories could provide a one-on-one-withexpert training experience in a repeatable and flexible form. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,332.52,374.56,211.16,8.91"><head>Figure 1. </head><figDesc>Figure 1. GeoTime for analysis of events in time and space. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,63.84,223.42,219.98,8.91;3,149.88,233.38,47.98,8.91"><head>Figure 2. </head><figDesc>Figure 2. The story concept spectrum as conceived for Stories development. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,332.52,208.84,211.16,8.91;3,363.00,218.86,150.23,8.91"><head>Figure 3. </head><figDesc>Figure 3. A concept sketch of an annotated GeoTime scene representing the events of a fictional story. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,66.24,312.58,217.38,8.91;4,60.30,322.54,227.11,8.91;4,124.08,332.56,99.54,8.91"><head>Figure 4. </head><figDesc>Figure 4. Annotated snapshot result of the velocity annotation function. Path of movement is annotated with indicator of speed; red is fast and white is slow. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="4,62.70,494.92,222.34,8.91;4,76.02,504.94,195.59,8.91"><head>Figure 5. </head><figDesc>Figure 5. Annotation of movement speed using icons (cars and walking people) to describe possible mode of transport. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="4,326.70,258.22,222.83,8.91"><head>Figure 6. </head><figDesc>Figure 6. The user annotation menu with five annotation styles. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="5,55.44,277.30,236.88,8.91;5,63.60,287.32,220.51,8.91"><head>Figure 7. </head><figDesc>Figure 7. The story window to the right of the GeoTime scene. Text sections titled " Pattern: … " are generated by pattern functions. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="6,72.30,542.14,203.20,8.91"><head>Figure 8. </head><figDesc>Figure 8. The technical architecture of the stories system. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="7,326.88,268.76,231.04,9.96;7,318.24,279.08,239.81,9.96;7,318.24,289.40,239.82,9.96;7,318.24,299.78,239.93,9.96;7,318.24,310.10,239.80,9.96;7,318.24,320.48,239.72,9.96;7,318.24,330.80,239.81,9.96;7,318.24,341.18,239.92,9.96;7,318.24,351.50,239.77,9.96;7,318.24,361.88,239.78,9.96;7,318.24,372.20,239.79,9.96;7,318.24,382.58,239.84,9.96;7,318.24,392.90,148.03,9.96"><head></head><figDesc>A formative evaluation of GeoTime Stories capabilities run by the National Institute of Standards and Technology (NIST) is planned for late summer 2007. This evaluation will collect analyst-centered data about the interaction of analysts with GeoTime Stories, for the purpose of integrating usability and utility findings and feedback from analysts into the development process. The evaluation is designed in two parts. The first will examine the ability of analysts to create GeoTime Stories reports about an ecologically valid task, consisting of events and entities interacting in time and space. The second part will examine how an analyst reads a completed GeoTime Stories report concerning an unfamiliar scenario and how they contribute additional information or commentary to the report. </figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS </head><p>This study was supported and monitored by the National Geospatial-Intelligence Agency (NGA) under Contract Number HM1582-05-C-0022. The views, opinions, and findings contained in this report are those of the author(s) and should not be construed as an official Department of Defense position, policy, or decision, unless so designated by other official documentation. The authors wish to thank DTO and all DTO and NGA staff for their support and encouragement. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="8,72.00,552.69,221.71,8.83;8,72.00,561.93,221.73,8.83;8,72.00,571.11,62.66,8.83"  xml:id="b0">
	<analytic>
		<title level="a" type="main">Narration as Human Communication Paradigm: The Case of Public Moral Argument</title>
		<author>
			<persName>
				<forename type="first">Walter</forename>
				<forename type="middle">R</forename>
				<surname>Fisher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communication Monographs</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,590.25,221.78,8.83;8,72.00,599.49,221.76,8.83;8,72.00,608.73,112.02,8.83"  xml:id="b1">
	<analytic>
		<title level="a" type="main">The Ergonomics of Hypertext Narrative: Usability Testing as a Tool for Evaluation and Redesign</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Gee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM J. Computer. Documentation</title>
		<imprint>
			<biblScope unit="page" from="25" to="28" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,627.87,221.74,8.83;8,72.00,637.11,221.77,8.83;8,72.00,646.29,221.78,8.83;8,72.00,655.53,14.06,8.83"  xml:id="b2">
	<analytic>
		<title level="a" type="main">MyLifeBits: Fulfilling the Memex Vision</title>
		<author>
			<persName>
				<forename type="first">Jim</forename>
				<surname>Gemmell</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Bell</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Gordon</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Lueder</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Roger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Drucker</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Steven</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Curtis</forename>
				<surname>Wong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia &apos;02</title>
		<meeting><address><addrLine>Juan-les-Pins, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="235" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.00,674.67,221.66,8.83;8,72.00,683.91,219.52,8.83"  xml:id="b3">
	<analytic>
		<title level="a" type="main">What Storytelling can do for Information Visualization</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Gershon</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Page</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="31" to="37" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.24,54.09,221.80,8.83;8,336.24,63.33,221.68,8.83;8,336.24,72.57,61.73,8.83"  xml:id="b4">
	<analytic>
		<title level="a" type="main">Spatial Cognition in Natural-Language Narratives</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Herman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Fall Symposium on Narrative Intelligence</title>
		<meeting>the AAAI Fall Symposium on Narrative Intelligence</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.24,91.71,221.72,8.83;8,336.24,100.95,89.04,8.83"  xml:id="b5">
	<monogr>
		<title level="m" type="main">Psychology of Intelligence Analysis, Center for the Study of Intelligence</title>
		<author>
			<persName>
				<forename type="first">Richard</forename>
				<surname>Heuer</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.24,120.09,221.67,8.83;8,336.24,129.33,221.77,8.83;8,336.24,138.57,67.11,8.83"  xml:id="b6">
	<analytic>
		<title level="a" type="main">Analytic Culture in the U.S. Intelligence Community, Center for the Study of Intelligence</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Johnston</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Government Printing Office</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.24,157.71,221.87,8.83;8,336.24,166.95,221.70,8.83;8,336.24,176.13,121.78,8.83"  xml:id="b7">
	<analytic>
		<title level="a" type="main">The Story Picturing Engine-a system for automatic text illustration</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Joshi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">Z</forename>
				<surname>Wang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Multimedia Comput. Commun. Appl</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="68" to="89" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.24,195.33,221.79,8.83;8,336.24,204.57,66.20,8.83"  xml:id="b8">
	<analytic>
		<title level="a" type="main">GeoTime Information Visualization</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Kapler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Wright</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE InfoViz</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.24,223.71,221.79,8.83;8,336.24,232.95,221.81,8.83;8,336.24,242.13,77.78,8.83"  xml:id="b9">
	<analytic>
		<title level="a" type="main">GeoTime Information Visualization</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Kapler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Wright</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization Journal</title>
		<imprint>
			<publisher>Palgrave Macmillan</publisher>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="136" to="146" />
			<date type="published" when="2005" />
			<publisher>Palgrave Macmillan</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.24,261.27,221.66,8.83;8,336.24,270.51,22.04,8.83"  xml:id="b10">
	<monogr>
		<title level="m" type="main">Computers as Theatre</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Laurel</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Addison-Wesley</publisher>
			<pubPlace>New York, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.24,289.71,221.77,8.83;8,339.08,298.95,218.95,8.83;8,336.24,308.13,111.86,8.83"  xml:id="b11">
	<analytic>
		<title level="a" type="main">LifeLines: Visualizing personal histories</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Plaisant</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Milash</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Rose</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Widoff</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Shneiderman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CHI`96CHI`96</title>
		<meeting>CHI`96CHI`96<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="221" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.24,327.27,221.77,8.83;8,336.24,336.51,221.74,8.83;8,336.24,345.75,221.78,8.83;8,336.24,354.93,58.70,8.83"  xml:id="b12">
	<analytic>
		<title level="a" type="main">Designing multimedia for learning: narrative guidance and narrative construction</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Plowman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Luckin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI &apos;99: Proceedings of the SIGCHI conference on Human factors in computing systems</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="310" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.24,374.07,221.71,8.83;8,336.24,383.31,221.79,8.83;8,336.24,392.55,92.90,8.83"  xml:id="b13">
	<analytic>
		<title level="a" type="main">A System to Compose Movies for Cross-Cultural Storytelling: Textable Movie</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Vaucelle</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of TIDSE</title>
		<meeting>TIDSE</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="126" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.25,411.69,221.83,8.83;8,336.25,420.93,221.70,8.83;8,336.25,430.11,221.77,8.83;8,336.25,439.35,107.81,8.83"  xml:id="b14">
	<analytic>
		<title level="a" type="main">Reading and Writing Fluid Hypertext Narratives</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">T</forename>
				<surname>Zellweger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Mangen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Newman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth ACM conference on hypertext and hypermedia. Conference on Hypertext and Hypermedia</title>
		<meeting>the thirteenth ACM conference on hypertext and hypermedia. Conference on Hypertext and Hypermedia</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="45" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.25,458.49,221.74,8.83;8,336.25,467.73,221.83,8.83;8,336.25,476.91,72.88,8.83;8,318.25,496.11,205.35,8.83"  xml:id="b15">
	<analytic>
		<title level="a" type="main">Voyagers and Voyeurs: Supporting Asychronous Collaborative Information Visualization</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Heer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<forename type="middle">B</forename>
				<surname>Viegas</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Wattenberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI 2007 Proceedings [17] Web site www.Many-eyes.com, downloaded July18</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.24,515.31,221.70,8.83;8,336.24,524.55,221.72,8.83;8,336.24,533.73,97.75,8.83"  xml:id="b16">
	<analytic>
		<title level="a" type="main">Correlating Events with Tracked Movements in Time and Space</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Harper</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Kapler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Wright</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Intelligence Analysis</title>
		<meeting>. International Conference on Intelligence Analysis</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.24,552.87,221.64,8.83;8,336.24,562.11,221.81,8.83;8,336.24,571.29,16.05,8.83"  xml:id="b17">
	<analytic>
		<title level="a" type="main">Enhancing Visual Analysis of Network Ttraffic Using a Knowledge Representation</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Xiao</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Gerth</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Hanrahan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE VAST</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,324.12,618.92,157.56,10.04;8,318.24,627.45,3.34,6.70;8,324.06,629.24,167.24,10.04;8,318.24,637.83,3.34,6.70;8,324.12,639.62,165.18,10.04;8,318.24,648.15,3.34,6.70;8,324.12,649.94,165.58,10.04"  xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">Ryan</forename>
				<surname>Eccles</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">–</forename>
				<surname>Reccles@oculusinfo</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
