<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T13:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">D-Dupe: An Interactive Tool for Entity Resolution in Social Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Mustafa</forename>
								<surname>Bilgic</surname>
							</persName>
							<affiliation>
								<orgName type="institution" key="instit1">University of Maryland College Park</orgName>
								<orgName type="institution" key="instit2">University of Maryland College Park</orgName>
								<orgName type="institution" key="instit3">University of Maryland College Park</orgName>
								<orgName type="institution" key="instit4">University of Maryland College Park</orgName>
								<address>
									<region>MD, MD, MD, MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Louis</forename>
								<surname>Licamele</surname>
							</persName>
							<affiliation>
								<orgName type="institution" key="instit1">University of Maryland College Park</orgName>
								<orgName type="institution" key="instit2">University of Maryland College Park</orgName>
								<orgName type="institution" key="instit3">University of Maryland College Park</orgName>
								<orgName type="institution" key="instit4">University of Maryland College Park</orgName>
								<address>
									<region>MD, MD, MD, MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Lise</forename>
								<surname>Getoor</surname>
							</persName>
							<affiliation>
								<orgName type="institution" key="instit1">University of Maryland College Park</orgName>
								<orgName type="institution" key="instit2">University of Maryland College Park</orgName>
								<orgName type="institution" key="instit3">University of Maryland College Park</orgName>
								<orgName type="institution" key="instit4">University of Maryland College Park</orgName>
								<address>
									<region>MD, MD, MD, MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ben</forename>
								<surname>Shneiderman</surname>
							</persName>
							<affiliation>
								<orgName type="institution" key="instit1">University of Maryland College Park</orgName>
								<orgName type="institution" key="instit2">University of Maryland College Park</orgName>
								<orgName type="institution" key="instit3">University of Maryland College Park</orgName>
								<orgName type="institution" key="instit4">University of Maryland College Park</orgName>
								<address>
									<region>MD, MD, MD, MD</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">D-Dupe: An Interactive Tool for Entity Resolution in Social Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Data cleaning and integration, user interfaces, visual</term>
					<term>analytics, visual data mining</term>
					<term>Index Terms:</term>
					<term>H28 [Information Systems]: Database</term>
					<term>Applications—Data mining; H52 [Information Interfaces and Pre-</term>
					<term>sentation]: User Interfaces—User-centered design</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Visualizing and analyzing social networks is a challenging problem that has been receiving growing attention. An important first step, before analysis can begin, is ensuring that the data is accurate. A common data quality problem is that the data may inadvertently contain several distinct references to the same underlying entity; the process of reconciling these references is called entity-resolution. D-Dupe is an interactive tool that combines data mining algorithms for entity resolution with a task-specific network visu-alization. Users cope with complexity of cleaning large networks by focusing on a small subnetwork containing a potential duplicate pair. The subnetwork highlights relationships in the social network , making the common relationships easy to visually identify. D-Dupe users resolve ambiguities either by merging nodes or by marking them distinct. The entity resolution process is iterative: as pairs of nodes are resolved, additional duplicates may be revealed; therefore, resolution decisions are often chained together. We give examples of how users can flexibly apply sequences of actions to produce a high quality entity resolution result. We illustrate and evaluate the benefits of D-Dupe on three bibliographic collections. Two of the datasets had already been cleaned, and therefore should not have contained duplicates; despite this fact, many duplicates were rapidly identified using D-Dupe&apos;s unique combination of entity resolution algorithms within a task-specific visual interface.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p> There is a growing interest in tools which support the analysis of social networks. In order for these tools to work effectively and convey accurate visual and analytic information, the underlying data must be clean. Unfortunately this is rarely the case. Often networks are extracted from databases which may contain errors and inconsistencies. One common problem is that a dataset may contain multiple references to the same underlying entity or actor. In a graph visualization of such a network, a single actor would be represented by multiple nodes. This visual display is clearly misleading; it not only has the incorrect number of nodes but in turn the edges and paths are inaccurate. Furthermore, calculating any of the standard social network measures, such as degree-centrality, betweenness and so on, would give inaccurate results. Entity resolution is the process of reconciling, from the underlying data references, the " actual " real-world entities <ref type="bibr" coords="1,238.71,626.60,9.51,8.12" target="#b1">[2]</ref>. Traditional entity resolution approaches use similarity metrics which compare the attributes of the references. Entity resolution in social networks is more interesting because, in addition to making use of attribute similarities to identify potential duplicates, the social context, or " who's connected to who, " can provide useful information to the resolution process. Recently a number of approaches have been developed which make use of relational information to help in the resolution process <ref type="bibr" coords="1,385.11,218.65,9.69,8.12" target="#b2">[3,</ref><ref type="bibr" coords="1,397.04,218.65,11.19,8.12" target="#b27"> 27,</ref><ref type="bibr" coords="1,410.47,218.65,6.46,8.12" target="#b3"> 4]</ref>. Most existing entity resolution methods focus on automated entity resolution. Automated techniques are not perfect, and they face a " precision-recall " trade-off. If they are tuned to have high precision , they rarely merge duplicates, leaving many duplicates in the database. If they are tuned to have a high recall, they mistakenly merge nodes that are in fact distinct. On the other hand, handcleaning methods, even with visualization support, can be slow and inefficient in finding duplicates. These approaches tend to be high precision, because there is a human-in-the-loop making the final resolution decision. However, inspecting a large dataset and hunting for duplicates can be like looking for the proverbial needle in a haystack. Thus, while these approaches may have high precision, they tend to have low recall. Here, we provide an interactive analyst-centric approach to the problem which tightly integrates the data mining techniques with a visualization suited to the task. D-Dupe <ref type="bibr" coords="1,477.21,379.69,10.45,8.12" target="#b6">[6] </ref>provides access to sophisticated entity resolution algorithms and enables users to flexibly apply sequences of actions to uncover duplicates. In addition, D-Dupe provides users with a simple network visualization which displays the collaboration context for potential duplicates. The collaboration context shows, for any two potential duplicates, their relational neighborhood. The network visualization allows users to quickly identify shared and non-shared relational context and base their exploration and resolution decisions on the context. Emerging principles from information visualization, such as laying out the nodes on a meaningful substrate, are combined with representations for uncertainty, resulting in a tool that is especially well suited to the entity resolution task. Powerful filtering and search techniques are also integrated into the tool. Two of D-Dupe's novelties are: 1. Stable Visual Layout Optimized for Entity Resolution: Instead of visualizing the whole collaboration network, D-Dupe shows only the subnetwork relevant for the entity resolution task. Such a dramatic simplification reduces the users' cognitive load as the networks presented are much simpler, easier to understand, and yet they still contain the information relevant to the task at hand. Furthermore, the simplification allows our visualization to scale to large networks. We also develop a visual layout tuned to the entity resolution task; the nodes are laid out on a stable and meaningful substrate where the potential duplicates and other related entities always appear at the same location, leading to considerable reduction in scanning the network. 2. User Control for Combining Entity Resolution Algorithms: Numerous similarity measures can be used to determine potential duplicates; some are good at finding misspellings , others may find abbreviations and so on. Moreover, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="43"></head><formula>(a) (b) (c) (d) (e) (f) </formula><p>Figure 1: A series of resolutions on a portion of the InfoVis data set. (a) shows the initial network before any resolutions have been performed. It is apparent that there are a number of duplicates. (b) through (f) show the same network, each drawn after each resolution in the process The resolutions are: (a) to (b) " Hua Su " and " Hus Su " , (b) to (c) " Lisa Tweedie " and " L. Tweedie " , (c) to (d) " Huw Dawkes " and " H. Dawkes " , (d) to (e) " Bob Spence " and " B. Spence " , and (e) to (f) " Robert Spence " and " Bob Spence " . Note the simplicity of the final network in contrast to the original network. decisions made using one measure might uncover new potential duplicates under another measure. D-Dupe allows users to flexibly apply and interleave different measures. It is hard to get the same benefit from automated combination of the measures . In our case studies, we found this feature, integrated with the visualization of the common social context, to be extremely effective. Throughout, in both our running examples and our evaluation datasets, we illustrate and evaluate D-Dupe on bibliographic collaboration networks. However D-Dupe's layout and interaction principles are general and can be used in other social networks in which the relational context provides useful information for entity resolution decisions. We show the utility of D-Dupe on three bibliographic datasets; in each we were able to quickly and effectively resolve duplicates. This is particularly impressive, since two of the three datasets had already been extensively cleaned. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A MOTIVATING EXAMPLE</head><p>Before going into the specific details of the tool, <ref type="figure" coords="2,231.45,564.40,30.35,8.12">Figure 1</ref>gives an overview of the deduplication process on a small portion of bibliographic dataset used for the InfoVis 2004 Contest <ref type="bibr" coords="2,255.31,584.32,13.72,8.12" target="#b15">[15]</ref>. The dataset describes the papers and authors culled from eight years (<ref type="bibr" coords="2,58.07,604.24,16.27,8.12">[1995]</ref><ref type="bibr" coords="2,74.34,604.24,4.07,8.12">[1996]</ref><ref type="bibr" coords="2,74.34,604.24,4.07,8.12">[1997]</ref><ref type="bibr" coords="2,74.34,604.24,4.07,8.12">[1998]</ref><ref type="bibr" coords="2,74.34,604.24,4.07,8.12">[1999]</ref><ref type="bibr" coords="2,74.34,604.24,4.07,8.12">[2000]</ref><ref type="bibr" coords="2,74.34,604.24,4.07,8.12">[2001]</ref><ref type="bibr" coords="2,78.41,604.24,20.34,8.12">[2002]</ref>of the InfoVis conference. <ref type="figure" coords="2,204.99,604.24,30.35,8.12">Figure 1</ref> (a) shows a coauthor network for a portion of the dataset. In this network, a node represents an author, and two authors are linked if they have published a paper (in the dataset) together. It is immediately apparent that the network in <ref type="figure" coords="2,128.29,644.09,30.41,8.12">Figure 1</ref>(a) contains a number of duplicates. <ref type="figure" coords="2,54.00,654.05,28.88,8.12">Figure 1</ref> (<ref type="bibr" coords="2,96.32,654.05,10.07,8.12">(f) </ref>shows the transformation the network undergoes, as duplicate authors are found and merged. <ref type="figure" coords="2,198.91,664.02,29.00,8.12">Figure 1</ref>(g) shows the final network, after all of the duplicates have been resolved. As we can see, we have quickly gone from a rather complex network, in the start, to a relatively simple network at the end. More importantly, comparing <ref type="figure" coords="2,94.44,703.87,29.13,8.12">Figure 1</ref>(a) with <ref type="figure" coords="2,154.59,703.87,28.89,8.12">Figure 1</ref>(f) reveals that visualization of datasets with duplicates will lead to incorrect conclusions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DESIGN COMPONENTS</head><p>Our goal with D-Dupe is to help automate the process of bringing potential duplicates to the users' attention, supporting the users in making a resolution decision (deciding whether or not two nodes are in fact duplicates) and allowing the users to flexibly chain together multiple resolutions. The basic interaction paradigm for D-Dupe is as follows. Users begin by loading a dataset. They can then choose from a number of possible entity resolution algorithms. The entity resolution algorithms use a variety of different similarity metrics to rank pairs of nodes according to how likely they are to be duplicates. The users can scroll through the list of potential duplicate pairs and select a potential duplicate pair for analysis. They can then view the collaboration context network for the pair and apply filtering and highlighting features of D-Dupe to this network. Users can resolve the potential duplicate by deciding that the two nodes are: 1) duplicates , in which case the nodes are merged, or 2) distinct entities , in which case the nodes are marked as distinct. User actions are recorded, and at any point in the process the 'resolved' network can be saved. A video D-Dupe demonstration is available at http://www.cs.umd.edu/linqs/ddupe/. D-Dupe is written in Java and will run on any system with a Java Virtual Machine. D-Dupe makes use of JUNG's <ref type="bibr" coords="2,515.66,627.13,14.92,8.12" target="#b23">[23] </ref>visualization support for social networks and uses several string distance measures from SecondString <ref type="bibr" coords="2,424.92,647.06,13.72,8.12" target="#b10">[10]</ref>, in addition to a Levenstein edit distance algorithm that we implemented. <ref type="figure" coords="2,327.92,673.98,30.27,8.12" target="#fig_0">Figure 2</ref>shows the D-Dupe interface. The tool consists of three coordinated windows <ref type="bibr" coords="2,396.40,683.94,13.93,8.12" target="#b22">[22]</ref>: the collaboration context network panel on the left, the entity resolution control panel on the right, and the potential duplicates details panel at the bottom. We describe the capabilities supported in each window in the following subsections. Details on the current candidate duplicate pair are presented in potential duplicates detail panel in the lower window. The entity resolution control panel appears on the right; the user can select an entity similarity measure to use, view a list of candidate duplicate pairs, choose filters for the nodes, edges and collaborators, perform resolutions for a particular pair, and search for a particular author. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Collaboration Context Network</head><p>One of the first challenges in the design of D-Dupe was deciding how to present the users with the collaboration context for potential duplicates. Presenting the full collaboration network is only feasible for extremely small networks. As <ref type="figure" coords="3,205.48,574.36,30.10,8.12" target="#fig_1">Figure 3</ref>(a) shows, even for moderately sizes datasets, viewing the entire network is ineffective because the network is unreadable. Instead, as mentioned earlier, D-Dupe uses a task-specific network visualization. This visualization is based on the paradigm of interactive visualization where the users inspect each potential duplicate individually. In this paradigm, users first choose a potential duplicate pair to analyze and they are then presented with the relevant subnetwork for that pair. Only the potential duplicates, their neighbors, and relationships among them are shown. <ref type="figure" coords="3,165.38,664.02,29.73,8.12" target="#fig_1">Figure 3</ref>(b) shows the result for the pair of potential duplicates " George G. Robertson " and " George C. Robertson " (The chosen pair is shown as square nodes in the graph). The collaboration context network shown in <ref type="figure" coords="3,214.20,693.91,29.35,8.12" target="#fig_1">Figure 3</ref>(b) uses an an off-the-shelf spring embedder method, Fruchterman-Reingold lay- out <ref type="bibr" coords="3,68.77,713.83,14.92,8.12" target="#b17">[17] </ref>algorithm, for laying out the nodes. This simplifies the network sufficiently so that the network is readable, while still containing relevant context information for the entity resolution task. While this layout is a significant improvement over viewing the entire network, its disadvantage is that it is not stable. Each time a potential duplicate pair is analyzed, the nodes will be placed at different locations on the screen, as determined by the spring embedder algorithm. This randomness causes the cognitive overhead of scanning the network to find the potential duplicates which is burdensome in this repetitive task. This disadvantage led us to to develop meaningful substrates for node placement. These produce a stable layout which reduces unnecessary cognitive overhead for the entity resolution task. The substrates divide the screen into five regions: the first potential duplicate is always at the center of the second region and the second potential duplicate is always at the center of the fourth region . The third region highlights their shared neighbors. Their non-shared neighbors are displayed in the first and fifth regions re- spectively. <ref type="figure" coords="3,361.57,703.87,29.48,8.12" target="#fig_1">Figure 3</ref>(c) shows an example of the substrates for the " George Robertson " references. In the center, we see their shared co-authors, in this case " Stuart K. Card " and " Jock D. Mackinley " . On the far left, we see the non-shared co-authors of " George G. Robertson " and on the far right, we see the non-shared co-authors of " George C. Robertson " . By default, we show only the links between the potential duplicates and their co-authors, we do not show the co-author links among the co-authors. This results in a simpler graph and eliminates links among nodes in the same substrate and between nodes in non-consecutive substrates. However, the co-author links between potential duplicates' neighbors can be shown, by checking the show non-consecutive edges check-box in the control panel (discussed in more detail in the next section). This pleasingly simple design has proved to be surprisingly effective . In a preliminary study with five participants to validate the usefulness of this layout, we studied the response time and accuracy for users on 10 collaboration context networks. Users were presented half of the networks using the Fruchterman-Reingold layout and half using the stable layout, with the order appropriately randomized within subjects, and they were asked to determine the number of shared neighbors the potential duplicates shared. For this simple task, there was no difference in accuracy between the two layouts; however there was a 15% reduction in response time when the stable layout was used. The benefit of the layout becomes more apparent as users gain experience with the tool. Additional information about the nodes is conveyed through shape, shading, and size. The current potential duplicate nodes are squares, and the other nodes are circles. The current potential duplicate pair and other potential duplicates in the neighborhood are shaded according to their similarity based on the current entity resolution metric. Darker nodes indicate a greater degree of similarity . The similarity shading for the nodes in the neighborhood can be controlled using a slider. The node and label size is a function of the " importance " of the node, where " importance " is dictated by the domain semantics. In the bibliographic domain, we define importance as the number of publications attributed to the author. This provides an additional channel to visually show semantic differences between the nodes. The links also convey information; edge thickness indicates the strength of a relationship. In the bibliographic domain, the relationship strength between two nodes can be defined as the number of times authors have co-authored together. Often, there may be additional potential duplicates among the co-authors of the currently analyzed potential duplicate. Being able to spot these additional potential duplicates is important for making the correct decision about the current potential duplicate. We provide a slider which controls the similarity between the co-authors of the potential duplicate pair. Depending on the currently chosen similarity measure and the threshold, nodes which have a potential duplicate in the neighborhood will be shaded. Nodes in each region are sorted according to their similarity to the nodes in other regions; similar nodes are highlighted and appear together at the top, ranked according to their similarity. We chose a node-link representation because of its familiarity to social network researchers. Textual lists could be used for a compact representation but additional coding would be needed to show similarity, number of publications, number of co-authorships, etc. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Entity Resolution Control Panel</head><p>The Entity Resolution Control Panel (right side of <ref type="figure" coords="4,505.91,451.45,30.17,8.12" target="#fig_0">Figure 2</ref> ) provides the main functionalities for D-Dupe users. The actions they may perform include: </p><p>@BULLET Choose an entity similarity measure @BULLET Select the current potential duplicate pair @BULLET Filter the collaboration context network @BULLET Resolve a potential duplicate pair by merging the nodes or marking them distinct @BULLET Search the database for a particular author @BULLET Save the resolved collaboration network Potential Duplicates List: D-Dupe users can select from a variety of entity similarity measures in the drop down menu at the top of the control panel. By selecting a measure and clicking the Run button, users populate the potential duplicates list. This list is sorted with the most similar pairs of nodes at the top. Filters: D-Dupe allows dynamic filtering of the collaboration context network. As mentioned earlier, users can filter the edges shown by choosing to show only co-author links among consecutive regions, co-author links among the authors in the non-consecutive regions, or both. D-Dupe supports filtering authors based on importance . Users can control the importance of the displayed authors using a slider to set the importance threshold. D-Dupe also supports filtering based on edge weights, set using the co-authorship strength slider. As mentioned earlier, we also provide a slider which controls the co-authorship similarity. Potential Duplicate Action: D-Dupe provides an easy way to resolve duplicates. When users are satisfied that the potential duplicate pair that they are inspecting is truly a duplicate they can merge the pair. When merging, users select the author they want to keep by select Merge on (1) or Merge on (2).After the merge, the co-authors links are updated to refer to the newly resolved node. On the other hand, if users decide that the potential duplicates correspond to different entities, then they can select Mark Distinct. After performing a merge or distinct action, this author pair will no longer be presented to users. Each resolution step is recorded, so that users can examine a history of the resolution decisions. We currently do not support undoing resolutions, because the resolutions are chained together and they result from complex interdependencies . However this is an interesting topic for future research. Querying: In some cases, users are interested in resolving references for a particular author. D-Dupe users can search the database for specific authors, generating a list of the closest matches according to the currently selected similarity measure. If users select one of these authors, the potential duplicates table will be populated with potential duplicates for that author. Users can also query on a particular author by double-clicking on it in the collaboration context network. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Potential Duplicates Details Panel</head><p>D-Dupe provides two tables, shown at bottom of <ref type="figure" coords="5,229.80,319.33,28.90,8.12" target="#fig_0">Figure 2</ref> , with details for the current potential duplicate pair. For the bibliographic domain, the window is used to show the publications of each author . By definition, more important authors will have more publications . This extra information allows users to see if the duplicate pairs share additional attributes. In addition, users can double click on a publication, and D-Dupe will search Google Scholar for the paper. For other domains, D-Dupe can go to another online source such as the white pages or company personnel file for additional information. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ENTITY SIMILARITY MEASURES</head><p> D-Dupe users can select from a variety of entity similarity metrics to identify and rank potential duplicates. D-Dupe uses several standard string similarity functions including Levenstein, Jaccard, JaccardChar, Jaro, JaroWinkler and MongeElkan. Users can easily switch between measures to explore the benefits of each measure. Different entity similarity measures are appropriate for finding different kinds of errors. For example, in the bibliographic domain common errors that lead to duplicates in databases are: 1) parsingerrors , such as switching a first name and last name, 2) abbreviations , such as using first initial instead of full first name, and, of course, 3) misspellings. To deal with the first two, the distance measures need to compare terms in the string rather than characters; Jaccard similarity works well for this purpose. To address the misspellings , measures that do comparison at the character level, such as Levenstein, JaccardChar, Jaro, JaroWinkler, and MongeElkan work well. Since users control resolution decisions, they can chain together resolution decisions based on different similarity metrics. This finegrained flexibility, while seemingly simple, is not easily achievable in an automatic system. Simply applying the algorithms in some fixed order does not support the complex dependencies that may be discovered in carefully chosen sequences. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CASE STUDIES WITH THREE BIBLIOGRAPHIC DATASETS</head><p>We evaluated D-Dupe on three bibliographic datasets. The first two datasets were considered " clean " in that the providers claimed that duplicates had already been removed. Common practices for cleaning data include automated approaches that use a particular entity resolution algorithm and ones that rely on hand cleaning without much automated guidance. @BULLET InfoVis Contest: 614 publications from 1974 to 2004 and 1,036 authors, with 1,832 co-authorship links between authors <ref type="bibr" coords="5,337.87,110.01,13.72,8.12" target="#b15">[15]</ref>. This dataset was provided as a cleaned dataset for the InfoVis contest in 2004. The contest organizers made a substantial effort to resolve duplicates by asking people within the InfoVis community to point out and resolve duplicates for themselves as well as their co-authors and friends. This intensive process, distributed over many individuals took several months; however, the cleaned dataset still had duplicates. @BULLET CiteSeer subset: 1504 publications by 1167 authors, cleaned by its developers <ref type="bibr" coords="5,403.96,193.90,14.92,8.12" target="#b18">[18] </ref>and further cleaned by Aron Culotta and Andrew McCallum for use in evaluating entity resolution algorithms within the machine learning community. The method used to initially clean this collection used simple, high-recall methods to " over-merge " entities. Next a domain expert split up the clusters if required—an intensive manual process. Specifically, to resolve the author names, the researchers began by normalizing the author strings by initialing the first name and merging all the author references with the same normalized string. To account for misspellings, approximate string matching algorithms were used. In the manual post-processing step, a web search was performed for resources that could help make an informed decision about when clusters should be split. The researchers spent roughly 8-12 hours resolving this dataset. @BULLET PubMed subset: Subset of 56 papers by 161 authors retrieved from a query of PubMed, a carefully built database from the U. S. National Library of Medicine. Unlike the other two datasets, PubMed does not provide identifiers for authors, so our results illustrate how D-Dupe can help label an unprocessed dataset. </p><p>We next describe example deduplication task sequences in each of these datasets to highlight D-Dupe's functionalities. <ref type="figure" coords="5,317.95,464.16,30.72,8.12">Figure 4</ref> shows the sequence of resolutions corresponding the example from Section 2. <ref type="figure" coords="5,406.40,474.13,30.24,8.12">Figure 4</ref>(a) shows the potential duplicate pair " Hua Su " and " Hus Su " in the InfoVis dataset. The center of the collaboration context network shows their two shared co-authors, which is a good indication that they are in fact duplicates . Without domain knowledge, however, users may not be sure whether these two references are the same entity, so they can examine the paper reference using Google Scholar. After seeing the original papers, it seems clear that " Hus Su " is in fact a misspelling of " Hua Su. " After merging them, the neighbors of the secondary author are transferred to the primary author. In the next step, <ref type="figure" coords="5,542.79,563.79,14.94,8.12;5,317.95,573.76,16.89,8.12">Fig- ure 4</ref>(b), " Hua Su " is shown in green to highlight that it is the result of a recent resolution and thus we are more confident in its identity. Because merging " Hua Su " and " Hus Su " leads to changes in the network structure, it will be wise to inspect Hua Su's co-authors for potential duplicates. Additional resolutions are shown in <ref type="figure" coords="5,542.79,613.61,14.94,8.12;5,317.95,623.57,11.43,8.12">Fig- ure</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">InfoVis</head><formula>4(b), (c), (d)</formula><p>, and (e). We stop at <ref type="figure" coords="5,448.76,623.57,28.56,8.12">Figure 4</ref>(f), where there are no more duplicates. If the collaboration context network consists of two disjoint subnetworks , i.e. the potential duplicates do not have any shared coauthors , it is a strong indication that these potential duplicates represent distinct authors. <ref type="figure" coords="5,407.82,673.98,31.35,8.12" target="#fig_2">Figure 5</ref>shows an example where users may be unsure of the identities of " Jian Huang " and " Qian Huang " . Based solely on the author names, users might mistakenly merge these authors. But by observing the lack of shared context visually, users will pause to investigate their conclusion more carefully. This </p><formula>(a) (b) (c) (d) (e) (f) </formula><p>Figure 4: The sequence of collaboration context networks corresponding to the entity resolution steps from the motivating example in Section 2. The resolution process is iterative; an earlier decision effects the next decision. Resolved nodes in the earlier steps are drawn in green, indicating a higher confidence in their identities. The iterative process ends at (f), where we do not have any more duplicates to consider in the network. example demonstrates how the network also highlights distinctions between the potential duplicates. <ref type="figure" coords="6,63.96,604.24,30.10,8.12">Figure 6</ref>(a) shows another another pair of potential duplicates, " George G. Robertson " and " George C. Robertson " , from the InfoVis dataset. Because there are few publications for " George C. Robertson, " it is drawn as a small node. This may be an indication that it is a misspelling. <ref type="figure" coords="6,137.67,644.09,29.36,8.12">Figure 6</ref>(b) shows the collaboration context network after the user decreased the threshold for co-authorship similarity. Another potential duplicate pair in the neighborhood, " Jack D. Mackinlay " and " Jock D. Mackinlay " , is now apparent. <ref type="figure" coords="6,54.00,683.94,30.25,8.12">Figure 6</ref>(c) shows the result after further filtering using the edge based filtering and node based filtering; this illustrates how users might quickly isolate the " George C. Robertson " node from the rest of the network, revealing additional evidence that it might be a mis- spelling. <ref type="figure" coords="6,327.92,386.49,31.17,8.12" target="#fig_3">Figure 7</ref>shows another example from the InfoVis dataset, for the potential duplicates " Steven K. Feiner " and " S. K. Feiner " . Initially , the potential duplicates do not seem to have any common co-authors. But, after lowering the threshold for co-authorship similarity , " M. X. Zhou " and " Michelle X. Zhou " are highlighted as potential duplicates. This additional evidence may increase users' confidence that " Steven K. Feiner " and " S. K. Feiner " may be duplicates . This example shows another novel way in which D-Dupe can help users, by drawing attention to potentially important nodes in the neighborhood of the authors currently being inspected.  In our experience, D-Dupe enabled us to rapidly find duplicates in the InfoVis dataset. Although this database was carefully prepared from electronic sources, and used by dozens of research groups in a highly visible contest, we were able to detect more than 60 duplicates within our first half hour of use. </p><formula>(a) (b) (c) </formula><p> Figure 6: (a) The initial collaboration network for potential duplicates " George G. Robertson " and " George C. Robertson. " (b) The use of the Co- Authorship Similarity Slider highlights another potential duplicate among the neighbors: " Jack D. Mackinlay " and " Jock D. Mackinlay. " (c) Filtering the collaboration network using the node and edge weights quickly isolates " George C. Robertson " from the rest of the network signaling that it might be a misspelling. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">CiteSeer</head><p>The next dataset we consider is the CiteSeer dataset. As an already " cleaned " dataset, used for the evaluation of entity resolution algorithms , we were surprised to see that within only a minute of using D-Dupe we were able to find seven duplicates. These duplicates had quite high similarity measures according to the Jaccard similarity measure. Each of these duplicates were due to parse errors. After these pairs are merged and there are no more pairs that users feel confident in merging under this similarity measure, users can switch to another similarity measure. JaccardChar is similar to Jaccard except that instead of using tokens, it operates at the character level. Using JaccardChar, D-Dupe shows three very similar pairs which require further inspection. Of these, only one is a true duplicate. One potential duplicate pair is " C Codognet " and " P Codognet " . The collaboration context network shows that these two authors are co-authors and therefore are likely to be distinct, because an author would not be a co-author of himself/herself. This is one of the constraints that must be met in author networks and is easily detected by visual inspection using D-Dupe. Using a third entity similarity measure, the MongeElkan measure , D-Dupe is able to detect another parse error. It indicates that " Philips A " and " Philips Andrew B Philips Stevens " are potential duplicates. Users may have high confidence in merging these two entities because they share two co-authors. Finally, D-Dupe detects one more potential duplicate pair using the JaroWinkler distance measure. The pair of " Weiss S " and " Wess S " can be merged after the Google Scholar search shows that the author on the paper for " Weiss " is in fact listed as " Wess " . In our use of D-Dupe for this supposedly clean CiteSeer subset, we were able to detect and resolve 10 duplicates in 20 minutes. As illustrated above, the flexible combination of similarity measures greatly increased our ability to resolve duplicates. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">PubMed</head><p>We have shown that D-Dupe can be helpful in finding duplicates in two datasets previously cleaned by others. We next turn to a setting in which D-Dupe works on a database for which no author extraction has been attempted. An example of such a database is the PubMed dataset maintained by NCBI. A paper record has only the authors' names associated with it, but does not have any author IDs. The PubMed records were obtained by querying for " Giardia Translation " producing 56 papers with 161 author references. In loading the data into D-Dupe, we assumed that each author reference was unique and considered all potential duplicate pairs. In this dataset, we found and resolved the potential duplicates in 20 minutes using the attribute similarity measures and the coauthorship similarity slider. We found seven duplicates by using Jaccard similarity measure, two by JaccardChar, and two more using Jaro. In the end, from the 161 author references, 11 duplicate author entities were identified. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RELATED WORK</head><p>There has been a surge of recent interest in social network analysis. Not surprisingly, at the same time, there has been extensive work on visualizing social networks <ref type="bibr" coords="7,429.12,429.43,14.17,8.12" target="#b16">[16,</ref><ref type="bibr" coords="7,445.61,429.43,6.71,8.12" target="#b8"> 8,</ref><ref type="bibr" coords="7,454.64,429.43,10.63,8.12" target="#b14"> 14]</ref>. A number of nice graph visualization and social networks packages have been developed in the past several years; a non-exhaustive list of the popular packages includes UCINET <ref type="bibr" coords="7,387.19,459.32,9.51,8.12" target="#b7">[7]</ref>, Pajek <ref type="bibr" coords="7,426.44,459.32,13.72,8.12" target="#b13">[13]</ref>, JUNG <ref type="bibr" coords="7,473.29,459.32,13.72,8.12" target="#b23">[23]</ref>, Prefuse <ref type="bibr" coords="7,524.12,459.32,13.72,8.12" target="#b19">[19]</ref>, and GUESS <ref type="bibr" coords="7,348.41,469.28,9.51,8.12" target="#b0">[1]</ref>. Because our work focuses on cleaning the data, before it is input to these more general social network analysis and visual analytics tools, in some ways this work is orthogonal. There has also been extensive work on finding and cleaning duplicates in the machine learning and database communities. Most of that work has focused on automatic methods rather than interactive support. Traditional approaches make use of only attribute information , where entities are matched based on the values of their attributes . Much of this work focused on defining approximate string matching algorithms <ref type="bibr" coords="7,396.06,561.67,14.17,8.12" target="#b20">[20,</ref><ref type="bibr" coords="7,413.46,561.67,11.18,8.12" target="#b21"> 21,</ref><ref type="bibr" coords="7,427.88,561.67,11.93,8.12" target="#b10"> 10] </ref>and fuzzy matching <ref type="bibr" coords="7,518.88,561.67,9.51,8.12" target="#b9">[9]</ref>. Other attribute-based approaches have been adaptive <ref type="bibr" coords="7,483.89,571.63,14.17,8.12" target="#b26">[26,</ref><ref type="bibr" coords="7,499.89,571.63,11.18,8.12" target="#b25"> 25,</ref><ref type="bibr" coords="7,512.91,571.63,6.71,8.12" target="#b5"> 5,</ref><ref type="bibr" coords="7,521.44,571.63,10.63,8.12" target="#b11"> 11]</ref>. More recent work has focused on combining attribute information with the relational structure of the domain <ref type="bibr" coords="7,458.65,591.56,9.69,8.12" target="#b2">[3,</ref><ref type="bibr" coords="7,471.56,591.56,11.18,8.12" target="#b27"> 27,</ref><ref type="bibr" coords="7,485.96,591.56,6.47,8.12" target="#b3"> 4]</ref>. In these works, the relational graph is taken into account for finding possible duplicates . Within the database community, there has been work on interactive data cleaning <ref type="bibr" coords="7,421.33,621.45,14.17,8.12" target="#b24">[24,</ref><ref type="bibr" coords="7,438.43,621.45,10.63,8.12" target="#b12"> 12]</ref>, but unlike D-Dupe which is designed for resolving network data, the interactive data cleaning work typically focuses on a single table. One of the challenges of visual analytics is data representation <ref type="bibr" coords="7,317.95,664.02,13.72,8.12" target="#b28">[28]</ref>. As Thomas and Cook state, " Data are at the heart of the analytic challenge. These data, in their raw form, are rarely appropriate for direct analysis. " D-Dupe addresses an element of this analytic challenge and solves it using an interface which effectively combines visual and analytic information for data cleaning in an interactive tool. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head><p> Our evaluation highlights D-Dupe's performance on three bibliographic datasets. We believe that is fairly straightforward to use D-Dupe on other social network data as well, as long as the actors and the relationships are well defined. To best exploit D-Dupe's multiple functionalities, the domain should exhibit the following properties: @BULLET The actors should have properties that can be used by the attribute similarity functions. It is relatively easy to extend the entity resolution algorithms with domain-specific algorithms supplied by the users. </p><p>@BULLET The collaboration between actors should be informative about the entity resolution task, so that the visualization of the collaboration network helps in the decision process. </p><p>@BULLET The node and edge importance should be informative for the deduplication task so that the filtering of nodes and edges helps in the decision process. </p><p>We do not present results here, but we have investigated applying D-Dupe to other tasks including name resolution in email collections , place resolution in geospatial databases, and name resolution in academic genealogy datasets. We have presented demos to experts in these domains and received very encouraging feedback. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,54.00,468.03,503.49,7.64;3,54.00,477.49,503.45,7.64;3,54.00,486.95,503.49,7.64;3,54.00,496.42,375.15,7.64"><head>Figure 2: </head><figDesc>Figure 2: Overview: The layout consists of three coordinated windows. The relevant collaboration context network is shown in the main window. Details on the current candidate duplicate pair are presented in potential duplicates detail panel in the lower window. The entity resolution control panel appears on the right; the user can select an entity similarity measure to use, view a list of candidate duplicate pairs, choose filters for the nodes, edges and collaborators, perform resolutions for a particular pair, and search for a particular author. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,54.00,238.24,503.47,7.64;4,54.00,247.70,503.47,7.64;4,54.00,257.16,503.52,7.64;4,54.00,266.62,216.11,7.64"><head>Figure 3: </head><figDesc>Figure 3: The evolution of the layout. (a) The original collaboration network using the Fruchterman-Reingold layout with no pruning. (b) Showing only the collaboration context network for the potential duplicates with the most commonly used force directed layout (c) The collaboration context subnetwork shown using the stable layout. The potential duplicates are shown in region 2 and 4, the shared neighbors are shown in region 3 and non-overlapping neighbors are shown in regions 1 and 5. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,54.00,536.59,239.81,7.64;6,54.00,546.05,154.86,7.64"><head>Figure 5: </head><figDesc>Figure 5: An example where the link structure helps in deciding that two similar nodes are in fact distinct entities. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,317.95,635.62,239.82,7.64;6,317.95,645.08,239.79,7.64;6,317.95,654.55,35.27,7.64"><head>Figure 7: </head><figDesc> Figure 7: Although these potential duplicates do not share coauthors , we can see that there are potential duplicates in their neigh- borhoods. </figDesc></figure>

			<note place="foot" n="8"> CONCLUSION D-Dupe integrates data mining algorithms with an interactive information visualization interface to support an important analytic task: entity resolution. The stable and meaningful layout presents small subnetworks from large databases in an task-appropriate, simple, and surprisingly effective design for visually presenting information about potential duplicates. The ability to flexibly apply sequences of similarity measures enables users to be highly effective in entity resolution tasks, because they often exhibit complex interdependencies . This provides a potent environment for decision making and recording of user actions for later review. By giving users control over the decision making process, they can develop improvements to the data mining algorithms and learn about the distinctive problems in their data. In using D-Dupe, we easily found duplicates in &apos;gold-standard&apos; entity resolution datasets; in one of our cleaned datasets we found that 6% of the nodes represented duplicate entities. We believe that D-Dupe illustrates the utility of building interactive tools that combine data mining and information visualization to support specific analytic tasks.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS </head><p>This work was supported by the National Science Foundation under NSF #0423845 and NSF #0438866. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="8,72.25,582.01,221.57,7.22;8,72.26,591.48,221.59,7.22;8,72.26,600.95,49.78,7.22"  xml:id="b0">
	<analytic>
		<title level="a" type="main">GUESS: a language and interface for graph exploration</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Adar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCHI Conf. on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="791" to="800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.25,610.41,221.57,7.22;8,72.26,619.87,221.55,7.22;8,72.26,629.33,54.67,7.22"  xml:id="b1">
	<monogr>
		<title level="m" type="main">Swoosh: A generic approach to entity resolution</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Benjelloun</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Garcia-Molina</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Q</forename>
				<surname>Su</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Widom</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.25,638.80,221.54,7.22;8,72.26,648.27,221.60,7.22;8,72.26,657.73,192.71,7.22"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Iterative record linkage for cleaning and integration</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Bhattacharya</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Getoor</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="page" from="11" to="18" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.25,667.20,221.53,7.22;8,72.26,676.66,221.57,7.22"  xml:id="b3">
	<monogr>
		<title level="m" type="main">Entity Resolution in Graphs, chapter Mining Graph Data</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Bhattacharya</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Getoor</surname>
			</persName>
		</author>
		<editor>Lawrence B. Holder and Diane J. Cook</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.26,686.12,40.41,7.22"  xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Wiley</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,72.26,695.59,221.56,7.22;8,72.26,705.05,221.57,7.22;8,72.26,714.52,192.71,7.22"  xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive duplicate detection using learnable string similarity measures</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bilenko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">J</forename>
				<surname>Mooney</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,58.48,221.55,7.22;8,336.21,67.95,221.53,7.22;8,336.21,77.41,155.95,7.22"  xml:id="b6">
	<analytic>
		<title level="a" type="main">D-Dupe: An interactive tool for entity resolution in social networks (poster)</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bilgic</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Licamele</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Getoor</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Shneiderman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Symp. on Graph Drawing</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="505" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,86.87,207.35,7.22"  xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Borgatti</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">G</forename>
				<surname>Everett</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">C</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Freeman. UCINET</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,96.33,221.56,7.22;8,336.21,105.80,221.54,7.22;8,336.21,115.27,90.39,7.22"  xml:id="b8">
	<analytic>
		<title level="a" type="main">Exploratory network visualization: Simultaneous display of actor status and connections</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Brandes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Raab</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Wagner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Social Structure</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,124.73,221.59,7.22;8,336.21,134.20,221.57,7.22;8,336.21,143.66,170.72,7.22"  xml:id="b9">
	<analytic>
		<title level="a" type="main">Robust and efficient fuzzy match for online data cleaning</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Chaudhuri</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Ganjam</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Ganti</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Motwani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMOD Int. Conf. on Management of Data</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="313" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.20,153.12,221.61,7.22;8,336.21,162.59,221.58,7.22;8,336.21,172.05,188.39,7.22"  xml:id="b10">
	<analytic>
		<title level="a" type="main">A comparison of string distance metrics for name-matching tasks</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">W</forename>
				<surname>Cohen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Ravikumar</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">E</forename>
				<surname>Fienberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI Workshop on Information Integration on the Web</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="73" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.20,181.52,221.59,7.22;8,336.21,190.99,221.58,7.22;8,336.21,200.45,221.60,7.22;8,336.21,209.91,17.92,7.22"  xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning to match and cluster large high-dimensional data sets for data integration</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">W</forename>
				<surname>Cohen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Richman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="475" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.20,219.37,221.58,7.22;8,336.21,228.84,99.78,7.22"  xml:id="b12">
	<monogr>
		<title level="m" type="main">Exploratory Data Mining and Data Cleaning</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Dasu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Johnson</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>John Wiley &amp; Sons, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.20,238.31,221.56,7.22;8,336.21,247.77,178.39,7.22"  xml:id="b13">
	<monogr>
		<title level="m" type="main">Exploratory Social Network Analysis with Pajek</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>De Nooy</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Mrvar</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Batageli</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,257.24,221.56,7.22;8,336.21,266.70,220.99,7.22"  xml:id="b14">
	<analytic>
		<title level="a" type="main">Visualisation of social networks using CAVALIER</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">H</forename>
				<surname>Dekker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Australasian Symp. on Information Visualisation</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="49" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,276.16,221.55,7.22;8,336.21,285.63,208.16,7.22"  xml:id="b15">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Fekete</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Grinstein</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Plaisant</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Contest, the history of InfoVis IEEE Symposium on Information Visualization</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,295.09,221.54,7.22;8,336.21,304.56,51.69,7.22"  xml:id="b16">
	<analytic>
		<title level="a" type="main">Visualizing social networks</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">C</forename>
				<surname>Freeman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Social Structure</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,314.02,221.59,7.22;8,336.21,323.49,220.90,7.22"  xml:id="b17">
	<monogr>
		<title level="m" type="main">Graph drawing by forcedirected placement. Software Practice and Experience</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">M J</forename>
				<surname>Fruchterman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">M</forename>
				<surname>Reingold</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,332.95,221.51,7.22;8,336.21,342.41,221.56,7.22;8,336.21,351.88,41.82,7.22"  xml:id="b18">
	<analytic>
		<title level="a" type="main">CiteSeer: An automatic citation indexing system</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">L</forename>
				<surname>Giles</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Bollacker</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Lawrence</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Int. Conf. on Digital Libraries</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="89" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,361.35,221.53,7.22;8,336.21,370.81,221.58,7.22;8,336.21,380.28,144.67,7.22"  xml:id="b19">
	<analytic>
		<title level="a" type="main">prefuse: a toolkit for interactive information visualization</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Heer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">K</forename>
				<surname>Card</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">A</forename>
				<surname>Landay</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCHI Conf. on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="421" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,389.73,221.57,7.22;8,336.21,399.20,221.58,7.22;8,336.21,408.67,140.91,7.22"  xml:id="b20">
	<analytic>
		<title level="a" type="main">The field matching problem: Algorithms and applications</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">E</forename>
				<surname>Monge</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Elkan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="267" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,418.13,221.60,7.22;8,336.21,427.60,127.17,7.22"  xml:id="b21">
	<analytic>
		<title level="a" type="main">A guided tour to approximate string matching</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Navarro</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="88" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,437.06,221.61,7.22;8,336.21,446.52,221.56,7.22;8,336.21,455.99,17.92,7.22"  xml:id="b22">
	<monogr>
		<title level="m" type="main">A taxonomy of multiple window coordinations</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>North</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Shneiderman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,465.45,221.57,7.22;8,336.21,474.92,221.55,7.22;8,336.21,484.38,66.06,7.22"  xml:id="b23">
	<analytic>
		<title level="a" type="main">Analysis and visualization of network data using JUNG</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>O &apos;madadhain</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Fisher</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Smyth</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>White</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<forename type="middle">B</forename>
				<surname>Boey</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,493.85,221.51,7.22;8,336.21,503.31,221.60,7.22;8,336.21,512.77,17.92,7.22"  xml:id="b24">
	<analytic>
		<title level="a" type="main">Potter&apos;s wheel: An interactive data cleaning system</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Raman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hellerstein</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Very Large Data Bases</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="381" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.21,522.24,221.53,7.22;8,336.21,531.71,221.57,7.22;8,336.21,541.17,33.85,7.22"  xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning string-edit distance</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">S</forename>
				<surname>Ristad</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">N</forename>
				<surname>Yianilos</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="522" to="532" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.20,550.64,221.54,7.22;8,336.21,560.10,221.56,7.22;8,336.21,569.56,128.76,7.22"  xml:id="b26">
	<analytic>
		<title level="a" type="main">Interactive deduplication using active learning</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Sarawagi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bhamidipaty</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="269" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.20,579.03,221.56,7.22;8,336.21,588.49,192.59,7.22"  xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-relational record linkage</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Singla</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Domingos</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD Workshop on Multi-Relational Data Mining</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.20,597.96,221.59,7.22;8,336.21,607.42,221.55,7.22;8,336.21,616.89,38.71,7.22"  xml:id="b28">
	<monogr>
		<title level="m" type="main">lluminating the Path: The Research and Development Agenda for Visual Analytics</title>
		<editor>J. J. Thomas and K. A. Cook</editor>
		<imprint>
			<date type="published" when="2005" />
			<publisher>IEEE CS Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
