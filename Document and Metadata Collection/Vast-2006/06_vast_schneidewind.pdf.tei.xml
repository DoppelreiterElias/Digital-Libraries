<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T13:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pixnostics: Towards Measuring the Value of Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Jörn</forename>
								<surname>Schneidewind</surname>
							</persName>
							<affiliation>
								<orgName type="institution">University of Konstanz</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Mike</forename>
								<surname>Sips</surname>
							</persName>
							<affiliation>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Daniel</forename>
								<forename type="middle">A</forename>
								<surname>Keim</surname>
							</persName>
							<affiliation>
								<orgName type="institution">University of Konstanz</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pixnostics: Towards Measuring the Value of Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Visual Data Exploration, Visualization tech-</term>
					<term>nique, Visual Analytics</term>
					<term>Index Terms:</term>
					<term>I69 [Visualization]: Information</term>
					<term>Visualization—Visualization Techniques and Methodologies</term>
				</keywords>
			</textClass>
			<abstract>
				<p>During the last two decades a wide variety of advanced methods for the Visual Exploration of large data sets have been proposed. For most of these techniques user interaction has become a crucial element, since there are many situations in which an user or an analyst has to select the right parameter settings from among many or select a subset of the available attribute space for the visualization process, in order to construct valuable visualizations that provide insight into the data and reveal interesting patterns. The right choice of input parameters is often essential, since suboptimal parameter settings or the investigation of irrelevant data dimensions make the exploration process more time consuming and may result in wrong conclusions. In this paper we propose a novel method for automatically determining meaningful parameter-and attribute settings based on the Information content of the resulting visualizations. Our technique called Pixnostics, in analogy to Scagnostics[1] automatically analyses pixel images resulting from diverse parameter mappings and ranks them according to the potential value for the user. This allows a more effective and more efficient visual data analysis process, since the attribute/parameter space is reduced to meaningful selections and thus the analyst obtains faster insight into the data. Real world applications are provided to show the benefit of the proposed approach.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p> A wide variety of advanced Visual Exploration and Visualization methods have been proposed in the past. These techniques have proven to be of high value in supporting researchers and analysts to obtain insight in large data sets and to turn raw data into useful and valuable knowledge by integrating the human in the exploration process. However , with the increasing volume and complexity of today's data sets, new challenges for Visualization techniques arise. To keep step with the growing flood of information, Visualization techniques are getting more sophisticated, e.g. by integrating automated analysis methods or providing new visualization metaphors as proposed in the context of Visual Analytics <ref type="bibr" coords="1,95.01,607.60,9.20,8.12" target="#b1">[2]</ref>. But this also means, that visualization techniques are getting more complex, forcing the user to set up many different parameters to adjust the mapping of attributes to visual * schneide@inf.uni-konstanz.de † ms@pixelmap.org ‡ keim@inf.uni-konstanz.de </p><p>(a) Linear Colormap (b) Logarithmic Colormap <ref type="figure" coords="1,317.96,267.95,28.97,7.14">Figure 1</ref>: A typical application scenario – The visual analysis of a census data set involves different normalizations to a color scale; Although both visualizations are based on exactly the same input data, the right figure provides more insight since a logarithmic color scale is more suitable for the underlying data distribution variables on the display space. In classical data exploration, playing with parameters to find a promising parameter setting is an important part of the exploration process, but with the increasing number and diversity of the parameters it becomes more and more difficult to determine a good parameter setup, which is vital for insightful visualizations. For example, if we have 50 attributes (or attribute dimensions ) and 4 parameters for the visual mapping, as e.g. in Pixel Bar Charts <ref type="bibr" coords="1,389.99,420.42,9.72,8.12" target="#b2">[3] </ref>employed in Section 4.2, then we have over 5 million possible mappings and it is very unlikely to find useful ones interactively. Suboptimal parameter settings or the investigation of irrelevant data dimensions make the exploration process tedious and an interactive search impossible. In general, finding a good parameter setup is a challenging task for the analyst, since it is often not clear what is the best parameter setting for a given task, due to the huge parameter-and attribute space <ref type="bibr" coords="1,381.51,511.48,9.21,8.12" target="#b3">[4]</ref>. A simple application scenario is shown in <ref type="figure" coords="1,500.23,522.83,33.03,8.12">Figure 1</ref>. The figure shows two choropleth maps visualizing USA population density data at county level. The two maps are based on the same input data, but created with two different parameter settings. More precisely, in the left figure a linear color mapping was chosen, in the right figure a logarithmic color mapping was chosen. It is easy to see that the linear mapping provides much less insight to the data than the logarithmic mapping, because the data is highly non-uniformly distributed. For instance, very high populated areas around Los Angeles, Chicago or Manhattan cause uniform dark colors for the remaining USA and it is almost impossible to see fine structures or differences in population density among them. In practice, the analyst does not know a priori which normalization function is best suited for a given dataset and he may test some preferred ones. Of course, there are typically much more parameters that have to be selected. But the growing data complexity does not allow such playing with data by hand anymore. Therefore the paper aims at supporting the user in finding promising parameter tups from the available parameter space to speed up the exploration process. We present a framework that employs automated analysis methods to detect potentially useful parameter settings for a given pixel-based visualization technique and an associated input data set, with respect to a given user task like Clustering or Outlier detection. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="199"></head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Definition</head><p>In many application scenarios analysts have to deal with large parameter spaces when using visualization techniques to explore large data sets. These parameters control the visual encoding of the data, including the selection of attributes from the input data, the selection of the color scale, algorithm parameters, the selection of visual variables and so on. The problem is that the optimal parameter setting for a given task is often not clear in advance, which means that the analyst has to try multiple parameter settings in order to generate valuable visualizations. Since such selections can hardly be done manually, the integration of automated methods to support the analyst has been recognized as an important research problem in the context of Visual Analyt- ics <ref type="bibr" coords="2,67.35,267.51,9.21,8.12" target="#b1">[2]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Parameter space of the Visualization Process</head><p>The challenging task in generating expressive visualizations is to find an adequate visual encoding of the input data set in the data display space. The visual encoding depends on the input data, the employed visualization technique and the visual variables given by a particular parameter setting. In classical data exploration, the mapping to visual variables described by Bertin <ref type="bibr" coords="2,133.20,357.21,9.20,8.12" target="#b4">[5]</ref>, such as position (x,y), size, or color is manually controlled by the user. More precisely, the central process of visualization V can be described as </p><formula>I(t) = V (D, S(P ), t) </formula><p>where data D is transformed using a specification S into a time varying image I(t), according to the work proposed by Wijk <ref type="bibr" coords="2,91.76,434.56,9.21,8.12" target="#b5">[6]</ref>. To simplify matters, we aim at determining initial parameter settings for non-animated visualizations, therefore the time t can be excluded from our considerations. (Note that the complexity of the problem would be boosted exponentially, if we take time into consideration.) Based on the formula above, the data set D is given as input data within a database environment with D = (d1, . . . , dn). In the presentation of our approach, we focus mainly on demographic data provided by the US Census Bureau <ref type="bibr" coords="2,85.98,524.23,9.21,8.12" target="#b6">[7]</ref>. The data set contains, for example, information about US education levels, crime rates, housing or household incomes on different levels of detail (country, states, counties , block level). Typical exploration tasks focus on the extraction of information about housing neighbourhoods for particular areas within the US including the identification of correlations between statistical parameters like household income, house prices, education levels and crime rates. The employed visualization technique V is defined by the application scenario and is given by the user. In this paper we use novel pixel-based techniques such as Pixel Bar Charts <ref type="bibr" coords="2,84.76,633.82,9.72,8.12" target="#b2">[3] </ref>and Jigsaw maps <ref type="bibr" coords="2,171.14,633.82,9.72,8.12" target="#b7">[8] </ref>as examples to explain our new idea. Pixel Bar Charts (described in Section 4.2) have 4 parameters and more to adjust the visual encoding. The technique uses 1 parameter to separate the data into bars, 2 parameters for ordering of pixels in x and y direction and 1 parameter for color coding. Obviously, the manual selection of useful parameter settings does not scale with practical data sets, since the number of parameter settings which the user may try is limited. In our setting the input data D and the visualization technique V is given by the user and P = Pi = (p 1 i , . . . , p m i ) as instance of a parameter setting generating image I(S(<ref type="bibr" coords="2,532.06,87.37,12.85,8.12">Pi)</ref>) is determined by the system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Limits and Problem Complexity</head><p>Most visualization techniques can handle less attributes than provided by the dimensionality of the input data set, so in the visualization step potentially useful attribute combinations must be selected from the data. As an example, we consider a data analyst who wants to use the Pixel Bar Chart technique to analyze real world customer purchase data. Such data sets typically include at least 20 dimensions (attributes), including name of item, price of item, name/id of the customer, status and so on. The number of possible parameter settings Pi = (p 1 i , . . . , p m i ) that control the visual encoding and therefore the number of possible images IP i is defined by the number of different attribute combinations of size m from the available number of dimensions d, given as: </p><formula>I(S(Pi)) = V (D, S(Pi), t) = d! (d − m)! </formula><p> For the Pixel Bar Chart example, we may specify m = 4 attributes at once from the input data with 20 dimensions, which would result in 116,280 mappings. This number may be increased by additional parameters like different colormaps or different scalings. The equation above also shows that increasing dimensionality boosts the parameter space exponentially. If we have 50 attributes the number of possible mappings is 5.5 million. Then the analyst faces the problem , how to determine interesting subsets from the available data dimensions for visual analysis, that reveal interesting relationships. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Analysis Objectives</head><p>The aim of this paper is to provide techniques to prune the available parameter space to relevant settings to reduce the costs of creating insightful visualizations by filtering potentially relevant visualizations from irrrelevant ones. In <ref type="bibr" coords="2,330.24,473.39,9.72,8.12" target="#b8">[9] </ref> a semi-automated technique to search through visualization parameter space with applications in surface texturing is presented that focuses especially on perceptual and aesthetic concerns. The basic idea of this approach is to employ a genetic algorithm to guide a human-in-the-loop search through the parameter space. In <ref type="bibr" coords="2,340.52,533.68,9.72,8.12" target="#b0">[1,</ref><ref type="bibr" coords="2,354.39,533.68,11.77,8.12" target="#b9"> 10,</ref><ref type="bibr" coords="2,370.31,533.68,11.77,8.12" target="#b10"> 11] </ref>graph theoretic approaches to solve these problems for scatterplots were proposed. This work called Scagnostics highly influenced our work. The goal of the mentioned approaches was to find interesting attribute relationships by creating scatterplot matrices from the data and then analyze each scatterplot, which reveals a relationship between 2 attributes, for certain properties using graph theoretic methods. The basic idea is to construct geometric graphs based on the data points of each scatterplot and then to compute relevance measurements from these graphs. For example, properties of the convex hull and the minimal spanning trees of the scattered points are used for outlier or cluster analysis. With our approach we extend this idea to a broader set of visualization techniques. We provide analysis functions to analyse both patterns in the data using data analysis techniques as well as the patterns contained in the images by using image analysis techniques. Although data mining methods are commonly used for data analysis, only little research has been done on analyzing visualizations with respect to their information content using image analysis methods. In this paper we focus on pixel-based visualization techniques in which every data point corresponds to a pixel. Since we deal with pixel images instead of scatterplots, we call our approach Pixnostics instead of Scagnostics. Our idea is to employ image analysis and retrieval methods to compute measurements based on the properties of the image pixels like color and pixel neighbourhoods. A very promising way to extract information about the content of an image is Shannon's entropy measure <ref type="bibr" coords="3,253.21,157.11,13.51,8.12" target="#b11">[12]</ref>. It is frequently used in image processing and analysis. In <ref type="bibr" coords="3,279.64,167.07,14.32,8.12" target="#b12">[13] </ref> an entropy based approach for image cluster analysis is proposed , a more general approach for image retrieval using entropy is introduced in <ref type="bibr" coords="3,155.36,196.96,13.51,8.12" target="#b13">[14]</ref>. We adapt these techniques to measure the relevance of images Ii resulting from visualizations V (D, S(Pi)) with respect to a given task T . In classical visual exploration the user visually analyzes a collection of data items to find answers to various questions (analysis tasks), whereas in our framework different analysis tasks are supported by evaluating properties of the resulting visualizations. Since the applied methods highly depend on the selected task, it is one of the major challenges to identify the most relevant tasks, identify their relationship to visual properties in the resulting image I and finally to find adequate analysis functions for each of the tasks, i.e. to find good predictors for these properties in images. Unique properties in images are homogenous areas, color outliers, edges and segments etc. Previous studies on visualization design proposed a range of different analysis goals and tasks <ref type="bibr" coords="3,120.57,356.36,14.32,8.12" target="#b14">[15] </ref>[16] <ref type="bibr" coords="3,156.81,356.36,14.33,8.12" target="#b16">[17] </ref>[18] <ref type="bibr" coords="3,193.04,356.36,13.51,8.12" target="#b18">[19]</ref> . They propose individual taxonomies of information visualizations using different backgrounds and models, so that users and analysts can quickly identify various techniques that can be applied to their domain of interest. Based on the proposed approaches, generic tasks like identify, locate, cluster, associate, compare, correlate, match and sort can be identified. In the following we describe the individual steps of Pixnostics where we mainly focused on analysis functions for clustering tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Pixnostics approach</head><p>Our Pixnostics approach follows a three step process based on the current task-at-hand: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>@BULLET Analytical Filtering and Pruning </head><p> of the set of possible images {I(S(<ref type="bibr" coords="3,150.76,501.49,13.04,11.66">Pi)</ref>)} by analyzing the parameter space Pi. The aim is to extract useful attribute selections and useful parameter settings automatically (candidate set CS), In the following we describe the individual steps in more details. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Step 1: Analytical Filtering and Pruning</head><p> In practice, the number of attributes is greater than the capabilities of most visualization techniques. The first step of our Pixnostics approach is therefore to determine relevant relationships among the different attributes analytically . We use data mining techniques, more precisely, correlation analysis, partial matching techniques and cluster analysis to accomplish this step. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Correlation Analysis</head><p> Attributes that are correlated may be interesting for detailed analysis, because they may reveal relevant impact relationships. Therefore we employ correlation analysis to find groups of correlated attributes. First, we determine the pair-wise global correlations among all measurements as given by Pearson's correlation matrix. Pearson's correlation coefficient r between bivariate data A1i and A2i with (i = 1, . . . , n) is defined as </p><formula>r = n i=1 (A1i − ¯ A1)(A2i − ¯ A2) n i=1 (A1i − ¯ A1) 2 n i=1 (A2i − ¯ A2) 2 (1) </formula><p>where ¯ A1 and ¯ A2 are the means of the A1i and A2i values, respectively. If two dimensions are perfectly correlated, the correlation coefficient is 1, in case of an inverse correlation -1. In case of a perfect correlation, we can omit one of the attributes since it contains redundant information. In <ref type="figure" coords="3,474.57,267.97,33.96,8.12" target="#fig_1">Figure 2</ref>an example from the census housing data on US state level is shown, correlation coefficients for pairs of attributes are shown in the upper right half of the matrix, histograms in the diagonal show the data distribution. The <ref type="figure" coords="3,477.66,621.47,52.92,8.12">figure clearly</ref>shows that states with high total population have high gross rents (0.96) or that Median Household incomes are correlated with Median House prices per state (0.68). The analyst may now investigate such relations in more detail. In most cases, however the correlations are not perfect and we are interested in high correlation coefficients and select sets of highly correlated attributes to be visualized. An available alternative for adjacently depicting similar dimensions is to use the normalized Euclidean distance as a measure for global similarity Sim Global defined as: </p><formula>Sim Global (Ai, Aj) = N −1 i=0 (b 1 i − b 2 i ) 2 (2) </formula><p>where b j </p><formula>i = (a j i − min(Aj))/(max(Aj) − min(Aj)) </formula><p> The global similarity measure compares two whole dimension such that any change in one of the dimensions has an influence on the resulting similarity. The defined similarity measure allows it to determine groups of similar attributes for the following visualization. Since in general, computing similarity measures is a non-trivial task, because similarity can be defined in various ways and for specific domains, special measures may be included for specific tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Cluster analysis</head><p>In order to perform a visual analysis, it is important to have the possibility to partition the value ranges appropriately. Cluster analysis can help to do this based on the characteristics of the data instances. The cluster analysis may, for example, find out that the data instance of a data set may be partitioned into different groups, which may be then independently analysed using visualization techniques. Since attribute parameter values may be continuous (sales amount) or categorical values (item name) the clustering approach has to take these properties into account. There are a large number of clustering methods which have been proposed in the literature (<ref type="bibr" coords="4,113.41,353.59,14.33,8.12" target="#b19">[20] </ref> presents a nice overview). In the Pixnostics prototype we employed the k-means approach <ref type="bibr" coords="4,260.11,363.55,13.51,8.12" target="#b20">[21]</ref>, one of the most popular approaches, since it is easy to implement and provides good results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Classification Analysis</head><p> In some applications, for example in visual root-cause analysis , the goal of the data exploration is to understand the relationship between data attributes and some specific target attribute, e.g. which attributes have an influence on the target attribute. The task is to find the attributes which are best predicting the outcome of the target attribute. A wellknown heuristic for this task is the GINI index <ref type="bibr" coords="4,250.22,481.39,13.50,8.12" target="#b21">[22]</ref>, which is commonly used in decision tree construction. Given a target attribute (e.g. a business metric) AT which is partitioned into a disjoint set of k classes (e.g. accept, reject ) or value ranges (e.g. large, medium, small) denoted by </p><formula>C1, . . . , C k , (B = k i=1 Ci)</formula><p> , then the GINI index of an attribute A which induces a partitioning of A into A1, . . . , Am is defined as </p><formula>InfoGainGINI (AT , A) = m i=1 |Ai| |AT | GIN I(Ai) </formula><formula>(3) where GIN I(Ai) = 1 − k j=1 |Cj| |Ai| 2 </formula><p> The InfoGain is determined for all attributes and attribute combinations and the attributes with the highest InfoGain with respect to the target attribute AT are chosen for visualization. These attributes are best predicting the outcome of the target attribute and therefore they may be relevant for detailed analysis. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Step 2: Image Analysis</head><p>Once we have selected candidate parameter settings Pi, i = 1, ..., max based on promising attribute selections, were max is the number of parameter settings, we generate visualizations by computing all possible mappings of the candidate parameter set to visual variables, and then determine the Information content of the resulting images using image analy- sis. In the first step we generate and store IPi as a matrix U of scalars representing gray scale values, the pixel-matrix representation with U = (ui,j), i ∈ [0, ..., I width ], j ∈ [0, .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.., I height ] </head><p>(color images are converted to gray values). The next step is to process the image, to generate some measurements of it's information content and thus return the relevance of this image with respect to a given task T . Numerous image processing operations σ() exist in the literature, e.g. for Image Segmentation, Edge Detection, Image Denoising or Image Inpainting <ref type="bibr" coords="4,389.88,229.93,13.51,8.12" target="#b22">[23]</ref>. The base for our analysis is the distribution of gray values within the image. Thus we are interested to know the pixel distribution H in certain areas of the Image as a function of gray levels g. Image Histograms are an efficient way to reach this goal. The histogram of the 2D image g(U ) can be seen as a 1D function H<ref type="bibr" coords="4,414.19,593.97,13.62,8.12">[g] </ref>where the independent variable is the gray value g and the dependent variable is the number of pixels H with that level. We can then use the histogram properties to make assumptions about the information contained in the image. For example, if most pixels in an image are contained in a small range of gray levels, the image can be seen as redundant since it provides little new information and thus the underlying parameter setting would not lead to insightful visualizations. If there are too many different gray levels, the image represents noise and it is not likely that it contains relevant information. An image with a bimodal histogram (i.e. a histogram with two peaks) may contain clusters and may be relevant for visual exploration. Since all pixels in the image must have some gray value in the allowed range, the sum of populations of the histogram bins must be equal the total number of image pixels N : </p><formula>N = gmax g=0 H(g) </formula><p>where gmax is the maximum gray value (gmax = 255 for an 8-bit quantizer). The histogram function is equal to the scaled probability distribution function p(g) of gray levels in that image: </p><formula>p(g) = 1 N H(g) with g=max g=0 p(g) = 1 </formula><p>Based on the probability distribution we can now compute a measure for the information content of the image. In general any function σ() can be used , but a common way of doing this is Shannons Entropy <ref type="bibr" coords="5,154.53,423.99,13.50,8.12" target="#b11">[12]</ref>, which is equal to the minimum number of bits which are required to store the image. If the probability of gray level g in the image u(i, j) is represented as p(g), the definition of the quantity of information in the image is: </p><formula>E(g) = − gmax g=0 p(g) log 2 (p(g)) (4) </formula><p> From this definition, it is easy to show that the maximum information content E is obtained if each gray level has the same probability; in other words, a flat histogram corresponds to maximum information content. The minimum information content E = 0 is obtained if the image contains only one gray level. Since minimal information content means redundancy and maximum information content means information overload or noise, the interesting images should have an information content in between, e.g. in a task dependent range c shown in <ref type="figure" coords="5,189.18,597.01,33.68,8.12" target="#fig_4">Figure 4</ref>Alternatively we use the standard deviation stdev as a measure of spread of gray levels g in a given image I with N as the number of different gray levels in the image: </p><formula>stdev(I, g) = 1 N N i=1 (gi − g) 2 (5) </formula><p>Since we want to analyze the images not only in whole, but also find interesting local patterns in the image, we use a regular grid to separate the image in regular grid cells and than apply the methods mentioned above to compute values for each grid cell. The computation of the information content of each cell is identical to the methods described above. The only difference is that from the individual grid values we then compute a single relevance value for each image , described in the next section. To adapt our method to given application scenarios, we do not only use a fixed grid-resolution, but a hierarchy of grid cells, efficiently implemented by a quadtree data structure <ref type="bibr" coords="5,481.40,137.30,13.51,8.12" target="#b23">[24]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input: Candidate Set </head><formula>C = {A 1 D , . . . A h D }, {P1, . . . , P l } with Candidate Data Attributes A 1 D , . . . A h D (h &lt; n), Candidate Parameter Settings P1, . . . , P l : (l &lt; k), Visualization V with Specification S Performed Task T Output: Ranking Scores R( I(S(Pi)) = V ({A 1 D , . . . A h D }, S(P1, . . . , P l ) ) Procedure Visualization Analysis Generate Ii = V ({A 1 D , . . . A h D }, S(P1, . . . , P l ) for i ← 1 to |C| do ComputeRegularGridonImage(Ii) </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>for each GridCell GC(Ii) do </head><p>ComputeEntropyValues f (GC</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Step 3: Ranking and Output to the User</head><p>Having a function f , such as E, stdev, which measures the information content of an image, we can now compute rankings from the candidate parameter sets with respect to a given user task T . For effective data analysis we can identify two major tasks that are common in most analyses processes, namely outlier analysis, including the search for local outliers or values of interest (find all counties or cities that have similar household income or unexpected household income), and cluster analysis (find areas with similar statistical parameters ). In our prototype framework we provide ranking functions for both tasks and show how we applied it to real world data sets. Of course, the user may also use other ranking functions for specific tasks, which can be easily integrated into the Pixnostics framework. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Computing the Global Ranking Score</head><p> The first step in processing the image is to superpose a regular grid on the image. Each grid cell may then again be separated into grid cells at finer resolution until a sufficient resolution is reached as shown in <ref type="figure" coords="5,453.33,643.78,33.67,8.12" target="#fig_3">Figure 3</ref>(b). We initialize each regular grid cell GC(Ii) with its information content score f (GC(<ref type="bibr" coords="5,414.81,663.71,12.84,8.12">Ii)</ref> ). Then we start to merge regular grid cells GC k (Ii) and GC l (Ii) that have similar content scores, to larger cells. The new content score f (GC(<ref type="bibr" coords="5,530.53,683.63,13.49,8.12">Ii)</ref>) is determined using local term weighting f (<ref type="bibr" coords="5,489.11,693.59,53.48,8.12">GCcommon(Ii)</ref>) </p><formula>= l(f (GC k (Ii)) + f (GC l (Ii)</formula><p>). The term weight function l is defined over the set of all regular grid cells GC(Ii) . We use this measure to investigate clustering properties, where we are looking for images with higher information content f on coarser grid resolutions and with lower information content f at finer grid resolutions. The technique is similar to Single Linkage Clustering. We order on each resolution level the grid cells according to their value f , starting with the finest resolution. Then we expand grid cells with similar low content scores and sum up their weight while enlarging the grid cells. Since the spread of gray levels is typically higher if the size of the grid cell increases, we use cell size as an weighting factor. Note that the local term weight l directly depends on the given task T . That means, the user just needs to provide useful weight functions to get a relevance measure of the image for the given task. Well-known and widely used weight functions are binary operators, logarithmic or augmented normalized term frequency. In outlier analysis, the goal is to compute a ranking of a collection of images in such a manner that images showing outliers should have higher global ranking scores. The inverse normalized term frequency is common choice for outlier analysis. The normalized term frequency l is defined as the logarithm of the sum of two information content scores f (GC k (<ref type="bibr" coords="6,84.99,452.73,10.77,8.12">Ii)</ref>) and f (GC l (Ii) normalized by the total number of regular grid cells {GC(Ii)} . </p><formula>l(f (GC k (Ii)) + f (GC l (Ii)) = log {GC(Ii)} f (GC k (Ii)) + f (GC l (Ii) </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation and Application</head><p>To show the usefulness of our approach we applied the Pixnostics technique to generate Jigsaw maps and Pixel Bar Charts. The proposed experiments show how Pixnostics can steer the visual exploration process in an unsupervised manner , to increase the efficiency of the exploration process and to actively support the analyst to reduce the effort of getting insight from the data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Census data Jigsaw Maps</head><p>Our first application example analyzes US census data, in particular median household income for the state of New York on block level. We generated visualizations using Jigsaw maps <ref type="bibr" coords="6,94.10,643.78,9.21,8.12" target="#b7">[8]</ref>, a pixel-based space filling technique. The basic idea is to map the census data into the 2D plane in such a way that properties like locality and clusters in the data are preserved by using a space filling curve. To verify our proposed techniques, we generated a Jigsaw map from the New York state census median household income data on block level which should preserve the clusters in the data (clusters of areas with high/low income) and their spatial location shown in <ref type="figure" coords="7,184.23,314.46,33.80,8.12" target="#fig_7">Figure 5</ref>(a). As the figure shows, in the Queens area households with a income arround $100,000 are clustered. Then we permutate the pixels in the data at different permutation rates. This should of course destroy, or at least reduce the clustering/locality properties. Now we apply our automated analysis function based on the clustering task, that ranks the underlying figures according to their clustering properties. The original jigsaw should of course be the image with the highest rank, since it provides the best clustering properties. The more permutation in the image, the lower should the relevance of the image, i.e. its rank, be. <ref type="figure" coords="7,63.96,434.07,33.02,8.12" target="#fig_8">Figure 6</ref>shows the experimental results. The upper figure </p><p>shows the unordered input data set, a set of Jigsaw images. It is easy to visually identify images with good clustering properties, i.e. images having a cluster with low income in the upper left corner surrounded by high income areas. In the lower figure, the result after the analysis step is shown. It is easy to see that figures with good clustering properties are ranked first, while images containing more noise have lower relevance. To determine the ranking, either the Entropy or the Standard deviation of the pixel gray levels in combination with the regular grid cell hierarchies are em- ployed. <ref type="figure" coords="7,89.01,543.66,34.52,8.12" target="#fig_7">Figure 5</ref>shows the rationale for the ranking. An image that provides a good clustering has areas with very low Entropy or low Stdev of gray levels while the complete figure does not necessarily have low Entropy. Therefore we start with a fine grid and determine the information content of each cell like shown in <ref type="figure" coords="7,181.19,593.47,33.65,8.12" target="#fig_7">Figure 5</ref> (b). Then we hierarchically compare neighbouring grid cells similar to Single Linkage Clustering and try to extend clusters. Finally we aggregate the Information content of the clusters and order the images according to their Information content values. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Pixel Bar Charts</head><p>Pixel bar charts<ref type="bibr" coords="7,116.30,663.65,11.37,8.12" target="#b2">[3] </ref>are derived from regular bar charts. The basic idea of a pixel bar chart is to present the data values directly instead of aggregating them into a few data values by representing each data item by a single pixel in the bar chart. The detailed information of one attribute of each data item is encoded into the pixel color and can be accessed and displayed as needed. To arrange the pixels within the bars one attribute is used to separate the data into bars and then two additional attributes are used to impose an ordering within the bars along the x and y axes. A Pixel Bar Chart can be seen as a combination of traditional bar charts and x-y diagrams. Although Pixel Bar Charts have been successfully applied to explore large data sets, the analyst has to choose selections of attributes for separation, ordering and color coding of data points from the underlying data manually, according to his analysis tasks. On one hand, this is time consuming since he has to try multiple parameter settings even those that do not reveal interesting patterns, on the other hand he may overlook interesting patterns since only a few attribute combinations can be analyzed manually. To face this problem we combined Pixnostics and Pixel Bar Charts, to guide the analyst through the exploration process and indicate potentially interesting parameter settings. We applied our approach to a production data example. The data set contains data from an assembly line, in particular measurements from different stages of the assembly line like cast temperatures, part measurements and the quality of the output. All in all the data set contains 22 attributes. The output parts are classified into 3 groups: accept, reject , rework. Parts that are grouped " accept " pass the quality check, " rework " parts need to be reworked to pass the quality check and " reject " parts must be rejected because of defects. The analysis of such data is an important task in order to reduce rejected parts and thus to reduce production cost. Using Pixel Bar Charts, the analyst faces to problem of how to find groups of attributes that may influence the quality of the output. There are 175560 combinations possible to choose 4 attributes as visual variable from 22, even if the target attribute " Quality " is fixed for separation of the bars, there are still over 9000 combinations for selection of 3 attributes out of 22, which can't by checked manually. Therefore we first apply our automated analysis tools to determine attributes that most influence the " Quality " variable, using correlation and classification analysis. Of course we can additionally prune all parameter settings where " Quality " is not involved, since these will not bring us any new insight. From the remaining combinations we either generate images and order them by information content directly, like shown in <ref type="figure" coords="8,91.17,225.60,32.92,8.12" target="#fig_9">Figure 7</ref>(a) or we can filter Pixel Bar Charts where the target attribute is fixed as splitting attribute and select the most valuable ones from them, as shown in <ref type="figure" coords="8,243.23,245.52,33.25,8.12" target="#fig_9">Figure 7</ref>(b). The figure shows the 25 most relevant Pixel Bar Charts having " Quality " as splitting attribute. Note that the left bar shows parts that are " rework " , the middle bar shows " reject " parts and the right bar show " accept " parts. It is easy to see that the " reject " bars look significantly different than the rest. The analyst may now select a single image from the provided images, and a Pixel Bar Charts is created from this selection as shown in <ref type="figure" coords="8,163.67,325.23,33.51,8.12" target="#fig_10">Figure 8</ref>. The analyst can now easily discover relevant patterns by visual based root cause analysis. In the image the color shows the temperature of a particular casting mold and the ordering in y direction shows the duration of the part at this stage. It is easy to see that the casting mold had a significantly higher temperature for " reject " parts, which is a potentially reason for a damaged part. In this manner the analyst may investigate further high ranked images, which provides a more efficient way of visual analysis than manual feature selection. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future work</head><p>Integrating automated analysis methods into the Visual Exploration process is an important challenge in the age of massive data sets and has been recognised as a major research area in the context of Visual Analytics. Therefore the aim of this paper is to show how unsupervised analysis functions can help to speedup the Visual Exploration process by supporting the user with task driven relevance functions for a more effective data analysis. The basic idea of the proposed method is to measure the relevance of the resulting visualization with respect to input parameters and user tasks and to provide a ranking of potentially useful initial visualizations. This helps the analyst to focus on relevant parts of the data and relevant parameter settings and could lead to an improved exploration process. We provided a formal definition of our work and showed how the technique can be used with Jigsaw's and Pixel Bar Charts. Future work will focus on the improvement of the proposed technique and its application to a variety of visualization techniques, including geometric and iconic techniques. Another important issue is the evaluation of the proposed analysis functions, where bridging the gap between human expresssions of an analysis task and the corresponding analysis functions in Pixnostics is one of the major topics for further research. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,64.34,548.23,229.71,11.66;3,73.93,560.23,220.08,8.12;3,73.93,570.19,59.98,8.12;3,64.34,585.01,229.71,11.66;3,73.93,597.01,166.13,8.12"><head>@BULLET </head><figDesc>Image Analysis of the remaining candidate set CS – generating visualizations using the determined candidate attributes @BULLET Ranking and Output of the candidate set CS – providing a ranking of candidate images ICS </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,317.96,536.98,240.00,7.14;3,317.96,546.45,240.01,7.14;3,317.96,555.91,240.00,7.14;3,317.96,565.38,233.84,7.14"><head>Figure 2: </head><figDesc>Figure 2: Identifying correlations in census housing data on US state level: Besides trivial correlations (e.g. Population and Number of House Units) , some interesting correlations reveal e.g. between population and gross rent (because of demand and supply effects) </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,324.58,373.76,229.64,7.22;4,328.40,492.49,100.45,7.22;4,448.19,492.49,92.77,7.22"><head></head><figDesc>(a) Original NY state Jigsaw (b) Generated Image Gridcells (c) Coarse Grid Resolution (d) Fine Grid Resolution </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,317.96,515.96,240.04,7.14;4,317.96,525.43,240.03,7.14;4,317.96,534.89,240.03,7.14;4,317.96,544.35,87.52,7.14"><head>Figure 3: </head><figDesc>Figure 3: Basic idea of grid based information content: Based on the entropy values for certain grid resolutions, measurements for the relevance of the image are generated. Darker gray levels correspond to higher entropy values. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,54.00,187.21,240.03,7.14;5,54.00,196.67,240.06,7.14;5,54.00,204.33,224.26,10.36"><head>Figure 4: </head><figDesc>Figure 4: Information content (IG) of different gray level images. From an analyst's point of view, interesting images should have an Information content in a certain range c between 0 and IGmax </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="6,54.00,183.91,503.96,7.14;6,54.00,193.37,503.99,7.14;6,54.00,202.84,363.06,7.14"><head>Figure 5: </head><figDesc>Figure 5: Visualization of Information content: Jigsaw maps are generated from NY median household income, darker colors correspond to higher income. Gray levels show the information content of image sections, darker gray levels correspond to higher information content. The permutated image has significant higher information content, which indicates bad clustering properties </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="6,317.96,689.03,240.06,7.14;6,317.96,698.49,240.08,7.14;6,317.96,707.96,166.62,7.14"><head>Figure 6: </head><figDesc>Figure 6: Census data Jigsaw unsorted (top) und sorted (line by line starting at top left corner with most relevant) by ranking function based on Entropy and clustering task (bottom) </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="7,54.00,273.84,503.95,7.14;7,54.00,283.30,242.73,7.14"><head>Figure 7: </head><figDesc>Figure 7: Pixel Bar Chart showing top 25 results after image analysis using entropy measure. It is easy to see that the bar in the middle ( " reject " parts) show significant differences in comparison to the 2 other bars. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10" coords="8,54.00,143.06,240.08,7.14;8,54.00,152.53,238.76,7.14"><head>Figure 8: </head><figDesc>Figure 8: Pixel Bar Chart constructed from the output result of Pixnostics (from the Chart in the upper right corner in Figure7 (b). </figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement </head><p>This work was supported by the Max Planck Center for Visual Computing and Communication (MPC-VCC). </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="8,336.11,70.75,221.84,7.22;8,336.11,80.22,221.91,7.22;8,336.11,89.68,221.89,7.22;8,336.11,99.15,167.46,7.22"  xml:id="b0">
	<analytic>
		<title level="a" type="main">Graph-theoretic scagnostics</title>
		<author>
			<persName>
				<forename type="first">Leland</forename>
				<surname>Wilkinson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Anushka</forename>
				<surname>Anand</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Robert</forename>
				<surname>Grossman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INFOVIS &apos;05: Proceedings of the 2005 IEEE Symposium on Information Visualization</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.11,108.61,221.81,7.22;8,336.11,118.08,221.88,7.22;8,336.11,127.54,78.31,7.22"  xml:id="b1">
	<analytic>
		<title level="a" type="main">Illuminating the path:Research and Development agenda for Visual Analyics</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">J</forename>
				<surname>Thomas</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">A</forename>
				<surname>Cook</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE</title>
		<imprint>
			<date type="published" when="2005-10" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.11,137.00,221.86,7.22;8,336.11,146.47,221.83,7.22;8,336.11,155.93,221.87,7.22;8,336.11,165.40,19.28,7.22"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Pixel Bar Charts: A visualization technique for very large multiattribute data sets</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Keim</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">C</forename>
				<surname>Hao</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Dayal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hsu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="20" to="34" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.11,174.86,221.89,7.22;8,336.11,184.33,152.58,7.22"  xml:id="b3">
	<monogr>
		<title level="m" type="main">Information Visualization</title>
		<author>
			<persName>
				<forename type="first">Robert</forename>
				<surname>Spence</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>ACM Press Books</publisher>
			<pubPlace>Pearson Education ltd.,UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.11,193.79,221.87,7.22;8,336.11,203.26,123.11,7.22"  xml:id="b4">
	<monogr>
		<title level="m" type="main">Semiology of graphics</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Bertin</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<publisher>University of Wisconsin Press</publisher>
			<pubPlace>Madison, Wisconsin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.11,212.72,221.90,7.22;8,336.11,222.19,221.85,7.22;8,336.11,231.65,51.96,7.22"  xml:id="b5">
	<analytic>
		<title level="a" type="main">The value of visualization</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Jarke</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Van Wijk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization</title>
		<meeting>IEEE Visualization<address><addrLine>Minneapolis, MN</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-10" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.11,241.12,184.88,7.22"  xml:id="b6">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">US Census Bureau</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.11,250.58,221.82,7.22;8,336.11,260.04,196.03,7.22"  xml:id="b7">
	<analytic>
		<title level="a" type="main">A note on space-filling visualizations and space-filling curves</title>
		<author>
			<persName>
				<forename type="first">Martin</forename>
				<surname>Wattenberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INFOVIS</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.11,269.51,221.81,7.22;8,336.11,278.97,221.88,7.22;8,336.11,288.44,175.79,7.22"  xml:id="b8">
	<analytic>
		<title level="a" type="main">On the optimization of visualizations of complex phenomena</title>
		<author>
			<persName>
				<forename type="first">Donald</forename>
				<forename type="middle">H</forename>
				<surname>House</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Alethea</forename>
				<surname>Bair</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Colin</forename>
				<surname>Ware</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<meeting><address><addrLine>Minneapolis, MN</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.11,297.90,221.88,7.22;8,336.11,307.37,118.32,7.22"  xml:id="b9">
	<monogr>
		<title level="m" type="main">Exploratory Data Analysis</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">W</forename>
				<surname>Tukey</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<publisher>Addison Wesley Publishing</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.11,316.83,221.83,7.22;8,336.11,326.30,221.90,7.22;8,336.11,335.76,221.94,7.22;8,336.11,345.23,189.82,7.22"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Computing graphics and exploratory data analysis: An introduction</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">W</forename>
				<surname>Tukey</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">A</forename>
				<surname>Tukey</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Annual Conference and Exposition: Computer Graphics85. Nat. Computer Graphics Assoc</title>
		<meeting>the Sixth Annual Conference and Exposition: Computer Graphics85. Nat. Computer Graphics Assoc</meeting>
		<imprint>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.10,354.69,221.84,7.22;8,336.11,364.16,153.01,7.22"  xml:id="b11">
	<analytic>
		<title level="a" type="main">A summary of entropy statistics</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">D</forename>
				<surname>Esteban</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Morales</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kybernetika</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="337" to="346" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.10,373.62,221.85,7.22;8,336.11,383.09,221.82,7.22;8,336.11,392.55,221.91,7.22;8,336.11,402.02,189.53,7.22"  xml:id="b12">
	<analytic>
		<title level="a" type="main">Entropy-based measures for clustering and som topology preservation applied to content-based image indexing and retrieval</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Koskela</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Laaksonen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Oja</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">17th Int. Conference on Pattern Recognition</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1005" to="1009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.11,411.48,221.83,7.22;8,336.11,420.95,221.81,7.22;8,336.11,430.41,221.86,7.22"  xml:id="b13">
	<analytic>
		<title level="a" type="main">Content based image retrieval and information theory: a general approach</title>
		<author>
			<persName>
				<forename type="first">John</forename>
				<surname>Zachary</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">S</forename>
				<surname>Iyengar</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Jacob</forename>
				<surname>Barhen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Soc. Inf. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="840" to="852" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.10,439.88,221.84,7.22;8,336.11,449.34,221.89,7.22;8,336.11,458.80,188.61,7.22"  xml:id="b14">
	<analytic>
		<title level="a" type="main">The eye have it: A task by data type taxonomy for information visualizations</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Shneiderman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Visual Languages</title>
		<meeting>. IEEE Conference on Visual Languages</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="336" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.10,468.27,221.91,7.22;8,336.11,477.73,187.34,7.22"  xml:id="b15">
	<monogr>
		<title level="m" type="main">Visual Cues -Practical Data Visualization</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Peter</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Mary</forename>
				<forename type="middle">M</forename>
				<surname>Keller</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Keller</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>IEEE Press</publisher>
		</imprint>
	</monogr>
	<note>1st. edition</note>
</biblStruct>

<biblStruct coords="8,336.10,487.20,221.84,7.22;8,336.11,496.66,221.89,7.22;8,336.11,506.13,75.72,7.22"  xml:id="b16">
	<analytic>
		<title level="a" type="main">Task-analytic approach to the automated design of graphic presentations</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Stephen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Casner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="151" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.10,515.59,221.84,7.22;8,336.11,525.06,221.86,7.22"  xml:id="b17">
	<analytic>
		<title level="a" type="main">A taxonomy of visualization techniques using the data state reference model</title>
		<author>
			<persName>
				<forename type="first">Ed</forename>
				<forename type="middle">H</forename>
				<surname>Chi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INFOVIS</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.10,534.52,221.83,7.22;8,336.11,543.99,221.92,7.22;8,336.11,553.45,176.68,7.22"  xml:id="b18">
	<analytic>
		<title level="a" type="main">Designing pixel-oriented visualization techniques: Theory and applications</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Keim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="78" />
			<date type="published" when="2000-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.10,562.92,221.86,7.22;8,336.11,572.38,221.90,7.22;8,336.11,581.85,221.87,7.22;8,336.11,591.31,149.04,7.22"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Clustering techniques for large data sets From the past to the future</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Hinneburg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Keim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD &apos;99: Tutorial notes of the fifth ACM SIGKDD</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="141" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.10,600.78,221.85,7.22;8,336.11,610.24,221.82,7.22;8,336.11,619.70,130.36,7.22"  xml:id="b20">
	<monogr>
		<title level="m" type="main">An efficient k-means clustering algorithm: analysis and implementation</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Kanungo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Mount</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Netanyahu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Piatko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Silverman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Wu</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.10,629.17,221.85,7.22;8,336.11,638.63,221.92,7.22;8,336.11,648.09,173.91,7.23"  xml:id="b21">
	<analytic>
		<title level="a" type="main">Types and forms of knowledge (patterns): decision trees</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Zytkow</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of data mining and knowledge discovery</title>
		<imprint>
			<publisher>Oxford University Press, Inc</publisher>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.11,657.55,221.87,7.22;8,336.11,667.02,88.47,7.22"  xml:id="b22">
	<monogr>
		<title level="m" type="main">Intelligent Image Processing</title>
		<author>
			<persName>
				<forename type="first">Steve</forename>
				<surname>Mann</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2001-11-02" />
			<publisher>John Wiley and Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,336.10,676.48,221.83,7.22;8,336.11,685.95,221.88,7.22;8,336.11,695.41,19.28,7.22"  xml:id="b23">
	<analytic>
		<title level="a" type="main">Quad trees: A data structure for retrieval on composite key</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">A</forename>
				<surname>Finkel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">L</forename>
				<surname>Bentley</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Informatica</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
